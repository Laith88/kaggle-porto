{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(solution, submission):\n",
    "    df = zip(solution, submission, range(len(solution)))\n",
    "    df = sorted(df, key=lambda x: (x[1],-x[2]), reverse=True)\n",
    "    rand = [float(i+1)/float(len(df)) for i in range(len(df))]\n",
    "    totalPos = float(sum([x[0] for x in df]))\n",
    "    cumPosFound = [df[0][0]]\n",
    "    for i in range(1,len(df)):\n",
    "        cumPosFound.append(cumPosFound[len(cumPosFound)-1] + df[i][0])\n",
    "    Lorentz = [float(x)/totalPos for x in cumPosFound]\n",
    "    Gini = [Lorentz[i]-rand[i] for i in range(len(df))]\n",
    "    return sum(Gini)\n",
    "\n",
    "def normalized_gini(solution, submission):\n",
    "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n",
    "    return normalized_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import keras.callbacks as kc\n",
    "\n",
    "class Metrics(kc.Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        targ = self.validation_data[1]\n",
    "        self.ginis=(2*roc_auc_score(targ, predict))-1\n",
    "        return\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    non_imp = ['ps_ind_12_bin','ps_ind_13_bin','ps_ind_18_bin','ps_car_10_cat','ps_ind_11_bin','ps_ind_10_bin','ps_ind_14']\n",
    "    \n",
    "    train = (pd.read_csv('../data/train.csv', na_values=999)\n",
    "              .fillna(value=999))\n",
    "    unwanted = list((set(train.columns[train.columns.str.startswith('ps_calc_')])|set(non_imp)))\n",
    "    train.drop(unwanted, axis=1, inplace=True)\n",
    "            \n",
    "    test  = (pd.read_csv('../data/test.csv', na_values=999)\n",
    "              .fillna(value=999)\n",
    "              .drop(unwanted, axis=1)) \n",
    "            \n",
    "    X = train.drop(['id', 'target'], axis=1).values\n",
    "    y = train.target.values\n",
    "    test_id = test.id.values\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    \n",
    "    f_dicts ={}\n",
    "\n",
    "    features_dict_data_type = {}\n",
    "    for k in ['cat', 'bin', 'con']:\n",
    "        features_dict_data_type[k]=[]\n",
    "        for i in train.columns.tolist()[2:]:\n",
    "            j = i.split('_')\n",
    "            if len(j) == 3:\n",
    "                j.append('con')\n",
    "            if j[3]==k:\n",
    "                features_dict_data_type[k].append(i)\n",
    "    f_dicts['type'] = features_dict_data_type\n",
    "\n",
    "    train_cat = np.array(train[f_dicts['type']['cat']])\n",
    "    train_cat[:,:] = np.add(train_cat[:,:],np.ones((train_cat.shape[0],train_cat.shape[1])))\n",
    "    test_cat  = np.array(test[f_dicts['type']['cat']])\n",
    "    test_cat[:,:] =  np.add(test_cat[:,:],np.ones((test_cat.shape[0],train_cat.shape[1])))\n",
    "\n",
    "    OH = OneHotEncoder()\n",
    "    OH.fit(np.array(list(train_cat) + list(test_cat)))\n",
    "    train_cat = OH.transform(train_cat).toarray()\n",
    "    test_cat = OH.transform(test_cat).toarray()\n",
    "\n",
    "    train_con = np.array(train[f_dicts['type']['con']])\n",
    "    test_con  = np.array(test[f_dicts['type']['con']])\n",
    "    RS = StandardScaler()\n",
    "    RS.fit(list(train_con) + list(test_con))\n",
    "    train_con = RS.transform(train_con)\n",
    "    train_con = RS.transform(train_con)\n",
    "\n",
    "    train_bin = np.array(train[f_dicts['type']['bin']])\n",
    "    test_bin = np.array(test[f_dicts['type']['bin']])\n",
    "\n",
    "\n",
    "    X = np.hstack((train_cat,train_con,train_bin))\n",
    "\n",
    "    X_test = np.hstack((test_cat,test_con,test_bin))\n",
    "    \n",
    "    #smote = SMOTE(random_state=0)\n",
    "    #X_resampled, y_resampled = smote.fit_sample(X, y)\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.25, shuffle=True,  random_state=np.random.randint(1000), stratify=y)\n",
    "\n",
    "    return X_train, X_vali, y_train, y_vali, X_test, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Metrics(kc.Callback):\n",
    "        def on_epoch_end(self, batch, logs={}):\n",
    "            predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "            targ = self.validation_data[1]\n",
    "            self.ginis=(2*roc_auc_score(targ, predict))-1\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    class Metrics(kc.Callback):\n",
    "        def on_epoch_end(self, batch, logs={}):\n",
    "            predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "            targ = self.validation_data[1]\n",
    "            self.ginis=(2*roc_auc_score(targ, predict))-1\n",
    "            return\n",
    "    metrics = Metrics()\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([128, 256, 512])}}, input_dim=198, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation={{choice(['relu', 'tanh', 'sigmoid'])}}))#{{choice(['relu', 'tanh', 'linear'])}}\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([128, 256, 512])}}, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation={{choice(['relu', 'tanh', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([128, 256, 512, 1024])}}, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation={{choice(['relu', 'tanh', 'sigmoid'])}}))\n",
    "    model.add(Dense(1,activation={{choice(['tanh', 'sigmoid'])}}, kernel_initializer='glorot_uniform'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "    \n",
    "    ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "    model.fit(X_train, y_train, batch_size={{choice([64, 128])}}, epochs= 20,validation_data=(X_vali,y_vali), callbacks=[ES,metrics])#, class_weight = class_weight\n",
    "    score, acc = model.evaluate(X_vali, y_vali, verbose=0)\n",
    "    print('Test accuracy: ', metrics.ginis)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali, X_test, test_id = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Input\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop, Adam, SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.wrappers.scikit_learn import KerasRegressor\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import cross_val_score, train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import KFold, StratifiedKFold\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.pipeline import Pipeline\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imblearn.over_sampling import SMOTE\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imblearn.combine import SMOTEENN, SMOTETomek\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import f1_score, roc_auc_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras.callbacks as kc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime as dt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [128, 256, 512]),\n",
      "        'activation': hp.choice('activation', ['relu', 'tanh', 'sigmoid']),\n",
      "        'activation_1': hp.choice('activation_1', ['relu', 'tanh', 'linear']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [128, 256, 512]),\n",
      "        'activation_2': hp.choice('activation_2', ['relu', 'tanh', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dense_2': hp.choice('Dense_2', [128, 256, 512, 1024]),\n",
      "        'activation_3': hp.choice('activation_3', ['relu', 'tanh', 'sigmoid']),\n",
      "        'activation_4': hp.choice('activation_4', ['tanh', 'sigmoid']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: non_imp = ['ps_ind_12_bin','ps_ind_13_bin','ps_ind_18_bin','ps_car_10_cat','ps_ind_11_bin','ps_ind_10_bin','ps_ind_14']\n",
      "   3: \n",
      "   4: train = (pd.read_csv('../data/train.csv', na_values=999)\n",
      "   5:           .fillna(value=999))\n",
      "   6: unwanted = list((set(train.columns[train.columns.str.startswith('ps_calc_')])|set(non_imp)))\n",
      "   7: train.drop(unwanted, axis=1, inplace=True)\n",
      "   8:         \n",
      "   9: test  = (pd.read_csv('../data/test.csv', na_values=999)\n",
      "  10:           .fillna(value=999)\n",
      "  11:           .drop(unwanted, axis=1)) \n",
      "  12:         \n",
      "  13: X = train.drop(['id', 'target'], axis=1).values\n",
      "  14: y = train.target.values\n",
      "  15: test_id = test.id.values\n",
      "  16: test = test.drop('id', axis=1)\n",
      "  17: \n",
      "  18: \n",
      "  19: f_dicts ={}\n",
      "  20: \n",
      "  21: features_dict_data_type = {}\n",
      "  22: for k in ['cat', 'bin', 'con']:\n",
      "  23:     features_dict_data_type[k]=[]\n",
      "  24:     for i in train.columns.tolist()[2:]:\n",
      "  25:         j = i.split('_')\n",
      "  26:         if len(j) == 3:\n",
      "  27:             j.append('con')\n",
      "  28:         if j[3]==k:\n",
      "  29:             features_dict_data_type[k].append(i)\n",
      "  30: f_dicts['type'] = features_dict_data_type\n",
      "  31: \n",
      "  32: train_cat = np.array(train[f_dicts['type']['cat']])\n",
      "  33: train_cat[:,:] = np.add(train_cat[:,:],np.ones((train_cat.shape[0],train_cat.shape[1])))\n",
      "  34: test_cat  = np.array(test[f_dicts['type']['cat']])\n",
      "  35: test_cat[:,:] =  np.add(test_cat[:,:],np.ones((test_cat.shape[0],train_cat.shape[1])))\n",
      "  36: \n",
      "  37: OH = OneHotEncoder()\n",
      "  38: OH.fit(np.array(list(train_cat) + list(test_cat)))\n",
      "  39: train_cat = OH.transform(train_cat).toarray()\n",
      "  40: test_cat = OH.transform(test_cat).toarray()\n",
      "  41: \n",
      "  42: train_con = np.array(train[f_dicts['type']['con']])\n",
      "  43: test_con  = np.array(test[f_dicts['type']['con']])\n",
      "  44: RS = StandardScaler()\n",
      "  45: RS.fit(list(train_con) + list(test_con))\n",
      "  46: train_con = RS.transform(train_con)\n",
      "  47: train_con = RS.transform(train_con)\n",
      "  48: \n",
      "  49: train_bin = np.array(train[f_dicts['type']['bin']])\n",
      "  50: test_bin = np.array(test[f_dicts['type']['bin']])\n",
      "  51: \n",
      "  52: \n",
      "  53: X = np.hstack((train_cat,train_con,train_bin))\n",
      "  54: \n",
      "  55: X_test = np.hstack((test_cat,test_con,test_bin))\n",
      "  56: \n",
      "  57: smote = SMOTE(random_state=0)\n",
      "  58: X_resampled, y_resampled = smote.fit_sample(X, y)\n",
      "  59: X_train, X_vali, y_train, y_vali = train_test_split(X_resampled, y_resampled, test_size=0.25, shuffle=True,  random_state=np.random.randint(1000), stratify=y_resampled)\n",
      "  60: \n",
      "  61: \n",
      "  62: \n",
      "  63: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     class Metrics(kc.Callback):\n",
      "   4:         def on_epoch_end(self, batch, logs={}):\n",
      "   5:             predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
      "   6:             targ = self.validation_data[1]\n",
      "   7:             self.ginis=(2*roc_auc_score(targ, predict))-1\n",
      "   8:             return\n",
      "   9:     metrics = Metrics()\n",
      "  10:     model = Sequential()\n",
      "  11:     model.add(Dense(space['Dense'], input_dim=198, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation=space['activation']))#space['activation_1']\n",
      "  12:     model.add(Dropout(space['Dropout']))\n",
      "  13:     model.add(Dense(space['Dense_1'], kernel_initializer='glorot_uniform',bias_initializer='zeros', activation=space['activation_2']))\n",
      "  14:     model.add(Dropout(space['Dropout_1']))\n",
      "  15:     model.add(Dense(space['Dense_2'], kernel_initializer='glorot_uniform',bias_initializer='zeros', activation=space['activation_3']))\n",
      "  16:     model.add(Dense(1,activation=space['activation_4'], kernel_initializer='glorot_uniform'))\n",
      "  17:     # Compile model\n",
      "  18:     model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])\n",
      "  19:     \n",
      "  20:     ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
      "  21:     model.fit(X_train, y_train, batch_size=space['batch_size'], epochs= 20,validation_data=(X_vali,y_vali), callbacks=[ES,metrics])#, class_weight = class_weight\n",
      "  22:     score, acc = model.evaluate(X_vali, y_vali, verbose=0)\n",
      "  23:     print('Test accuracy: ', metrics.ginis)\n",
      "  24:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  25: \n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.6148 - acc: 0.6415 - val_loss: 0.4424 - val_acc: 0.7871\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.4001 - acc: 0.8098 - val_loss: 0.3252 - val_acc: 0.8652\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.3136 - acc: 0.8633 - val_loss: 0.2513 - val_acc: 0.9002\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2719 - acc: 0.8870 - val_loss: 0.2310 - val_acc: 0.9086\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2480 - acc: 0.8997 - val_loss: 0.2364 - val_acc: 0.9030\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2311 - acc: 0.9081 - val_loss: 0.1927 - val_acc: 0.9288\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2190 - acc: 0.9143 - val_loss: 0.1933 - val_acc: 0.9267\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2098 - acc: 0.9188 - val_loss: 0.1802 - val_acc: 0.9332\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2007 - acc: 0.9230 - val_loss: 0.1766 - val_acc: 0.9336\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1942 - acc: 0.9261 - val_loss: 0.1670 - val_acc: 0.9400\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1879 - acc: 0.9294 - val_loss: 0.1664 - val_acc: 0.9386\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1823 - acc: 0.9320 - val_loss: 0.1607 - val_acc: 0.9416\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 36s - loss: 0.1777 - acc: 0.9343 - val_loss: 0.1582 - val_acc: 0.9428\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1735 - acc: 0.9363 - val_loss: 0.1584 - val_acc: 0.9423\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 36s - loss: 0.1695 - acc: 0.9380 - val_loss: 0.1505 - val_acc: 0.9465\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1665 - acc: 0.9394 - val_loss: 0.1614 - val_acc: 0.9407\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1632 - acc: 0.9409 - val_loss: 0.1439 - val_acc: 0.9504\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1602 - acc: 0.9422 - val_loss: 0.1417 - val_acc: 0.9516\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1584 - acc: 0.9433 - val_loss: 0.1405 - val_acc: 0.9528\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.1558 - acc: 0.9441 - val_loss: 0.1396 - val_acc: 0.9546\n",
      "Test accuracy:  0.961450303163\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.9272 - acc: 0.4898 - val_loss: 0.7911 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.7072 - acc: 0.4991 - val_loss: 0.6872 - val_acc: 0.5541\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.7545 - acc: 0.4967 - val_loss: 0.9929 - val_acc: 0.4989\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.7655 - acc: 0.4971 - val_loss: 0.7696 - val_acc: 0.4999\n",
      "Epoch 00003: early stopping\n",
      "Test accuracy:  -0.0130924240306\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 22s - loss: 8.0538 - acc: 9.5899e-04 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 8.0590 - acc: 0.0000e+00 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 8.0590 - acc: 0.0000e+00 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 00002: early stopping\n",
      "Test accuracy:  0.00207139773978\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.7026 - acc: 0.5022 - val_loss: 0.6865 - val_acc: 0.5452\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 20s - loss: 0.7016 - acc: 0.5015 - val_loss: 0.7067 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 20s - loss: 0.7020 - acc: 0.5030 - val_loss: 0.6890 - val_acc: 0.5400\n",
      "Epoch 00002: early stopping\n",
      "Test accuracy:  0.145974650598\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.7055 - acc: 0.5222 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6868 - acc: 0.5546 - val_loss: 0.6742 - val_acc: 0.5852\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6782 - acc: 0.5775 - val_loss: 0.6724 - val_acc: 0.5855\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6703 - acc: 0.5891 - val_loss: 0.6574 - val_acc: 0.6109\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6565 - acc: 0.6103 - val_loss: 0.6270 - val_acc: 0.6518\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6311 - acc: 0.6437 - val_loss: 0.5768 - val_acc: 0.7143\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5984 - acc: 0.6765 - val_loss: 0.5227 - val_acc: 0.7718\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5662 - acc: 0.7050 - val_loss: 0.4732 - val_acc: 0.8004\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5391 - acc: 0.7257 - val_loss: 0.4442 - val_acc: 0.8325\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5162 - acc: 0.7430 - val_loss: 0.4147 - val_acc: 0.8362\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4968 - acc: 0.7562 - val_loss: 0.3903 - val_acc: 0.8524\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4804 - acc: 0.7678 - val_loss: 0.3733 - val_acc: 0.8648\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4665 - acc: 0.7766 - val_loss: 0.3549 - val_acc: 0.8749\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4545 - acc: 0.7846 - val_loss: 0.3486 - val_acc: 0.8806\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4427 - acc: 0.7922 - val_loss: 0.3364 - val_acc: 0.8812\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4339 - acc: 0.7977 - val_loss: 0.3249 - val_acc: 0.8813\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4245 - acc: 0.8042 - val_loss: 0.3135 - val_acc: 0.8891\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4172 - acc: 0.8084 - val_loss: 0.3124 - val_acc: 0.8910\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4099 - acc: 0.8126 - val_loss: 0.2961 - val_acc: 0.8922\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4041 - acc: 0.8168 - val_loss: 0.2961 - val_acc: 0.8926\n",
      "Test accuracy:  0.926166833675\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.6646 - acc: 0.5974 - val_loss: 0.6684 - val_acc: 0.5627\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.5491 - acc: 0.7229 - val_loss: 0.6086 - val_acc: 0.6219\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4686 - acc: 0.7794 - val_loss: 0.5251 - val_acc: 0.6772\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4248 - acc: 0.8062 - val_loss: 0.4275 - val_acc: 0.7807\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3982 - acc: 0.8222 - val_loss: 0.4312 - val_acc: 0.7667\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3789 - acc: 0.8335 - val_loss: 0.3974 - val_acc: 0.7954\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3657 - acc: 0.8410 - val_loss: 0.3569 - val_acc: 0.8426\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3555 - acc: 0.8465 - val_loss: 0.3481 - val_acc: 0.8585\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3461 - acc: 0.8517 - val_loss: 0.3075 - val_acc: 0.9009\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3404 - acc: 0.8547 - val_loss: 0.2988 - val_acc: 0.9111\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3337 - acc: 0.8588 - val_loss: 0.2846 - val_acc: 0.9232\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3296 - acc: 0.8610 - val_loss: 0.2692 - val_acc: 0.9240\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3238 - acc: 0.8641 - val_loss: 0.2738 - val_acc: 0.9305\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3211 - acc: 0.8653 - val_loss: 0.2783 - val_acc: 0.9296\n",
      "Epoch 00013: early stopping\n",
      "Test accuracy:  0.944561455454\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6752 - acc: 0.5768 - val_loss: 0.6663 - val_acc: 0.5927\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6609 - acc: 0.6008 - val_loss: 0.7031 - val_acc: 0.5219\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6180 - acc: 0.6560 - val_loss: 1.4381 - val_acc: 0.5000\n",
      "Epoch 00002: early stopping\n",
      "Test accuracy:  0.0598198658109\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.5905 - acc: 0.6743 - val_loss: 0.4323 - val_acc: 0.8125\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 37s - loss: 0.4361 - acc: 0.7956 - val_loss: 0.3139 - val_acc: 0.8788\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.3657 - acc: 0.8378 - val_loss: 0.2635 - val_acc: 0.9000\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.3311 - acc: 0.8575 - val_loss: 0.2489 - val_acc: 0.9049\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.3088 - acc: 0.8698 - val_loss: 0.2557 - val_acc: 0.8978\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2940 - acc: 0.8777 - val_loss: 0.2213 - val_acc: 0.9183\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2821 - acc: 0.8843 - val_loss: 0.2184 - val_acc: 0.9190\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2729 - acc: 0.8888 - val_loss: 0.2077 - val_acc: 0.9269\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2650 - acc: 0.8932 - val_loss: 0.2088 - val_acc: 0.9231\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 37s - loss: 0.2592 - acc: 0.8963 - val_loss: 0.2131 - val_acc: 0.9188\n",
      "Epoch 00009: early stopping\n",
      "Test accuracy:  0.943658360694\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.6770 - acc: 0.5743 - val_loss: 0.6752 - val_acc: 0.5804\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.6678 - acc: 0.5907 - val_loss: 0.6563 - val_acc: 0.6076\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.6527 - acc: 0.6148 - val_loss: 0.6211 - val_acc: 0.6642\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.6219 - acc: 0.6538 - val_loss: 0.5626 - val_acc: 0.7317\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.5863 - acc: 0.6865 - val_loss: 0.5121 - val_acc: 0.7788\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.5543 - acc: 0.7126 - val_loss: 0.4625 - val_acc: 0.8041\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.5261 - acc: 0.7347 - val_loss: 0.4423 - val_acc: 0.8345\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.5009 - acc: 0.7521 - val_loss: 0.4116 - val_acc: 0.8456\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4800 - acc: 0.7664 - val_loss: 0.3933 - val_acc: 0.8556\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4623 - acc: 0.7777 - val_loss: 0.3828 - val_acc: 0.8634\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4483 - acc: 0.7865 - val_loss: 0.3618 - val_acc: 0.8670\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4366 - acc: 0.7949 - val_loss: 0.3452 - val_acc: 0.8778\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4265 - acc: 0.8005 - val_loss: 0.3475 - val_acc: 0.8822\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4175 - acc: 0.8064 - val_loss: 0.3323 - val_acc: 0.8833\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4094 - acc: 0.8115 - val_loss: 0.3285 - val_acc: 0.8905\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4029 - acc: 0.8154 - val_loss: 0.3222 - val_acc: 0.8933\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.3965 - acc: 0.8190 - val_loss: 0.3208 - val_acc: 0.8971\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.3908 - acc: 0.8228 - val_loss: 0.3154 - val_acc: 0.8905\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.3853 - acc: 0.8264 - val_loss: 0.3051 - val_acc: 0.8982\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.3802 - acc: 0.8295 - val_loss: 0.3064 - val_acc: 0.8967\n",
      "Test accuracy:  0.904296219351\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.7030 - acc: 0.5753 - val_loss: 0.5986 - val_acc: 0.6807\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5600 - acc: 0.7109 - val_loss: 0.4152 - val_acc: 0.8234\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4775 - acc: 0.7748 - val_loss: 0.3371 - val_acc: 0.8688\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4146 - acc: 0.8105 - val_loss: 0.3280 - val_acc: 0.8796\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4059 - acc: 0.8230 - val_loss: 0.5177 - val_acc: 0.6023\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3740 - acc: 0.8365 - val_loss: 0.2953 - val_acc: 0.8840\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3810 - acc: 0.8371 - val_loss: 0.2979 - val_acc: 0.8802\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3479 - acc: 0.8534 - val_loss: 0.2742 - val_acc: 0.8999\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3512 - acc: 0.8484 - val_loss: 0.2481 - val_acc: 0.9143\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3368 - acc: 0.8599 - val_loss: 0.2407 - val_acc: 0.9104\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3508 - acc: 0.8536 - val_loss: 0.2854 - val_acc: 0.8977\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3566 - acc: 0.8554 - val_loss: 0.2222 - val_acc: 0.9276\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3425 - acc: 0.8609 - val_loss: 0.2259 - val_acc: 0.9272\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3277 - acc: 0.8626 - val_loss: 0.2215 - val_acc: 0.9269\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3272 - acc: 0.8693 - val_loss: 0.2513 - val_acc: 0.9172\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3262 - acc: 0.8658 - val_loss: 0.2279 - val_acc: 0.9163\n",
      "Epoch 00015: early stopping\n",
      "Test accuracy:  0.926902090049\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.6633 - acc: 0.5957 - val_loss: 0.6206 - val_acc: 0.6575\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5622 - acc: 0.6973 - val_loss: 0.4307 - val_acc: 0.8032\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4601 - acc: 0.7698 - val_loss: 0.3778 - val_acc: 0.8271\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4005 - acc: 0.8107 - val_loss: 0.3172 - val_acc: 0.8645\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3636 - acc: 0.8350 - val_loss: 0.2772 - val_acc: 0.8921\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3395 - acc: 0.8501 - val_loss: 0.2506 - val_acc: 0.9048\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3217 - acc: 0.8605 - val_loss: 0.2394 - val_acc: 0.9109\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.3084 - acc: 0.8686 - val_loss: 0.2861 - val_acc: 0.8812\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.2976 - acc: 0.8748 - val_loss: 0.2431 - val_acc: 0.9032\n",
      "Epoch 00008: early stopping\n",
      "Test accuracy:  0.915416939279\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 24s - loss: 8.0580 - acc: 9.6481e-05 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 24s - loss: 8.0590 - acc: 0.0000e+00 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 23s - loss: 8.0590 - acc: 0.0000e+00 - val_loss: 8.0591 - val_acc: 0.0000e+00\n",
      "Epoch 00002: early stopping\n",
      "Test accuracy:  0.0\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.6726 - acc: 0.5827 - val_loss: 0.6556 - val_acc: 0.6132\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.6177 - acc: 0.6305 - val_loss: 0.5726 - val_acc: 0.6744\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.5579 - acc: 0.6906 - val_loss: 0.4786 - val_acc: 0.7702\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4996 - acc: 0.7395 - val_loss: 0.4254 - val_acc: 0.8001\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4656 - acc: 0.7647 - val_loss: 0.3971 - val_acc: 0.8134\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4393 - acc: 0.7848 - val_loss: 0.3477 - val_acc: 0.8606\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4173 - acc: 0.8008 - val_loss: 0.3261 - val_acc: 0.8659\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3990 - acc: 0.8134 - val_loss: 0.3115 - val_acc: 0.8712\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3840 - acc: 0.8234 - val_loss: 0.3070 - val_acc: 0.8691\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3714 - acc: 0.8315 - val_loss: 0.2830 - val_acc: 0.8914\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3614 - acc: 0.8379 - val_loss: 0.2839 - val_acc: 0.8828\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3516 - acc: 0.8440 - val_loss: 0.2741 - val_acc: 0.8874\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3446 - acc: 0.8488 - val_loss: 0.2687 - val_acc: 0.8931\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3373 - acc: 0.8528 - val_loss: 0.2806 - val_acc: 0.8811\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3327 - acc: 0.8560 - val_loss: 0.2653 - val_acc: 0.8947\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3262 - acc: 0.8595 - val_loss: 0.2613 - val_acc: 0.8947\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3215 - acc: 0.8624 - val_loss: 0.2692 - val_acc: 0.8883\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3178 - acc: 0.8649 - val_loss: 0.2593 - val_acc: 0.8938\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3141 - acc: 0.8667 - val_loss: 0.2508 - val_acc: 0.8998\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3108 - acc: 0.8692 - val_loss: 0.2497 - val_acc: 0.9006\n",
      "Test accuracy:  0.90451310607\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.6342 - acc: 0.6212 - val_loss: 0.5063 - val_acc: 0.7466\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.4291 - acc: 0.7917 - val_loss: 0.3615 - val_acc: 0.8384\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.3346 - acc: 0.8502 - val_loss: 0.2752 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.2850 - acc: 0.8783 - val_loss: 0.2344 - val_acc: 0.9084\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.2543 - acc: 0.8945 - val_loss: 0.2062 - val_acc: 0.9214\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.2326 - acc: 0.9054 - val_loss: 0.1941 - val_acc: 0.9306\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.2162 - acc: 0.9136 - val_loss: 0.1908 - val_acc: 0.9279\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.2041 - acc: 0.9198 - val_loss: 0.1766 - val_acc: 0.9351\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1943 - acc: 0.9243 - val_loss: 0.1643 - val_acc: 0.9411\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1849 - acc: 0.9289 - val_loss: 0.1704 - val_acc: 0.9368\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1776 - acc: 0.9322 - val_loss: 0.1637 - val_acc: 0.9403\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1714 - acc: 0.9351 - val_loss: 0.1510 - val_acc: 0.9486\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1660 - acc: 0.9375 - val_loss: 0.1612 - val_acc: 0.9420\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1606 - acc: 0.9400 - val_loss: 0.1464 - val_acc: 0.9504\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1557 - acc: 0.9423 - val_loss: 0.1388 - val_acc: 0.9526\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1520 - acc: 0.9438 - val_loss: 0.1386 - val_acc: 0.9522\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1475 - acc: 0.9456 - val_loss: 0.1378 - val_acc: 0.9527\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1429 - acc: 0.9476 - val_loss: 0.1394 - val_acc: 0.9501\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1396 - acc: 0.9490 - val_loss: 0.1294 - val_acc: 0.9570\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 38s - loss: 0.1357 - acc: 0.9506 - val_loss: 0.1298 - val_acc: 0.9557\n",
      "Test accuracy:  0.967788966987\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.6702 - acc: 0.5871 - val_loss: 0.6492 - val_acc: 0.6181\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.6079 - acc: 0.6435 - val_loss: 0.5492 - val_acc: 0.6990\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.5409 - acc: 0.7013 - val_loss: 0.4806 - val_acc: 0.7508\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4929 - acc: 0.7399 - val_loss: 0.4369 - val_acc: 0.7873\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4541 - acc: 0.7727 - val_loss: 0.3828 - val_acc: 0.8224\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4185 - acc: 0.7991 - val_loss: 0.3492 - val_acc: 0.8445\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 24s - loss: 0.3918 - acc: 0.8164 - val_loss: 0.3311 - val_acc: 0.8531\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 24s - loss: 0.3751 - acc: 0.8272 - val_loss: 0.3315 - val_acc: 0.8554\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3629 - acc: 0.8348 - val_loss: 0.3049 - val_acc: 0.8671\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3534 - acc: 0.8408 - val_loss: 0.3059 - val_acc: 0.8648\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3441 - acc: 0.8464 - val_loss: 0.2955 - val_acc: 0.8717\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3383 - acc: 0.8505 - val_loss: 0.2841 - val_acc: 0.8847\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3315 - acc: 0.8545 - val_loss: 0.2864 - val_acc: 0.8766\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3254 - acc: 0.8578 - val_loss: 0.2766 - val_acc: 0.8866\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3212 - acc: 0.8610 - val_loss: 0.2745 - val_acc: 0.8841\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3162 - acc: 0.8638 - val_loss: 0.2695 - val_acc: 0.8871\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3122 - acc: 0.8663 - val_loss: 0.2659 - val_acc: 0.8901\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3069 - acc: 0.8693 - val_loss: 0.2649 - val_acc: 0.8901\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3024 - acc: 0.8726 - val_loss: 0.2476 - val_acc: 0.9012\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 24s - loss: 0.2988 - acc: 0.8746 - val_loss: 0.2644 - val_acc: 0.8897\n",
      "Test accuracy:  0.905448617278\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 24s - loss: 0.6643 - acc: 0.5943 - val_loss: 0.6259 - val_acc: 0.6281\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 24s - loss: 0.5771 - acc: 0.6729 - val_loss: 0.5058 - val_acc: 0.7412\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4753 - acc: 0.7607 - val_loss: 0.3865 - val_acc: 0.8233\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4009 - acc: 0.8124 - val_loss: 0.3275 - val_acc: 0.8618\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3601 - acc: 0.8382 - val_loss: 0.3094 - val_acc: 0.8685\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3341 - acc: 0.8533 - val_loss: 0.2769 - val_acc: 0.8842\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3147 - acc: 0.8659 - val_loss: 0.2696 - val_acc: 0.8885\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3004 - acc: 0.8749 - val_loss: 0.2575 - val_acc: 0.8979\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.2891 - acc: 0.8815 - val_loss: 0.2582 - val_acc: 0.8974\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.2794 - acc: 0.8867 - val_loss: 0.2305 - val_acc: 0.9108\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.2706 - acc: 0.8919 - val_loss: 0.2352 - val_acc: 0.9089\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.2641 - acc: 0.8955 - val_loss: 0.2319 - val_acc: 0.9108\n",
      "Epoch 00011: early stopping\n",
      "Test accuracy:  0.917552754742\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.6585 - acc: 0.6057 - val_loss: 0.5743 - val_acc: 0.7086\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5782 - acc: 0.7004 - val_loss: 0.4614 - val_acc: 0.7977\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5224 - acc: 0.7436 - val_loss: 0.4089 - val_acc: 0.8330\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4894 - acc: 0.7660 - val_loss: 0.3789 - val_acc: 0.8478\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4664 - acc: 0.7810 - val_loss: 0.3589 - val_acc: 0.8676\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4517 - acc: 0.7899 - val_loss: 0.3380 - val_acc: 0.8799\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4391 - acc: 0.7984 - val_loss: 0.3296 - val_acc: 0.8764\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4293 - acc: 0.8036 - val_loss: 0.3326 - val_acc: 0.8610\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4216 - acc: 0.8086 - val_loss: 0.3040 - val_acc: 0.8960\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4158 - acc: 0.8122 - val_loss: 0.3185 - val_acc: 0.8752\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.4090 - acc: 0.8162 - val_loss: 0.3152 - val_acc: 0.8776\n",
      "Epoch 00010: early stopping\n",
      "Test accuracy:  0.912656641464\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.7223 - acc: 0.5488 - val_loss: 0.6744 - val_acc: 0.5842\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6741 - acc: 0.5813 - val_loss: 0.6663 - val_acc: 0.5923\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6692 - acc: 0.5886 - val_loss: 0.6621 - val_acc: 0.5992\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6630 - acc: 0.6005 - val_loss: 0.6445 - val_acc: 0.6204\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6468 - acc: 0.6120 - val_loss: 0.6088 - val_acc: 0.6335\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6242 - acc: 0.6230 - val_loss: 0.5992 - val_acc: 0.6378\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6153 - acc: 0.6301 - val_loss: 0.5921 - val_acc: 0.6492\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6088 - acc: 0.6364 - val_loss: 0.5858 - val_acc: 0.6547\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.6057 - acc: 0.6414 - val_loss: 0.5735 - val_acc: 0.6729\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5996 - acc: 0.6478 - val_loss: 0.5734 - val_acc: 0.6802\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5989 - acc: 0.6518 - val_loss: 0.5657 - val_acc: 0.6869\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5951 - acc: 0.6568 - val_loss: 0.5615 - val_acc: 0.7013\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5952 - acc: 0.6599 - val_loss: 0.5485 - val_acc: 0.7101\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5915 - acc: 0.6641 - val_loss: 0.5500 - val_acc: 0.7098\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5924 - acc: 0.6670 - val_loss: 0.5468 - val_acc: 0.7214\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5908 - acc: 0.6688 - val_loss: 0.5342 - val_acc: 0.7291\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5874 - acc: 0.6719 - val_loss: 0.5420 - val_acc: 0.7275\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 21s - loss: 0.5843 - acc: 0.6747 - val_loss: 0.5372 - val_acc: 0.7386\n",
      "Epoch 00017: early stopping\n",
      "Test accuracy:  0.631170792094\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6668 - acc: 0.5915 - val_loss: 0.6354 - val_acc: 0.6413\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.5540 - acc: 0.6998 - val_loss: 0.4337 - val_acc: 0.8098\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.4383 - acc: 0.7882 - val_loss: 0.3386 - val_acc: 0.8633\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3743 - acc: 0.8276 - val_loss: 0.2884 - val_acc: 0.8813\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3338 - acc: 0.8521 - val_loss: 0.2641 - val_acc: 0.8929\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3054 - acc: 0.8680 - val_loss: 0.2369 - val_acc: 0.9082\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2835 - acc: 0.8797 - val_loss: 0.2168 - val_acc: 0.9200\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2671 - acc: 0.8889 - val_loss: 0.2183 - val_acc: 0.9142\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2530 - acc: 0.8963 - val_loss: 0.2138 - val_acc: 0.9147\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2424 - acc: 0.9014 - val_loss: 0.1985 - val_acc: 0.9228\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2316 - acc: 0.9073 - val_loss: 0.1762 - val_acc: 0.9356\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2239 - acc: 0.9110 - val_loss: 0.1840 - val_acc: 0.9312\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2161 - acc: 0.9148 - val_loss: 0.1795 - val_acc: 0.9332\n",
      "Epoch 00012: early stopping\n",
      "Test accuracy:  0.957619678642\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 24s - loss: 0.6781 - acc: 0.5753 - val_loss: 0.6670 - val_acc: 0.5925\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.6495 - acc: 0.6093 - val_loss: 0.5985 - val_acc: 0.6561\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.5883 - acc: 0.6681 - val_loss: 0.5159 - val_acc: 0.7524\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.5418 - acc: 0.7188 - val_loss: 0.4517 - val_acc: 0.8066\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4987 - acc: 0.7540 - val_loss: 0.4075 - val_acc: 0.8398\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.4690 - acc: 0.7762 - val_loss: 0.3881 - val_acc: 0.8378\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4333 - acc: 0.8003 - val_loss: 0.3380 - val_acc: 0.8726\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.4049 - acc: 0.8192 - val_loss: 0.3023 - val_acc: 0.8833\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3775 - acc: 0.8332 - val_loss: 0.2822 - val_acc: 0.8922\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3568 - acc: 0.8443 - val_loss: 0.3186 - val_acc: 0.8806\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3396 - acc: 0.8538 - val_loss: 0.2557 - val_acc: 0.9006\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3309 - acc: 0.8593 - val_loss: 0.2750 - val_acc: 0.9009\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.3207 - acc: 0.8657 - val_loss: 0.2385 - val_acc: 0.9146\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3055 - acc: 0.8719 - val_loss: 0.2556 - val_acc: 0.9108\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.3005 - acc: 0.8750 - val_loss: 0.2318 - val_acc: 0.9186\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.2919 - acc: 0.8777 - val_loss: 0.2251 - val_acc: 0.9134\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.2804 - acc: 0.8826 - val_loss: 0.2149 - val_acc: 0.9254\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.2716 - acc: 0.8840 - val_loss: 0.2122 - val_acc: 0.9166\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 22s - loss: 0.2755 - acc: 0.8823 - val_loss: 0.2123 - val_acc: 0.9171\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 23s - loss: 0.2663 - acc: 0.8869 - val_loss: 0.2000 - val_acc: 0.9250\n",
      "Test accuracy:  0.951014954361\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.5533 - acc: 0.6918 - val_loss: 0.4033 - val_acc: 0.8068\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3587 - acc: 0.8366 - val_loss: 0.3195 - val_acc: 0.8629\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2985 - acc: 0.8729 - val_loss: 0.2938 - val_acc: 0.8784\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2673 - acc: 0.8898 - val_loss: 0.2781 - val_acc: 0.8894\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2437 - acc: 0.9020 - val_loss: 0.2296 - val_acc: 0.9093\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2268 - acc: 0.9103 - val_loss: 0.2050 - val_acc: 0.9232\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2143 - acc: 0.9163 - val_loss: 0.1963 - val_acc: 0.9249\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2043 - acc: 0.9210 - val_loss: 0.2007 - val_acc: 0.9238\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1955 - acc: 0.9251 - val_loss: 0.1801 - val_acc: 0.9333\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1876 - acc: 0.9288 - val_loss: 0.1774 - val_acc: 0.9346\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1812 - acc: 0.9318 - val_loss: 0.1685 - val_acc: 0.9396\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1755 - acc: 0.9344 - val_loss: 0.1642 - val_acc: 0.9415\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1712 - acc: 0.9364 - val_loss: 0.1636 - val_acc: 0.9407\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1672 - acc: 0.9382 - val_loss: 0.1573 - val_acc: 0.9434\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1628 - acc: 0.9399 - val_loss: 0.1627 - val_acc: 0.9409\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1598 - acc: 0.9413 - val_loss: 0.1531 - val_acc: 0.9473\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1566 - acc: 0.9429 - val_loss: 0.1480 - val_acc: 0.9487\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1537 - acc: 0.9439 - val_loss: 0.1433 - val_acc: 0.9516\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1508 - acc: 0.9452 - val_loss: 0.1449 - val_acc: 0.9504\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1485 - acc: 0.9465 - val_loss: 0.1448 - val_acc: 0.9510\n",
      "Epoch 00019: early stopping\n",
      "Test accuracy:  0.959180206893\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.6017 - acc: 0.6502 - val_loss: 0.4570 - val_acc: 0.7716\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4249 - acc: 0.7906 - val_loss: 0.3307 - val_acc: 0.8609\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3513 - acc: 0.8410 - val_loss: 0.2875 - val_acc: 0.8839\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3105 - acc: 0.8665 - val_loss: 0.2747 - val_acc: 0.8865\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2819 - acc: 0.8831 - val_loss: 0.2354 - val_acc: 0.9115\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2617 - acc: 0.8934 - val_loss: 0.2188 - val_acc: 0.9177\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2475 - acc: 0.9012 - val_loss: 0.2051 - val_acc: 0.9242\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2362 - acc: 0.9072 - val_loss: 0.2119 - val_acc: 0.9177\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2269 - acc: 0.9117 - val_loss: 0.1949 - val_acc: 0.9292\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2199 - acc: 0.9151 - val_loss: 0.1856 - val_acc: 0.9325\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2142 - acc: 0.9178 - val_loss: 0.1900 - val_acc: 0.9306\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2092 - acc: 0.9203 - val_loss: 0.1829 - val_acc: 0.9330\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2041 - acc: 0.9224 - val_loss: 0.1915 - val_acc: 0.9286\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2008 - acc: 0.9240 - val_loss: 0.1836 - val_acc: 0.9327\n",
      "Epoch 00013: early stopping\n",
      "Test accuracy:  0.942718688414\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.6046 - acc: 0.6483 - val_loss: 0.4555 - val_acc: 0.7714\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.4077 - acc: 0.8038 - val_loss: 0.3337 - val_acc: 0.8536\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3255 - acc: 0.8573 - val_loss: 0.2694 - val_acc: 0.8900\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2848 - acc: 0.8809 - val_loss: 0.2452 - val_acc: 0.9013\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2601 - acc: 0.8942 - val_loss: 0.2242 - val_acc: 0.9129\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2436 - acc: 0.9030 - val_loss: 0.2138 - val_acc: 0.9192\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2320 - acc: 0.9087 - val_loss: 0.2042 - val_acc: 0.9230\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2213 - acc: 0.9141 - val_loss: 0.1930 - val_acc: 0.9303\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2136 - acc: 0.9176 - val_loss: 0.1844 - val_acc: 0.9334\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2070 - acc: 0.9208 - val_loss: 0.1786 - val_acc: 0.9350\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2012 - acc: 0.9236 - val_loss: 0.1745 - val_acc: 0.9369\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1965 - acc: 0.9253 - val_loss: 0.1731 - val_acc: 0.9366\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 40s - loss: 0.1919 - acc: 0.9277 - val_loss: 0.1692 - val_acc: 0.9384\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1887 - acc: 0.9288 - val_loss: 0.1708 - val_acc: 0.9375\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1844 - acc: 0.9308 - val_loss: 0.1569 - val_acc: 0.9458\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1811 - acc: 0.9323 - val_loss: 0.1622 - val_acc: 0.9416\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1783 - acc: 0.9337 - val_loss: 0.1630 - val_acc: 0.9417\n",
      "Epoch 00016: early stopping\n",
      "Test accuracy:  0.953302401761\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.6351 - acc: 0.6196 - val_loss: 0.5267 - val_acc: 0.7240\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4356 - acc: 0.7869 - val_loss: 0.3509 - val_acc: 0.8409\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3350 - acc: 0.8501 - val_loss: 0.2707 - val_acc: 0.8876\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2839 - acc: 0.8790 - val_loss: 0.2301 - val_acc: 0.9091\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2520 - acc: 0.8959 - val_loss: 0.2019 - val_acc: 0.9246\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2300 - acc: 0.9071 - val_loss: 0.1873 - val_acc: 0.9324\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2131 - acc: 0.9155 - val_loss: 0.1882 - val_acc: 0.9279\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2008 - acc: 0.9215 - val_loss: 0.1717 - val_acc: 0.9399\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1896 - acc: 0.9269 - val_loss: 0.1632 - val_acc: 0.9411\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1800 - acc: 0.9314 - val_loss: 0.1552 - val_acc: 0.9451\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1723 - acc: 0.9348 - val_loss: 0.1571 - val_acc: 0.9430\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1647 - acc: 0.9382 - val_loss: 0.1648 - val_acc: 0.9404\n",
      "Epoch 00011: early stopping\n",
      "Test accuracy:  0.958324591905\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.6135 - acc: 0.6412 - val_loss: 0.4524 - val_acc: 0.7808\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3961 - acc: 0.8149 - val_loss: 0.3101 - val_acc: 0.8665\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3147 - acc: 0.8652 - val_loss: 0.2496 - val_acc: 0.9043\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2795 - acc: 0.8842 - val_loss: 0.2473 - val_acc: 0.9009\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2608 - acc: 0.8943 - val_loss: 0.2221 - val_acc: 0.9136\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2453 - acc: 0.9022 - val_loss: 0.2095 - val_acc: 0.9248\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2337 - acc: 0.9074 - val_loss: 0.1971 - val_acc: 0.9274\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2225 - acc: 0.9127 - val_loss: 0.2033 - val_acc: 0.9219\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2139 - acc: 0.9174 - val_loss: 0.1854 - val_acc: 0.9331\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2068 - acc: 0.9204 - val_loss: 0.1738 - val_acc: 0.9383\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2005 - acc: 0.9235 - val_loss: 0.1746 - val_acc: 0.9370\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1951 - acc: 0.9261 - val_loss: 0.1688 - val_acc: 0.9399\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1895 - acc: 0.9286 - val_loss: 0.1732 - val_acc: 0.9363\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1854 - acc: 0.9308 - val_loss: 0.1643 - val_acc: 0.9413\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1811 - acc: 0.9326 - val_loss: 0.1547 - val_acc: 0.9463\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1774 - acc: 0.9345 - val_loss: 0.1492 - val_acc: 0.9486\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1738 - acc: 0.9361 - val_loss: 0.1547 - val_acc: 0.9454\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.1703 - acc: 0.9378 - val_loss: 0.1506 - val_acc: 0.9493\n",
      "Epoch 00017: early stopping\n",
      "Test accuracy:  0.955822154497\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.5240 - acc: 0.7238 - val_loss: 0.3582 - val_acc: 0.8468\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3559 - acc: 0.8413 - val_loss: 0.2763 - val_acc: 0.8858\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2980 - acc: 0.8735 - val_loss: 0.2473 - val_acc: 0.8983\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2660 - acc: 0.8907 - val_loss: 0.2405 - val_acc: 0.9010\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2462 - acc: 0.9010 - val_loss: 0.2084 - val_acc: 0.9199\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2320 - acc: 0.9083 - val_loss: 0.1972 - val_acc: 0.9248\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2217 - acc: 0.9133 - val_loss: 0.1987 - val_acc: 0.9243\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2121 - acc: 0.9182 - val_loss: 0.1830 - val_acc: 0.9335\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2053 - acc: 0.9214 - val_loss: 0.1704 - val_acc: 0.9391\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1991 - acc: 0.9242 - val_loss: 0.1740 - val_acc: 0.9362\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1949 - acc: 0.9261 - val_loss: 0.1617 - val_acc: 0.9437\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1903 - acc: 0.9283 - val_loss: 0.1712 - val_acc: 0.9365\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1866 - acc: 0.9301 - val_loss: 0.1658 - val_acc: 0.9389\n",
      "Epoch 00012: early stopping\n",
      "Test accuracy:  0.959281751225\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.6690 - acc: 0.5874 - val_loss: 0.6420 - val_acc: 0.6267\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.5744 - acc: 0.6895 - val_loss: 0.4414 - val_acc: 0.8123\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.4546 - acc: 0.7799 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3940 - acc: 0.8188 - val_loss: 0.3118 - val_acc: 0.8826\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3556 - acc: 0.8409 - val_loss: 0.2817 - val_acc: 0.8934\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3293 - acc: 0.8564 - val_loss: 0.2604 - val_acc: 0.9078\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.3093 - acc: 0.8676 - val_loss: 0.2487 - val_acc: 0.9061\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2966 - acc: 0.8745 - val_loss: 0.2437 - val_acc: 0.9081\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2844 - acc: 0.8810 - val_loss: 0.2299 - val_acc: 0.9136\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2748 - acc: 0.8863 - val_loss: 0.2255 - val_acc: 0.9203\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2673 - acc: 0.8901 - val_loss: 0.2203 - val_acc: 0.9203\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2603 - acc: 0.8940 - val_loss: 0.2131 - val_acc: 0.9239\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2538 - acc: 0.8974 - val_loss: 0.2231 - val_acc: 0.9139\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 39s - loss: 0.2483 - acc: 0.9003 - val_loss: 0.2201 - val_acc: 0.9140\n",
      "Epoch 00013: early stopping\n",
      "Test accuracy:  0.947977053007\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.6515 - acc: 0.6032 - val_loss: 0.5855 - val_acc: 0.6555\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4856 - acc: 0.7491 - val_loss: 0.3824 - val_acc: 0.8223\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3763 - acc: 0.8275 - val_loss: 0.3125 - val_acc: 0.8742\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3320 - acc: 0.8546 - val_loss: 0.2676 - val_acc: 0.8961\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3035 - acc: 0.8710 - val_loss: 0.2297 - val_acc: 0.9141\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2816 - acc: 0.8828 - val_loss: 0.2403 - val_acc: 0.9027\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2671 - acc: 0.8902 - val_loss: 0.2135 - val_acc: 0.9206\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2555 - acc: 0.8967 - val_loss: 0.2043 - val_acc: 0.9273\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2455 - acc: 0.9015 - val_loss: 0.1996 - val_acc: 0.9244\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2371 - acc: 0.9059 - val_loss: 0.2033 - val_acc: 0.9222\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2285 - acc: 0.9101 - val_loss: 0.1874 - val_acc: 0.9297\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2222 - acc: 0.9134 - val_loss: 0.1928 - val_acc: 0.9282\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2165 - acc: 0.9162 - val_loss: 0.1751 - val_acc: 0.9380\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2107 - acc: 0.9189 - val_loss: 0.1675 - val_acc: 0.9400\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2069 - acc: 0.9212 - val_loss: 0.1666 - val_acc: 0.9427\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2018 - acc: 0.9236 - val_loss: 0.1800 - val_acc: 0.9337\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1976 - acc: 0.9255 - val_loss: 0.1608 - val_acc: 0.9451\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1948 - acc: 0.9272 - val_loss: 0.1787 - val_acc: 0.9340\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1898 - acc: 0.9292 - val_loss: 0.1529 - val_acc: 0.9496\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1878 - acc: 0.9303 - val_loss: 0.1546 - val_acc: 0.9461\n",
      "Test accuracy:  0.958118484854\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.6433 - acc: 0.6164 - val_loss: 0.5242 - val_acc: 0.7315\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.4163 - acc: 0.8031 - val_loss: 0.3074 - val_acc: 0.8697\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.3188 - acc: 0.8618 - val_loss: 0.2569 - val_acc: 0.8977\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2748 - acc: 0.8852 - val_loss: 0.2310 - val_acc: 0.9092\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2460 - acc: 0.9000 - val_loss: 0.2395 - val_acc: 0.9094\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2252 - acc: 0.9106 - val_loss: 0.2024 - val_acc: 0.9240\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.2103 - acc: 0.9184 - val_loss: 0.2122 - val_acc: 0.9150\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1985 - acc: 0.9245 - val_loss: 0.1777 - val_acc: 0.9353\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1877 - acc: 0.9292 - val_loss: 0.1753 - val_acc: 0.9366\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1798 - acc: 0.9332 - val_loss: 0.1682 - val_acc: 0.9399\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1730 - acc: 0.9362 - val_loss: 0.1639 - val_acc: 0.9404\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1668 - acc: 0.9389 - val_loss: 0.1567 - val_acc: 0.9452\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1619 - acc: 0.9412 - val_loss: 0.1529 - val_acc: 0.9478\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1575 - acc: 0.9433 - val_loss: 0.1503 - val_acc: 0.9481\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1537 - acc: 0.9448 - val_loss: 0.1507 - val_acc: 0.9474\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1502 - acc: 0.9463 - val_loss: 0.1456 - val_acc: 0.9498\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1463 - acc: 0.9482 - val_loss: 0.1440 - val_acc: 0.9503\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1437 - acc: 0.9491 - val_loss: 0.1405 - val_acc: 0.9521\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1410 - acc: 0.9505 - val_loss: 0.1394 - val_acc: 0.9534\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 40s - loss: 0.1389 - acc: 0.9513 - val_loss: 0.1385 - val_acc: 0.9529\n",
      "Test accuracy:  0.962138714126\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.6358 - acc: 0.6210 - val_loss: 0.5089 - val_acc: 0.7461\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.4558 - acc: 0.7712 - val_loss: 0.3450 - val_acc: 0.8517\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3661 - acc: 0.8316 - val_loss: 0.2982 - val_acc: 0.8746\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.3225 - acc: 0.8583 - val_loss: 0.2676 - val_acc: 0.8908\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2958 - acc: 0.8742 - val_loss: 0.2451 - val_acc: 0.9025\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2769 - acc: 0.8848 - val_loss: 0.2275 - val_acc: 0.9131\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2632 - acc: 0.8925 - val_loss: 0.2194 - val_acc: 0.9142\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2529 - acc: 0.8979 - val_loss: 0.2175 - val_acc: 0.9154\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2452 - acc: 0.9021 - val_loss: 0.2250 - val_acc: 0.9138\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2386 - acc: 0.9056 - val_loss: 0.2074 - val_acc: 0.9198\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2328 - acc: 0.9084 - val_loss: 0.2046 - val_acc: 0.9216\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2281 - acc: 0.9107 - val_loss: 0.1914 - val_acc: 0.9296\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2240 - acc: 0.9128 - val_loss: 0.1972 - val_acc: 0.9249\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2206 - acc: 0.9144 - val_loss: 0.1894 - val_acc: 0.9295\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 41s - loss: 0.2173 - acc: 0.9161 - val_loss: 0.1868 - val_acc: 0.9304\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2143 - acc: 0.9175 - val_loss: 0.1793 - val_acc: 0.9348\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2121 - acc: 0.9186 - val_loss: 0.1793 - val_acc: 0.9341\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 43s - loss: 0.2096 - acc: 0.9196 - val_loss: 0.1836 - val_acc: 0.9311\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2067 - acc: 0.9212 - val_loss: 0.1737 - val_acc: 0.9384\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2046 - acc: 0.9223 - val_loss: 0.1742 - val_acc: 0.9382\n",
      "Test accuracy:  0.945912075544\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6777 - acc: 0.5789 - val_loss: 0.6582 - val_acc: 0.6064\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5849 - acc: 0.6846 - val_loss: 0.4452 - val_acc: 0.8074\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4367 - acc: 0.7955 - val_loss: 0.4122 - val_acc: 0.8087\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3657 - acc: 0.8383 - val_loss: 0.3647 - val_acc: 0.8360\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3263 - acc: 0.8608 - val_loss: 0.3071 - val_acc: 0.8783\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2966 - acc: 0.8747 - val_loss: 0.4131 - val_acc: 0.8110\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2768 - acc: 0.8857 - val_loss: 0.2864 - val_acc: 0.8813\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2604 - acc: 0.8921 - val_loss: 0.3316 - val_acc: 0.8453\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2510 - acc: 0.8972 - val_loss: 0.3053 - val_acc: 0.8631\n",
      "Epoch 00008: early stopping\n",
      "Test accuracy:  0.945780484875\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5791 - acc: 0.6791 - val_loss: 0.4135 - val_acc: 0.8087\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3769 - acc: 0.8349 - val_loss: 0.2987 - val_acc: 0.8748\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3203 - acc: 0.8680 - val_loss: 0.2631 - val_acc: 0.8951\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2875 - acc: 0.8856 - val_loss: 0.2427 - val_acc: 0.9066\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2675 - acc: 0.8957 - val_loss: 0.2246 - val_acc: 0.9168\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2553 - acc: 0.9021 - val_loss: 0.2115 - val_acc: 0.9220\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2464 - acc: 0.9066 - val_loss: 0.2058 - val_acc: 0.9252\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2395 - acc: 0.9101 - val_loss: 0.2027 - val_acc: 0.9275\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2338 - acc: 0.9129 - val_loss: 0.2130 - val_acc: 0.9234\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2284 - acc: 0.9154 - val_loss: 0.2042 - val_acc: 0.9269\n",
      "Epoch 00009: early stopping\n",
      "Test accuracy:  0.930108234844\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6792 - acc: 0.5749 - val_loss: 0.6651 - val_acc: 0.5971\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6503 - acc: 0.6165 - val_loss: 0.5876 - val_acc: 0.6933\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5630 - acc: 0.7043 - val_loss: 0.4547 - val_acc: 0.8094\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4813 - acc: 0.7648 - val_loss: 0.3829 - val_acc: 0.8486\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4274 - acc: 0.8002 - val_loss: 0.3444 - val_acc: 0.8501\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3911 - acc: 0.8226 - val_loss: 0.2930 - val_acc: 0.8894\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3635 - acc: 0.8383 - val_loss: 0.2933 - val_acc: 0.8775\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3441 - acc: 0.8496 - val_loss: 0.2866 - val_acc: 0.8779\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3270 - acc: 0.8591 - val_loss: 0.2544 - val_acc: 0.8989\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3133 - acc: 0.8664 - val_loss: 0.2494 - val_acc: 0.8984\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3041 - acc: 0.8717 - val_loss: 0.2610 - val_acc: 0.8914\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2942 - acc: 0.8773 - val_loss: 0.2591 - val_acc: 0.8923\n",
      "Epoch 00011: early stopping\n",
      "Test accuracy:  0.942527148279\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6584 - acc: 0.6021 - val_loss: 0.5764 - val_acc: 0.6954\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.5161 - acc: 0.7309 - val_loss: 0.3896 - val_acc: 0.8332\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.4175 - acc: 0.8013 - val_loss: 0.3298 - val_acc: 0.8545\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3653 - acc: 0.8352 - val_loss: 0.2860 - val_acc: 0.8808\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3348 - acc: 0.8538 - val_loss: 0.3027 - val_acc: 0.8693\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3150 - acc: 0.8651 - val_loss: 0.2397 - val_acc: 0.9080\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.3000 - acc: 0.8735 - val_loss: 0.2387 - val_acc: 0.9067\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2892 - acc: 0.8798 - val_loss: 0.2376 - val_acc: 0.9055\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2787 - acc: 0.8852 - val_loss: 0.2134 - val_acc: 0.9192\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 42s - loss: 0.2696 - acc: 0.8899 - val_loss: 0.2154 - val_acc: 0.9167\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2616 - acc: 0.8945 - val_loss: 0.2162 - val_acc: 0.9172\n",
      "Epoch 00010: early stopping\n",
      "Test accuracy:  0.932331891197\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6679 - acc: 0.5896 - val_loss: 0.6387 - val_acc: 0.6318\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5822 - acc: 0.6758 - val_loss: 0.4861 - val_acc: 0.7781\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4811 - acc: 0.7591 - val_loss: 0.4144 - val_acc: 0.8082\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4099 - acc: 0.8068 - val_loss: 0.4935 - val_acc: 0.7156\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3648 - acc: 0.8344 - val_loss: 0.4759 - val_acc: 0.7232\n",
      "Epoch 00004: early stopping\n",
      "Test accuracy:  0.899081341033\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 45s - loss: 1.1841 - acc: 0.4994 - val_loss: 0.6815 - val_acc: 0.5643\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6789 - val_acc: 0.5661\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6848 - acc: 0.5609 - val_loss: 0.6821 - val_acc: 0.5687\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6837 - acc: 0.5643 - val_loss: 0.6924 - val_acc: 0.5425\n",
      "Epoch 00003: early stopping\n",
      "Test accuracy:  0.237379615933\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5215 - acc: 0.7251 - val_loss: 0.3453 - val_acc: 0.8583\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3529 - acc: 0.8427 - val_loss: 0.2588 - val_acc: 0.9002\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2894 - acc: 0.8779 - val_loss: 0.2175 - val_acc: 0.9200\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2557 - acc: 0.8953 - val_loss: 0.2059 - val_acc: 0.9219\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2353 - acc: 0.9060 - val_loss: 0.2025 - val_acc: 0.9220\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2197 - acc: 0.9135 - val_loss: 0.1941 - val_acc: 0.9251\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2092 - acc: 0.9183 - val_loss: 0.1926 - val_acc: 0.9263\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2003 - acc: 0.9228 - val_loss: 0.1859 - val_acc: 0.9302\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.1933 - acc: 0.9260 - val_loss: 0.2141 - val_acc: 0.9184\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.1880 - acc: 0.9285 - val_loss: 0.1835 - val_acc: 0.9306\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.1830 - acc: 0.9309 - val_loss: 0.1748 - val_acc: 0.9347\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.1786 - acc: 0.9328 - val_loss: 0.1590 - val_acc: 0.9430\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.1753 - acc: 0.9344 - val_loss: 0.1637 - val_acc: 0.9402\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.1724 - acc: 0.9357 - val_loss: 0.1603 - val_acc: 0.9423\n",
      "Epoch 00013: early stopping\n",
      "Test accuracy:  0.962837672097\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6748 - acc: 0.5785 - val_loss: 0.6638 - val_acc: 0.5924\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6605 - acc: 0.6024 - val_loss: 0.6342 - val_acc: 0.6318\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6195 - acc: 0.6303 - val_loss: 0.5865 - val_acc: 0.6547\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5946 - acc: 0.6522 - val_loss: 0.5567 - val_acc: 0.6975\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5785 - acc: 0.6709 - val_loss: 0.5354 - val_acc: 0.7215\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5580 - acc: 0.6933 - val_loss: 0.4811 - val_acc: 0.7702\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5336 - acc: 0.7157 - val_loss: 0.4521 - val_acc: 0.7825\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5124 - acc: 0.7332 - val_loss: 0.4494 - val_acc: 0.7882\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4935 - acc: 0.7466 - val_loss: 0.4449 - val_acc: 0.7823\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4822 - acc: 0.7552 - val_loss: 0.4188 - val_acc: 0.7997\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4718 - acc: 0.7627 - val_loss: 0.4025 - val_acc: 0.8139\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4639 - acc: 0.7692 - val_loss: 0.3938 - val_acc: 0.8153\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4572 - acc: 0.7744 - val_loss: 0.4102 - val_acc: 0.8007\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4509 - acc: 0.7786 - val_loss: 0.3847 - val_acc: 0.8209\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4456 - acc: 0.7830 - val_loss: 0.3833 - val_acc: 0.8239\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 53s - loss: 0.4414 - acc: 0.7859 - val_loss: 0.3760 - val_acc: 0.8300\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 87s - loss: 0.4370 - acc: 0.7883 - val_loss: 0.3751 - val_acc: 0.8258\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 86s - loss: 0.4327 - acc: 0.7913 - val_loss: 0.3626 - val_acc: 0.8413\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 88s - loss: 0.4293 - acc: 0.7937 - val_loss: 0.3685 - val_acc: 0.8276\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 88s - loss: 0.4256 - acc: 0.7960 - val_loss: 0.3628 - val_acc: 0.8360\n",
      "Epoch 00019: early stopping\n",
      "Test accuracy:  0.827216658068\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 60s - loss: 0.6607 - acc: 0.5984 - val_loss: 0.5747 - val_acc: 0.6945\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.4873 - acc: 0.7596 - val_loss: 0.3634 - val_acc: 0.8392\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3720 - acc: 0.8326 - val_loss: 0.3080 - val_acc: 0.8683\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3190 - acc: 0.8628 - val_loss: 0.2538 - val_acc: 0.9012\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2909 - acc: 0.8781 - val_loss: 0.2514 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2701 - acc: 0.8892 - val_loss: 0.2206 - val_acc: 0.9177\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2568 - acc: 0.8962 - val_loss: 0.2150 - val_acc: 0.9193\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2454 - acc: 0.9021 - val_loss: 0.2045 - val_acc: 0.9250\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2360 - acc: 0.9070 - val_loss: 0.1989 - val_acc: 0.9294\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2272 - acc: 0.9114 - val_loss: 0.1986 - val_acc: 0.9284\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2216 - acc: 0.9142 - val_loss: 0.1781 - val_acc: 0.9379\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2148 - acc: 0.9172 - val_loss: 0.1766 - val_acc: 0.9396\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2104 - acc: 0.9196 - val_loss: 0.1710 - val_acc: 0.9405\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2053 - acc: 0.9220 - val_loss: 0.1698 - val_acc: 0.9405\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2008 - acc: 0.9242 - val_loss: 0.1774 - val_acc: 0.9371\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.1969 - acc: 0.9260 - val_loss: 0.1669 - val_acc: 0.9424\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.1938 - acc: 0.9275 - val_loss: 0.1538 - val_acc: 0.9478\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.1905 - acc: 0.9291 - val_loss: 0.1593 - val_acc: 0.9480\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.1877 - acc: 0.9305 - val_loss: 0.1564 - val_acc: 0.9461\n",
      "Epoch 00018: early stopping\n",
      "Test accuracy:  0.953569638663\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.6309 - acc: 0.6561 - val_loss: 0.3927 - val_acc: 0.8305\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4868 - acc: 0.7945 - val_loss: 0.3273 - val_acc: 0.8775\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4470 - acc: 0.8302 - val_loss: 0.2603 - val_acc: 0.8955\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3887 - acc: 0.8428 - val_loss: 0.2497 - val_acc: 0.8969\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2803 - acc: 0.8846 - val_loss: 0.2114 - val_acc: 0.9171\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2739 - acc: 0.8842 - val_loss: 0.2216 - val_acc: 0.9112\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2500 - acc: 0.8984 - val_loss: 0.1870 - val_acc: 0.9296\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2378 - acc: 0.9064 - val_loss: 0.1915 - val_acc: 0.9288\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3655 - acc: 0.8588 - val_loss: 0.1828 - val_acc: 0.9380\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2311 - acc: 0.9114 - val_loss: 0.1864 - val_acc: 0.9288\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 44s - loss: 0.2294 - acc: 0.9119 - val_loss: 0.2873 - val_acc: 0.9166\n",
      "Epoch 00010: early stopping\n",
      "Test accuracy:  0.951870175287\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.6868 - acc: 0.5539 - val_loss: 0.6787 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6761 - acc: 0.5790 - val_loss: 0.6720 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6727 - acc: 0.5845 - val_loss: 0.6686 - val_acc: 0.5964\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6688 - acc: 0.5907 - val_loss: 0.6622 - val_acc: 0.6086\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6636 - acc: 0.5985 - val_loss: 0.6608 - val_acc: 0.6267\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6576 - acc: 0.6083 - val_loss: 0.6534 - val_acc: 0.6420\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6515 - acc: 0.6192 - val_loss: 0.6384 - val_acc: 0.6606\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6458 - acc: 0.6280 - val_loss: 0.6346 - val_acc: 0.6741\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6400 - acc: 0.6358 - val_loss: 0.6245 - val_acc: 0.6932\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6337 - acc: 0.6447 - val_loss: 0.6139 - val_acc: 0.7060\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6284 - acc: 0.6509 - val_loss: 0.6057 - val_acc: 0.7248\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6224 - acc: 0.6577 - val_loss: 0.5966 - val_acc: 0.7255\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6174 - acc: 0.6635 - val_loss: 0.5878 - val_acc: 0.7372\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6133 - acc: 0.6680 - val_loss: 0.5764 - val_acc: 0.7443\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6085 - acc: 0.6721 - val_loss: 0.5673 - val_acc: 0.7506\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.6043 - acc: 0.6770 - val_loss: 0.5673 - val_acc: 0.7617\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.6004 - acc: 0.6802 - val_loss: 0.5600 - val_acc: 0.7645\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5981 - acc: 0.6828 - val_loss: 0.5564 - val_acc: 0.7751\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5944 - acc: 0.6857 - val_loss: 0.5515 - val_acc: 0.7747\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.5933 - acc: 0.6869 - val_loss: 0.5470 - val_acc: 0.7772\n",
      "Test accuracy:  0.723423101834\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6669 - acc: 0.5902 - val_loss: 0.6243 - val_acc: 0.6482\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5308 - acc: 0.7181 - val_loss: 0.4242 - val_acc: 0.7912\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.4078 - acc: 0.8087 - val_loss: 0.3118 - val_acc: 0.8699\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3527 - acc: 0.8434 - val_loss: 0.2853 - val_acc: 0.8818\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.3200 - acc: 0.8627 - val_loss: 0.2566 - val_acc: 0.8967\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2982 - acc: 0.8754 - val_loss: 0.2168 - val_acc: 0.9214\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2820 - acc: 0.8839 - val_loss: 0.2636 - val_acc: 0.8926\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 43s - loss: 0.2685 - acc: 0.8908 - val_loss: 0.2202 - val_acc: 0.9161\n",
      "Epoch 00007: early stopping\n",
      "Test accuracy:  0.92595193648\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.6755 - acc: 0.5856 - val_loss: 0.6327 - val_acc: 0.6397\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.5802 - acc: 0.6863 - val_loss: 0.4573 - val_acc: 0.7926\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4767 - acc: 0.7641 - val_loss: 0.3874 - val_acc: 0.8330\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.4122 - acc: 0.8054 - val_loss: 0.3324 - val_acc: 0.8569\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.3756 - acc: 0.8288 - val_loss: 0.3119 - val_acc: 0.8629\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3470 - acc: 0.8460 - val_loss: 0.3379 - val_acc: 0.8803\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3336 - acc: 0.8540 - val_loss: 0.2611 - val_acc: 0.9009\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3142 - acc: 0.8633 - val_loss: 0.2689 - val_acc: 0.8976\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3064 - acc: 0.8672 - val_loss: 0.2368 - val_acc: 0.9085\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2925 - acc: 0.8738 - val_loss: 0.2278 - val_acc: 0.9153\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2833 - acc: 0.8793 - val_loss: 0.2320 - val_acc: 0.9095\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2748 - acc: 0.8846 - val_loss: 0.2196 - val_acc: 0.9115\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2707 - acc: 0.8827 - val_loss: 0.2094 - val_acc: 0.9202\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2651 - acc: 0.8863 - val_loss: 0.2067 - val_acc: 0.9187\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2590 - acc: 0.8898 - val_loss: 0.1958 - val_acc: 0.9258\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2556 - acc: 0.8900 - val_loss: 0.1979 - val_acc: 0.9272\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2495 - acc: 0.8974 - val_loss: 0.1918 - val_acc: 0.9281\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2428 - acc: 0.8979 - val_loss: 0.1894 - val_acc: 0.9337\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 44s - loss: 0.2400 - acc: 0.8995 - val_loss: 0.1746 - val_acc: 0.9410\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2343 - acc: 0.9035 - val_loss: 0.1952 - val_acc: 0.9255\n",
      "Test accuracy:  0.952028079041\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.6748 - acc: 0.5797 - val_loss: 0.6621 - val_acc: 0.5993\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.6462 - acc: 0.6268 - val_loss: 0.5728 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5701 - acc: 0.6934 - val_loss: 0.4770 - val_acc: 0.7507\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5109 - acc: 0.7329 - val_loss: 0.4217 - val_acc: 0.7914\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4762 - acc: 0.7599 - val_loss: 0.3861 - val_acc: 0.8204\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4506 - acc: 0.7805 - val_loss: 0.3591 - val_acc: 0.8457\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4307 - acc: 0.7945 - val_loss: 0.3311 - val_acc: 0.8573\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4136 - acc: 0.8064 - val_loss: 0.3361 - val_acc: 0.8559\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4001 - acc: 0.8160 - val_loss: 0.3218 - val_acc: 0.8688\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3868 - acc: 0.8245 - val_loss: 0.3066 - val_acc: 0.8760\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3778 - acc: 0.8302 - val_loss: 0.3042 - val_acc: 0.8748\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3693 - acc: 0.8357 - val_loss: 0.2852 - val_acc: 0.8796\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3600 - acc: 0.8417 - val_loss: 0.2872 - val_acc: 0.8804\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3533 - acc: 0.8463 - val_loss: 0.2904 - val_acc: 0.8808\n",
      "Epoch 00013: early stopping\n",
      "Test accuracy:  0.876961603814\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 27s - loss: 0.6355 - acc: 0.6311 - val_loss: 0.5145 - val_acc: 0.7712\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.5267 - acc: 0.7352 - val_loss: 0.4083 - val_acc: 0.8397\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.4638 - acc: 0.7786 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.4181 - acc: 0.8075 - val_loss: 0.3154 - val_acc: 0.8783\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3862 - acc: 0.8263 - val_loss: 0.2897 - val_acc: 0.8907\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3648 - acc: 0.8386 - val_loss: 0.2782 - val_acc: 0.8923\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3493 - acc: 0.8475 - val_loss: 0.2973 - val_acc: 0.8733\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3366 - acc: 0.8548 - val_loss: 0.2736 - val_acc: 0.8908\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3255 - acc: 0.8607 - val_loss: 0.2597 - val_acc: 0.8959\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3173 - acc: 0.8653 - val_loss: 0.2796 - val_acc: 0.8814\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3108 - acc: 0.8688 - val_loss: 0.2346 - val_acc: 0.9115\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3043 - acc: 0.8723 - val_loss: 0.2371 - val_acc: 0.9076\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2996 - acc: 0.8749 - val_loss: 0.2423 - val_acc: 0.9046\n",
      "Epoch 00012: early stopping\n",
      "Test accuracy:  0.945759814207\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.6732 - acc: 0.5806 - val_loss: 0.6632 - val_acc: 0.5962\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.6606 - acc: 0.6015 - val_loss: 0.6351 - val_acc: 0.6274\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.6190 - acc: 0.6271 - val_loss: 0.5903 - val_acc: 0.6517\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5969 - acc: 0.6464 - val_loss: 0.5728 - val_acc: 0.6789\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5838 - acc: 0.6632 - val_loss: 0.5506 - val_acc: 0.7008\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5717 - acc: 0.6785 - val_loss: 0.5195 - val_acc: 0.7421\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5588 - acc: 0.6919 - val_loss: 0.5085 - val_acc: 0.7465\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5468 - acc: 0.7033 - val_loss: 0.4845 - val_acc: 0.7695\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5351 - acc: 0.7140 - val_loss: 0.4666 - val_acc: 0.7829\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5252 - acc: 0.7224 - val_loss: 0.4444 - val_acc: 0.7999\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.5168 - acc: 0.7289 - val_loss: 0.4400 - val_acc: 0.8006\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5086 - acc: 0.7357 - val_loss: 0.4311 - val_acc: 0.8095\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5011 - acc: 0.7423 - val_loss: 0.4276 - val_acc: 0.8074\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4956 - acc: 0.7472 - val_loss: 0.4133 - val_acc: 0.8156\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4885 - acc: 0.7527 - val_loss: 0.4033 - val_acc: 0.8229\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4818 - acc: 0.7580 - val_loss: 0.3974 - val_acc: 0.8260\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4764 - acc: 0.7621 - val_loss: 0.3956 - val_acc: 0.8225\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.4712 - acc: 0.7655 - val_loss: 0.3890 - val_acc: 0.8257\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4665 - acc: 0.7693 - val_loss: 0.3910 - val_acc: 0.8249\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4637 - acc: 0.7708 - val_loss: 0.3877 - val_acc: 0.8182\n",
      "Test accuracy:  0.814130979546\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 28s - loss: 0.6787 - acc: 0.5777 - val_loss: 0.6654 - val_acc: 0.5928\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.6464 - acc: 0.6167 - val_loss: 0.5850 - val_acc: 0.6773\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.5485 - acc: 0.7068 - val_loss: 0.4585 - val_acc: 0.7910\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.4471 - acc: 0.7842 - val_loss: 0.3364 - val_acc: 0.8640\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3942 - acc: 0.8183 - val_loss: 0.3047 - val_acc: 0.8722\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3480 - acc: 0.8458 - val_loss: 0.2861 - val_acc: 0.8763\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3310 - acc: 0.8540 - val_loss: 0.2451 - val_acc: 0.9066\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3062 - acc: 0.8683 - val_loss: 0.2622 - val_acc: 0.8905\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2885 - acc: 0.8779 - val_loss: 0.2229 - val_acc: 0.9148\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2703 - acc: 0.8861 - val_loss: 0.2082 - val_acc: 0.9240\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2610 - acc: 0.8913 - val_loss: 0.1973 - val_acc: 0.9234\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2493 - acc: 0.8964 - val_loss: 0.2007 - val_acc: 0.9278\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2342 - acc: 0.9061 - val_loss: 0.1927 - val_acc: 0.9264\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2262 - acc: 0.9100 - val_loss: 0.2012 - val_acc: 0.9252\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2215 - acc: 0.9123 - val_loss: 0.1781 - val_acc: 0.9322\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2240 - acc: 0.9089 - val_loss: 0.1827 - val_acc: 0.9334\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2122 - acc: 0.9166 - val_loss: 0.1795 - val_acc: 0.9366\n",
      "Epoch 00016: early stopping\n",
      "Test accuracy:  0.957395586149\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.6545 - acc: 0.6040 - val_loss: 0.5884 - val_acc: 0.6642\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.5106 - acc: 0.7273 - val_loss: 0.4059 - val_acc: 0.8048\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.4072 - acc: 0.8017 - val_loss: 0.3475 - val_acc: 0.8399\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3662 - acc: 0.8307 - val_loss: 0.3070 - val_acc: 0.8701\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.3379 - acc: 0.8501 - val_loss: 0.3002 - val_acc: 0.8690\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860277/860277 [==============================] - 45s - loss: 0.3187 - acc: 0.8617 - val_loss: 0.2741 - val_acc: 0.8844\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.3048 - acc: 0.8697 - val_loss: 0.2696 - val_acc: 0.8848\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2959 - acc: 0.8749 - val_loss: 0.2651 - val_acc: 0.8896\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2888 - acc: 0.8789 - val_loss: 0.2598 - val_acc: 0.8906\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2827 - acc: 0.8820 - val_loss: 0.2473 - val_acc: 0.8993\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2772 - acc: 0.8852 - val_loss: 0.2435 - val_acc: 0.9018\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2729 - acc: 0.8880 - val_loss: 0.2470 - val_acc: 0.8986\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2684 - acc: 0.8904 - val_loss: 0.2355 - val_acc: 0.9032\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2639 - acc: 0.8930 - val_loss: 0.2337 - val_acc: 0.9060\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2611 - acc: 0.8948 - val_loss: 0.2318 - val_acc: 0.9061\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2572 - acc: 0.8968 - val_loss: 0.2254 - val_acc: 0.9111\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2547 - acc: 0.8985 - val_loss: 0.2295 - val_acc: 0.9076\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2521 - acc: 0.8998 - val_loss: 0.2187 - val_acc: 0.9154\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2490 - acc: 0.9016 - val_loss: 0.2158 - val_acc: 0.9165\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 45s - loss: 0.2474 - acc: 0.9024 - val_loss: 0.2161 - val_acc: 0.9183\n",
      "Test accuracy:  0.922667031828\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 27s - loss: 0.6580 - acc: 0.6040 - val_loss: 0.6180 - val_acc: 0.6493\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.5094 - acc: 0.7399 - val_loss: 0.3838 - val_acc: 0.8308\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3851 - acc: 0.8258 - val_loss: 0.3171 - val_acc: 0.8661\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.3291 - acc: 0.8561 - val_loss: 0.2796 - val_acc: 0.8869\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2899 - acc: 0.8764 - val_loss: 0.2435 - val_acc: 0.9039\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 25s - loss: 0.2629 - acc: 0.8910 - val_loss: 0.2240 - val_acc: 0.9141\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2434 - acc: 0.9007 - val_loss: 0.2149 - val_acc: 0.9182\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2282 - acc: 0.9083 - val_loss: 0.1998 - val_acc: 0.9263\n",
      "Epoch 9/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2156 - acc: 0.9148 - val_loss: 0.1900 - val_acc: 0.9302\n",
      "Epoch 10/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.2058 - acc: 0.9194 - val_loss: 0.1881 - val_acc: 0.9313\n",
      "Epoch 11/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1967 - acc: 0.9239 - val_loss: 0.1846 - val_acc: 0.9316\n",
      "Epoch 12/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1898 - acc: 0.9273 - val_loss: 0.1719 - val_acc: 0.9377\n",
      "Epoch 13/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1831 - acc: 0.9303 - val_loss: 0.1635 - val_acc: 0.9431\n",
      "Epoch 14/20\n",
      "860277/860277 [==============================] - 25s - loss: 0.1778 - acc: 0.9329 - val_loss: 0.1601 - val_acc: 0.9432\n",
      "Epoch 15/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1720 - acc: 0.9352 - val_loss: 0.1589 - val_acc: 0.9448\n",
      "Epoch 16/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1669 - acc: 0.9376 - val_loss: 0.1586 - val_acc: 0.9451\n",
      "Epoch 17/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1625 - acc: 0.9394 - val_loss: 0.1545 - val_acc: 0.9467\n",
      "Epoch 18/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1586 - acc: 0.9413 - val_loss: 0.1468 - val_acc: 0.9492\n",
      "Epoch 19/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1547 - acc: 0.9430 - val_loss: 0.1482 - val_acc: 0.9496\n",
      "Epoch 20/20\n",
      "860277/860277 [==============================] - 26s - loss: 0.1512 - acc: 0.9442 - val_loss: 0.1441 - val_acc: 0.9514\n",
      "Test accuracy:  0.961829972834\n",
      "Train on 860277 samples, validate on 286759 samples\n",
      "Epoch 1/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.5433 - acc: 0.7009 - val_loss: 0.3382 - val_acc: 0.8647\n",
      "Epoch 2/20\n",
      "860277/860277 [==============================] - 47s - loss: 0.3352 - acc: 0.8529 - val_loss: 0.2495 - val_acc: 0.9061\n",
      "Epoch 3/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2771 - acc: 0.8846 - val_loss: 0.2230 - val_acc: 0.9128\n",
      "Epoch 4/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2459 - acc: 0.9007 - val_loss: 0.1956 - val_acc: 0.9291\n",
      "Epoch 5/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2258 - acc: 0.9108 - val_loss: 0.1823 - val_acc: 0.9336\n",
      "Epoch 6/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2119 - acc: 0.9178 - val_loss: 0.1703 - val_acc: 0.9391\n",
      "Epoch 7/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.2018 - acc: 0.9229 - val_loss: 0.1731 - val_acc: 0.9387\n",
      "Epoch 8/20\n",
      "860277/860277 [==============================] - 46s - loss: 0.1934 - acc: 0.9272 - val_loss: 0.1718 - val_acc: 0.9378\n",
      "Epoch 00007: early stopping\n",
      "Test accuracy:  0.953034973057\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='dlsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Dense',\n",
       "  'config': {'activation': 'sigmoid',\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 198),\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'dtype': 'float32',\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_53',\n",
       "   'trainable': True,\n",
       "   'units': 512,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_27',\n",
       "   'rate': 0.10466253116015645,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'tanh',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_54',\n",
       "   'trainable': True,\n",
       "   'units': 256,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_28',\n",
       "   'rate': 0.006030364039549152,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_55',\n",
       "   'trainable': True,\n",
       "   'units': 128,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'sigmoid',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_56',\n",
       "   'trainable': True,\n",
       "   'units': 1,\n",
       "   'use_bias': True}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-80856f351247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \" got n_splits={0}.\".format(n_splits))\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1."
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((X_train,X_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.hstack((y_train,y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/6]\n",
      "Train on 955862 samples, validate on 191174 samples\n",
      "Epoch 1/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0942 - acc: 0.9658 - val_loss: 0.0990 - val_acc: 0.9668\n",
      "Epoch 2/20\n",
      "955862/955862 [==============================] - 31s - loss: 0.0920 - acc: 0.9667 - val_loss: 0.0949 - val_acc: 0.9688\n",
      "Epoch 3/20\n",
      "955862/955862 [==============================] - 31s - loss: 0.0901 - acc: 0.9675 - val_loss: 0.0948 - val_acc: 0.9689\n",
      "Epoch 4/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0886 - acc: 0.9680 - val_loss: 0.0945 - val_acc: 0.9687\n",
      "Epoch 5/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0867 - acc: 0.9685 - val_loss: 0.0945 - val_acc: 0.9691\n",
      "Epoch 6/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0850 - acc: 0.9693 - val_loss: 0.0942 - val_acc: 0.9695\n",
      "Epoch 7/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0835 - acc: 0.9697 - val_loss: 0.0937 - val_acc: 0.9693\n",
      "Epoch 8/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0815 - acc: 0.9706 - val_loss: 0.0921 - val_acc: 0.9703\n",
      "Epoch 9/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0802 - acc: 0.9709 - val_loss: 0.0904 - val_acc: 0.9707\n",
      "Epoch 10/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0789 - acc: 0.9713 - val_loss: 0.0894 - val_acc: 0.9714\n",
      "Epoch 11/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0779 - acc: 0.9719 - val_loss: 0.0909 - val_acc: 0.9703\n",
      "Epoch 12/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0766 - acc: 0.9723 - val_loss: 0.0914 - val_acc: 0.9709\n",
      "Epoch 00011: early stopping\n",
      "gini metric: 0.983480862536\n",
      "\n",
      "[Fold 1/6 Prediciton:]\n",
      "891616/892816 [============================>.] - ETA: 0s[Fold 2/6]\n",
      "Train on 955862 samples, validate on 191174 samples\n",
      "Epoch 1/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0581 - val_acc: 0.9799\n",
      "Epoch 2/20\n",
      "955862/955862 [==============================] - 32s - loss: 0.0800 - acc: 0.9715 - val_loss: 0.0589 - val_acc: 0.9788\n",
      "Epoch 3/20\n",
      "955862/955862 [==============================] - 31s - loss: 0.0781 - acc: 0.9718 - val_loss: 0.0582 - val_acc: 0.9799\n",
      "Epoch 00002: early stopping\n",
      "gini metric: 0.994438236991\n",
      "\n",
      "[Fold 2/6 Prediciton:]\n",
      "890976/892816 [============================>.] - ETA: 0s[Fold 3/6]\n",
      "Train on 955864 samples, validate on 191172 samples\n",
      "Epoch 1/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0786 - acc: 0.9716 - val_loss: 0.0522 - val_acc: 0.9828\n",
      "Epoch 2/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0766 - acc: 0.9725 - val_loss: 0.0533 - val_acc: 0.9818\n",
      "Epoch 3/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0750 - acc: 0.9727 - val_loss: 0.0539 - val_acc: 0.9822\n",
      "Epoch 00002: early stopping\n",
      "gini metric: 0.995542596779\n",
      "\n",
      "[Fold 3/6 Prediciton:]\n",
      "890720/892816 [============================>.] - ETA: 0s[Fold 4/6]\n",
      "Train on 955864 samples, validate on 191172 samples\n",
      "Epoch 1/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0756 - acc: 0.9726 - val_loss: 0.0499 - val_acc: 0.9828\n",
      "Epoch 2/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0730 - acc: 0.9738 - val_loss: 0.0494 - val_acc: 0.9831\n",
      "Epoch 3/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0722 - acc: 0.9739 - val_loss: 0.0529 - val_acc: 0.9819\n",
      "Epoch 4/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0706 - acc: 0.9745 - val_loss: 0.0520 - val_acc: 0.9820\n",
      "Epoch 00003: early stopping\n",
      "gini metric: 0.995436624736\n",
      "\n",
      "[Fold 4/6 Prediciton:]\n",
      "892384/892816 [============================>.] - ETA: 0s[Fold 5/6]\n",
      "Train on 955864 samples, validate on 191172 samples\n",
      "Epoch 1/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0718 - acc: 0.9741 - val_loss: 0.0464 - val_acc: 0.9842\n",
      "Epoch 2/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0701 - acc: 0.9746 - val_loss: 0.0486 - val_acc: 0.9836\n",
      "Epoch 3/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0690 - acc: 0.9749 - val_loss: 0.0486 - val_acc: 0.9836\n",
      "Epoch 00002: early stopping\n",
      "gini metric: 0.996399488461\n",
      "\n",
      "[Fold 5/6 Prediciton:]\n",
      "892256/892816 [============================>.] - ETA: 0s[Fold 6/6]\n",
      "Train on 955864 samples, validate on 191172 samples\n",
      "Epoch 1/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0695 - acc: 0.9749 - val_loss: 0.0422 - val_acc: 0.9856\n",
      "Epoch 2/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0676 - acc: 0.9755 - val_loss: 0.0456 - val_acc: 0.9838\n",
      "Epoch 3/20\n",
      "955864/955864 [==============================] - 32s - loss: 0.0666 - acc: 0.9758 - val_loss: 0.0471 - val_acc: 0.9836\n",
      "Epoch 00002: early stopping\n",
      "gini metric: 0.996449600189\n",
      "\n",
      "[Fold 6/6 Prediciton:]\n",
      "890944/892816 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    #class_weight = {1 : (len(y_train) - sum(y_train))/y_train.shape[0], 0: sum(y_train)/y_train.shape[0]}\n",
    "    ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "    history = best_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,validation_data=(X_valid,y_valid), callbacks=[ES,metrics])#, class_weight = class_weight\n",
    "    print('gini metric:', metrics.ginis)\n",
    "    print()\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test =best_model.predict_proba(X_test)[:,0]\n",
    "    sub['target'] += p_test/kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 446409 samples, validate on 191172 samples\n",
      "Epoch 1/20\n",
      "446409/446409 [==============================] - 18s - loss: 0.0217 - acc: 0.8678 - val_loss: 0.1568 - val_acc: 0.9336\n",
      "Epoch 2/20\n",
      "446409/446409 [==============================] - 18s - loss: 0.0223 - acc: 0.8567 - val_loss: 0.1481 - val_acc: 0.9385\n",
      "Epoch 3/20\n",
      "446409/446409 [==============================] - 18s - loss: 0.0222 - acc: 0.8569 - val_loss: 0.1468 - val_acc: 0.9376\n",
      "Epoch 4/20\n",
      "446409/446409 [==============================] - 18s - loss: 0.0217 - acc: 0.8596 - val_loss: 0.1553 - val_acc: 0.9329\n",
      "Epoch 5/20\n",
      "446409/446409 [==============================] - 18s - loss: 0.0214 - acc: 0.8612 - val_loss: 0.1913 - val_acc: 0.9137\n",
      "Epoch 00004: early stopping\n",
      "gini metric: 0.994863668361\n",
      "\n",
      "892480/892816 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "class_weight = {1 : (len(y_train) - sum(y_train))/y_train.shape[0], 0: sum(y_train)/y_train.shape[0]}\n",
    "history = best_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,validation_data=(X_valid,y_valid), callbacks=[ES,metrics], class_weight = class_weight)#, class_weight = class_weight\n",
    "print('gini metric:', metrics.ginis)\n",
    "print()\n",
    "# Predict on our test data\n",
    "sub['target'] = best_model.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'DL_model_'+str(dt.datetime.now()).replace(' ','_').replace(':','').replace('.','')\n",
    "sub.id = sub.id.astype('Int32')\n",
    "sub.to_csv('../output/'+filename+'.csv', index=False)\n",
    "#test = np.load('../output/params.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
