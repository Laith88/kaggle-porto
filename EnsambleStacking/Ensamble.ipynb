{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    #assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)['target'].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': 'target', 'target': 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': 'target', 'target': 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "    #'ps_reg_F',\n",
    "    #'ps_reg_M'\n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported data\n",
      "begining feature engineering\n",
      "\n",
      "\tCurrent feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0\n",
      "\tCurrent feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0\n",
      "Done adding features, smoothing categorical featuers now.. \n",
      "Done ... I can start learning now.. \n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('../../data/train.csv', na_values=\"-1\") # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('../../data/test.csv', na_values=\"-1\")\n",
    "print('imported data')\n",
    "\n",
    "# Process data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "print('begining feature engineering')\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('\\n\\tCurrent feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "print('\\nDone adding features, smoothing categorical featuers now.. ')\n",
    "#target categoricals \n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]\n",
    "\n",
    "for f in f_cats:\n",
    "    X[f + \"_avg\"], test_df[f + \"_avg\"] = target_encode(trn_series=X[f],\n",
    "                                         tst_series=test_df[f],\n",
    "                                         target=train_df['target'],\n",
    "                                         min_samples_leaf=200,\n",
    "                                         smoothing=10,\n",
    "                                         noise_level=0)\n",
    "print('Done ... I can start learning now.. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(-1)\n",
    "test_df = test_df.fillna(-1)\n",
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnsambleHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state']= seed\n",
    "        self.clf = clf(**params)\n",
    "        #self.clf = CalibratedClassifierCV(clf(**params), cv=5)\n",
    "#         if clf != XGBClassifier:\n",
    "#             self.clf = CalibratedClassifierCV(clf(**params), cv=5)\n",
    "#         else:\n",
    "#             self.clf = clf(**params)\n",
    "    \n",
    "    def train(self,X_train, y_train):\n",
    "        #cccv = CalibratedClassifierCV(self.clf, cv=StratifiedKFold(y_train, n_folds=5, random_state=42, shuffle=True))\n",
    "        #cccv.fit(X_train, y_train)\n",
    "        self.clf.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clf.fit(x, y)\n",
    "    \n",
    "    def features_importance(self, x, y):\n",
    "        print(self.clf.fit(x,y).features_importance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, X_train, y_train, X_test, K =5, SEED =43 ):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    kf = KFold(n_splits = K, random_state = 42, shuffle = True)\n",
    "    oof_train = np.zeros((X_train.shape[0],))\n",
    "    oof_test  = np.zeros((X_test.shape[0],))\n",
    "    oof_test_skf = np.empty((K, X_test.shape[0]))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_k = X_train[train_index]\n",
    "        y_train_k = y_train[train_index]\n",
    "        X_test_k =  X_train[test_index]\n",
    "        y_test_k = y_train[test_index]\n",
    "        \n",
    "        clf.train(X_train_k, y_train_k)\n",
    "        \n",
    "        train_pred = clf.predict_proba(X_train_k)[:,1]\n",
    "        test_pred = clf.predict_proba(X_test_k)[:,1]\n",
    "        oof_train[test_index] = clf.predict_proba(X_test_k)[:,1]\n",
    "        oof_test_skf[i,:] = clf.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        print( \"Fold {}:  Train-Gini = {:06.5f}, Eval-Gini = {:06.5f}\".format(i,eval_gini(y_train_k, train_pred),eval_gini(y_test_k, test_pred)))\n",
    "    \n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blend(clf, X_train, y_train, X_test, K =5, SEED =43 ):\n",
    "    y_test_pred = 0\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_k = X_train[train_index]\n",
    "        y_train_k = y_train[train_index]\n",
    "        X_test_k =  X_train[test_index]\n",
    "        y_test_k = y_train[test_index]\n",
    "        \n",
    "        clf.fit(X_train_k, y_train_k)\n",
    "        train_pred = clf.predict_proba(X_train_k)[:,1]\n",
    "        pred = clf.predict_proba(X_test_k)[:,1]\n",
    "        y_test_pred += clf.predict_proba(X_test)[:,1]/K\n",
    "        \n",
    "        print( \"Fold {}:  Train-Gini = {:06.5f}, Eval-Gini = {:06.5f}\".format(i,eval_gini(y_train_k, train_pred),eval_gini(y_test_k, pred)))\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = X.values\n",
    "y_train = y.values\n",
    "x_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "     'n_jobs': -1,\n",
    "     'criterion': 'gini',\n",
    "     'max_depth': 20,\n",
    "     'max_features': 4,\n",
    "     'max_leaf_nodes': 20,\n",
    "     'min_samples_leaf': 0.1,\n",
    "     'min_samples_split': 0.15,\n",
    "     'n_estimators': 54,\n",
    "     'class_weight':'balanced_subsample'\n",
    "}\n",
    "\n",
    "\n",
    "#Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':60,\n",
    "    'max_depth': 8,\n",
    "    'min_weight_fraction_leaf':0.0,\n",
    "    'min_samples_leaf': 3,\n",
    "    'verbose': 0,\n",
    "    'bootstrap': False,\n",
    "    #'min_samples_split': 4,\n",
    "    'max_features':  'log2',\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "# ada_params = {\n",
    "#     'base_estimator' :ExtraTreesClassifier(max_depth=4, n_estimators=5,n_jobs=-1,min_samples_leaf=1),\n",
    "#     'n_estimators': 50,\n",
    "#     'learning_rate' : 0.75\n",
    "# }\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'base_estimator' :ExtraTreesClassifier(max_depth=4, n_estimators=50,n_jobs=-1,min_samples_leaf=1),\n",
    "    'n_estimators': 25,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'max_leaf_nodes':None,\n",
    "    'max_features':None,\n",
    "    'learning_rate':0.1,\n",
    "    'loss':'deviance',\n",
    "    'presort':True,\n",
    "    'min_samples_split':2,\n",
    "    'min_weight_fraction_leaf':0.0,\n",
    "    'min_impurity_decrease':0.0,\n",
    "    'subsample':1.0,\n",
    "    'min_impurity_split':None,\n",
    "    'n_estimators': 100,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_leaf': 1,\n",
    "    'verbose': 0,\n",
    "    'max_leaf_nodes':None,\n",
    "}\n",
    "# # Gradient Boosting parameters\n",
    "# gb_params = {\n",
    "#     'learning_rate':0.1\n",
    "#     'n_estimators': 50,\n",
    "#      #'max_features': 0.2,\n",
    "#     'max_depth': 5,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }\n",
    "\n",
    "params = {'tree_method':'gpu_hist', 'predictor':'gpu_predictor'}\n",
    "\n",
    "xgb_params = {'n_estimators':450,\n",
    "                'max_depth':4,\n",
    "                'objective':\"binary:logistic\",\n",
    "                'learning_rate':0.07,\n",
    "                'max_delta_step':1.8,\n",
    "                'subsample':.8,\n",
    "                #min_child_weight=0.5,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'min_child_weight':28,#??\n",
    "                'colsample_bylevel':0.432,#??\n",
    "                'gamma':10,\n",
    "                'reg_alpha':8,\n",
    "               'n_jobs':12,\n",
    "                'reg_lambda':1.3,\n",
    "                'missing':-1,\n",
    "                **params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = EnsambleHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = EnsambleHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = EnsambleHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = EnsambleHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = EnsambleHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "xgb = EnsambleHelper(clf=XGBClassifier, seed=SEED, params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.36106, Eval-Gini = 0.27325\n",
      "Fold 1:  Train-Gini = 0.35715, Eval-Gini = 0.29476\n",
      "Fold 2:  Train-Gini = 0.35773, Eval-Gini = 0.28519\n",
      "Fold 3:  Train-Gini = 0.35739, Eval-Gini = 0.29556\n",
      "Fold 4:  Train-Gini = 0.35776, Eval-Gini = 0.28903\n"
     ]
    }
   ],
   "source": [
    "svc_oof_train, svc_oof_test = get_oof(xgb,x_train, y_train, x_test) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.29177, Eval-Gini = 0.23725\n",
      "Fold 1:  Train-Gini = 0.28925, Eval-Gini = 0.25948\n",
      "Fold 2:  Train-Gini = 0.28736, Eval-Gini = 0.25527\n",
      "Fold 3:  Train-Gini = 0.28646, Eval-Gini = 0.26026\n",
      "Fold 4:  Train-Gini = 0.28707, Eval-Gini = 0.26039\n"
     ]
    }
   ],
   "source": [
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.21055, Eval-Gini = 0.17645\n",
      "Fold 1:  Train-Gini = 0.20417, Eval-Gini = 0.20363\n",
      "Fold 2:  Train-Gini = 0.20484, Eval-Gini = 0.20837\n",
      "Fold 3:  Train-Gini = 0.20558, Eval-Gini = 0.21113\n",
      "Fold 4:  Train-Gini = 0.20039, Eval-Gini = 0.20930\n"
     ]
    }
   ],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.31844, Eval-Gini = 0.26736\n",
      "Fold 1:  Train-Gini = 0.31323, Eval-Gini = 0.28808\n",
      "Fold 2:  Train-Gini = 0.31486, Eval-Gini = 0.28189\n",
      "Fold 3:  Train-Gini = 0.31397, Eval-Gini = 0.28856\n",
      "Fold 4:  Train-Gini = 0.31503, Eval-Gini = 0.28580\n"
     ]
    }
   ],
   "source": [
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.30260, Eval-Gini = 0.26091\n",
      "Fold 1:  Train-Gini = 0.29840, Eval-Gini = 0.28695\n",
      "Fold 2:  Train-Gini = 0.29877, Eval-Gini = 0.27809\n",
      "Fold 3:  Train-Gini = 0.29790, Eval-Gini = 0.28616\n",
      "Fold 4:  Train-Gini = 0.29884, Eval-Gini = 0.28148\n"
     ]
    }
   ],
   "source": [
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GBoost</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458870</td>\n",
       "      <td>0.047472</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>0.505484</td>\n",
       "      <td>0.044113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>0.482431</td>\n",
       "      <td>0.026422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.448267</td>\n",
       "      <td>0.027043</td>\n",
       "      <td>0.021208</td>\n",
       "      <td>0.448453</td>\n",
       "      <td>0.019910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.446240</td>\n",
       "      <td>0.026823</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.479430</td>\n",
       "      <td>0.017558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.454641</td>\n",
       "      <td>0.028133</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.479002</td>\n",
       "      <td>0.044170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost  ExtraTrees    GBoost  RandomForest   XGBoost\n",
       "0  0.458870    0.047472  0.044198      0.505484  0.044113\n",
       "1  0.454031    0.032741  0.035664      0.482431  0.026422\n",
       "2  0.448267    0.027043  0.021208      0.448453  0.019910\n",
       "3  0.446240    0.026823  0.017561      0.479430  0.017558\n",
       "4  0.454641    0.028133  0.031373      0.479002  0.044170"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame({'RandomForest': rf_oof_train.ravel(),\n",
    "                                       'ExtraTrees': et_oof_train.ravel(),\n",
    "                                       'XGBoost': svc_oof_train.ravel(),\n",
    "                                       'AdaBoost': ada_oof_train.ravel(),\n",
    "                                       'GBoost': gb_oof_train.ravel()})\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fcbe86e8278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fcbce9cdd68>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fcbce91d978>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fcbe85e5ef0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fcbceab5e48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fcbceab5320>]], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naJiZWWkuNMzMrDQXGmZmVtr/Bx7grnuv/4D0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcbd08c1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_predictions_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= base_predictions_train.astype(float).corr().values ,\n",
    "        x=base_predictions_train.columns.values,\n",
    "        y= base_predictions_train.columns.values,\n",
    "          colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            reversescale = True\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='labelled-heatmap')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_blender= np.concatenate((et_oof_train, svc_oof_train,gb_oof_train,ada_oof_train), axis=1)\n",
    "x_test_blender = np.concatenate((et_oof_test, svc_oof_test,gb_oof_test,ada_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:  Train-Gini = 0.29923, Eval-Gini = 0.27135\n",
      "Fold 1:  Train-Gini = 0.29363, Eval-Gini = 0.29476\n",
      "Fold 2:  Train-Gini = 0.29578, Eval-Gini = 0.28599\n",
      "Fold 3:  Train-Gini = 0.29340, Eval-Gini = 0.29443\n",
      "Fold 4:  Train-Gini = 0.29364, Eval-Gini = 0.29072\n"
     ]
    }
   ],
   "source": [
    "mdl = XGBClassifier(n_estimators= 500,learning_rate=0.007, max_depth= 4,min_child_weight= 1,gamma=.8,subsample=1,\n",
    "                    colsample_bytree=1,objective= 'binary:logistic',scale_pos_weight=2,**params)\n",
    "predictions = blend(mdl,x_train_blender, y_train, x_test_blender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = predictions\n",
    "filename = 'ensamble_'+str(dt.datetime.now()).replace(' ','_').replace(':','').replace('.','')\n",
    "sub.id = sub.id.astype('Int32')\n",
    "sub.to_csv('../../output/'+filename+'.csv.gz', index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcafff5b9b0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcae632a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdUMDUlSNUNDklTt/wNRcy2isDqvqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcae61a9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub['target'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import BatchNormalization \n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import keras.callbacks as kc\n",
    "\n",
    "class Metrics(kc.Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        predict = np.asarray(self.model.predict_proba(self.validation_data[0])[:,0])\n",
    "        targ = self.validation_data[1]\n",
    "        self.ginis= eval_gini(targ, predict)\n",
    "        return\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=4, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RS = StandardScaler()\n",
    "RS.fit(list(x_train_blender) + list(x_test_blender))\n",
    "x_train_blender_in = RS.transform(x_train_blender)\n",
    "x_test_blender_in = RS.transform(x_test_blender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5]\n",
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1617 - acc: 0.9632 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1542 - acc: 0.9635 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1524 - acc: 0.9635 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1522 - acc: 0.9635 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1521 - acc: 0.9635 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 00005: early stopping\n",
      "[ 0.28844492]\n",
      "[Fold 1/5 Prediciton:]\n",
      "891136/892816 [============================>.] - ETA: 0s[Fold 2/5]\n",
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1520 - acc: 0.9635 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1520 - acc: 0.9635 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9636\n",
      "Epoch 00002: early stopping\n",
      "[ 0.28592662]\n",
      "[Fold 2/5 Prediciton:]\n",
      "889152/892816 [============================>.] - ETA: 0s[Fold 3/5]\n",
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1520 - acc: 0.9635 - val_loss: 0.1516 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1516 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "476169/476169 [==============================] - 28s - loss: 0.1519 - acc: 0.9635 - val_loss: 0.1519 - val_acc: 0.9636\n",
      "Epoch 00002: early stopping\n",
      "[ 0.28792717]\n",
      "[Fold 3/5 Prediciton:]\n",
      "890528/892816 [============================>.] - ETA: 0s[Fold 4/5]\n",
      "Train on 476170 samples, validate on 119042 samples\n",
      "Epoch 1/20\n",
      "476170/476170 [==============================] - 28s - loss: 0.1519 - acc: 0.9635 - val_loss: 0.1514 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "476170/476170 [==============================] - 28s - loss: 0.1519 - acc: 0.9635 - val_loss: 0.1515 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "476170/476170 [==============================] - 28s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1515 - val_acc: 0.9636\n",
      "Epoch 00002: early stopping\n",
      "[ 0.29267199]\n",
      "[Fold 4/5 Prediciton:]\n",
      "889856/892816 [============================>.] - ETA: 0s[Fold 5/5]\n",
      "Train on 476171 samples, validate on 119041 samples\n",
      "Epoch 1/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1519 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1519 - acc: 0.9635 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "476171/476171 [==============================] - 28s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9635\n",
      "Epoch 00005: early stopping\n",
      "[ 0.28075238]\n",
      "[Fold 5/5 Prediciton:]\n",
      "889184/892816 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = np.zeros_like(id_test)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x_train_blender_in, y_train)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train_blender_dl, X_valid_blender_dl = x_train_blender[train_index], x_train_blender[test_index]\n",
    "    y_train_blender_dl, y_valid_blender_dl = y_train[train_index], y_train[test_index]\n",
    "    #class_weight = {1 : (len(y_train) - sum(y_train))/y_train.shape[0], 0: sum(y_train)/y_train.shape[0]}\n",
    "    ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "    history = model.fit(X_train_blender_dl, y_train_blender_dl, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,validation_data=(X_valid_blender_dl,y_valid_blender_dl), callbacks=[ES,metrics])#, class_weight = class_weight\n",
    "    print(metrics.ginis)\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test =model.predict_proba(x_test_blender_in)[:,0]\n",
    "    sub['target'] += p_test/kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'dl_ensamble_'+str(dt.datetime.now()).replace(' ','_').replace(':','').replace('.','')\n",
    "sub.id = sub.id.astype('Int32')\n",
    "sub.to_csv('../../output/'+filename+'.csv.gz', index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['id'] = id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.046914e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.148240e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.253105e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.457876e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.579004e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8.017893e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.420868e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.048186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>9.604785e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>3.156874e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>9.257088e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>6.436024e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>9.010473e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>1.182689e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>3.418868e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>9.680229e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>2.613748e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>1.121796e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>2.109010e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37</td>\n",
       "      <td>7.585486e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38</td>\n",
       "      <td>4.190134e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40</td>\n",
       "      <td>1.044521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>41</td>\n",
       "      <td>1.233217e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42</td>\n",
       "      <td>1.420332e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892786</th>\n",
       "      <td>1487982</td>\n",
       "      <td>2.638974e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892787</th>\n",
       "      <td>1487984</td>\n",
       "      <td>1.032120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892788</th>\n",
       "      <td>1487985</td>\n",
       "      <td>1.490985e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892789</th>\n",
       "      <td>1487986</td>\n",
       "      <td>3.892627e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892790</th>\n",
       "      <td>1487987</td>\n",
       "      <td>2.667233e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892791</th>\n",
       "      <td>1487989</td>\n",
       "      <td>4.792158e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892792</th>\n",
       "      <td>1487991</td>\n",
       "      <td>9.652494e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892793</th>\n",
       "      <td>1487993</td>\n",
       "      <td>1.576559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892794</th>\n",
       "      <td>1487995</td>\n",
       "      <td>1.809902e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892795</th>\n",
       "      <td>1487997</td>\n",
       "      <td>1.413022e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892796</th>\n",
       "      <td>1487998</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892797</th>\n",
       "      <td>1487999</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892798</th>\n",
       "      <td>1488000</td>\n",
       "      <td>7.908485e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892799</th>\n",
       "      <td>1488002</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892800</th>\n",
       "      <td>1488003</td>\n",
       "      <td>2.099458e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892801</th>\n",
       "      <td>1488004</td>\n",
       "      <td>6.440830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892802</th>\n",
       "      <td>1488006</td>\n",
       "      <td>8.629573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892803</th>\n",
       "      <td>1488007</td>\n",
       "      <td>1.482021e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892804</th>\n",
       "      <td>1488010</td>\n",
       "      <td>7.077401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892805</th>\n",
       "      <td>1488012</td>\n",
       "      <td>9.192872e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892806</th>\n",
       "      <td>1488014</td>\n",
       "      <td>1.735133e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892807</th>\n",
       "      <td>1488015</td>\n",
       "      <td>2.210644e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892808</th>\n",
       "      <td>1488018</td>\n",
       "      <td>1.392106e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892809</th>\n",
       "      <td>1488019</td>\n",
       "      <td>1.251023e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892810</th>\n",
       "      <td>1488020</td>\n",
       "      <td>1.831262e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892811</th>\n",
       "      <td>1488022</td>\n",
       "      <td>9.900000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892812</th>\n",
       "      <td>1488023</td>\n",
       "      <td>4.206994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892813</th>\n",
       "      <td>1488024</td>\n",
       "      <td>2.530576e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892814</th>\n",
       "      <td>1488025</td>\n",
       "      <td>2.816096e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892815</th>\n",
       "      <td>1488026</td>\n",
       "      <td>1.306487e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892816 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        target\n",
       "0             0  6.046914e-10\n",
       "1             1  4.148240e-09\n",
       "2             2  1.253105e-09\n",
       "3             3  8.457876e-17\n",
       "4             4  3.579004e-04\n",
       "5             5  8.017893e-01\n",
       "6             6  1.420868e-12\n",
       "7             8  1.048186e-04\n",
       "8            10  9.900000e-01\n",
       "9            11  9.900000e-01\n",
       "10           12  9.604785e-08\n",
       "11           14  3.156874e-11\n",
       "12           15  9.257088e-01\n",
       "13           18  6.436024e-01\n",
       "14           21  9.010473e-01\n",
       "15           23  1.182689e-10\n",
       "16           24  3.418868e-11\n",
       "17           25  9.680229e-01\n",
       "18           27  2.613748e-16\n",
       "19           29  9.900000e-01\n",
       "20           30  1.121796e-03\n",
       "21           31  9.900000e-01\n",
       "22           32  9.900000e-01\n",
       "23           33  2.109010e-15\n",
       "24           37  7.585486e-08\n",
       "25           38  4.190134e-09\n",
       "26           39  9.900000e-01\n",
       "27           40  1.044521e-01\n",
       "28           41  1.233217e-09\n",
       "29           42  1.420332e-14\n",
       "...         ...           ...\n",
       "892786  1487982  2.638974e-14\n",
       "892787  1487984  1.032120e-01\n",
       "892788  1487985  1.490985e-03\n",
       "892789  1487986  3.892627e-03\n",
       "892790  1487987  2.667233e-03\n",
       "892791  1487989  4.792158e-10\n",
       "892792  1487991  9.652494e-07\n",
       "892793  1487993  1.576559e-01\n",
       "892794  1487995  1.809902e-09\n",
       "892795  1487997  1.413022e-04\n",
       "892796  1487998  9.900000e-01\n",
       "892797  1487999  9.900000e-01\n",
       "892798  1488000  7.908485e-01\n",
       "892799  1488002  9.900000e-01\n",
       "892800  1488003  2.099458e-09\n",
       "892801  1488004  6.440830e-05\n",
       "892802  1488006  8.629573e-07\n",
       "892803  1488007  1.482021e-06\n",
       "892804  1488010  7.077401e-01\n",
       "892805  1488012  9.192872e-02\n",
       "892806  1488014  1.735133e-11\n",
       "892807  1488015  2.210644e-09\n",
       "892808  1488018  1.392106e-08\n",
       "892809  1488019  1.251023e-14\n",
       "892810  1488020  1.831262e-11\n",
       "892811  1488022  9.900000e-01\n",
       "892812  1488023  4.206994e-01\n",
       "892813  1488024  2.530576e-03\n",
       "892814  1488025  2.816096e-09\n",
       "892815  1488026  1.306487e-04\n",
       "\n",
       "[892816 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[sub['target']>0.99]=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
