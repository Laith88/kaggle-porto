{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 24, 8\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(solution, submission):\n",
    "    df = zip(solution, submission, range(len(solution)))\n",
    "    df = sorted(df, key=lambda x: (x[1],-x[2]), reverse=True)\n",
    "    rand = [float(i+1)/float(len(df)) for i in range(len(df))]\n",
    "    totalPos = float(sum([x[0] for x in df]))\n",
    "    cumPosFound = [df[0][0]]\n",
    "    for i in range(1,len(df)):\n",
    "        cumPosFound.append(cumPosFound[len(cumPosFound)-1] + df[i][0])\n",
    "    Lorentz = [float(x)/totalPos for x in cumPosFound]\n",
    "    Gini = [Lorentz[i]-rand[i] for i in range(len(df))]\n",
    "    return sum(Gini)\n",
    "\n",
    "def normalized_gini(solution, submission):\n",
    "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n",
    "    return normalized_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    non_imp = ['ps_ind_16_bin','ps_car_08_cat','ps_car_11_cat','ps_ind_06_bin','ps_car_02_cat','ps_ind_07_bin','ps_ind_09_bin','ps_ind_08_bin','ps_ind_14','ps_ind_18_bin','ps_car_10_cat','ps_ind_11_bin','ps_ind_10_bin']\n",
    "    \n",
    "    train = (pd.read_csv('../data/train.csv', na_values=-1)\n",
    "              .fillna(value=-1))\n",
    "    unwanted = list((set(train.columns[train.columns.str.startswith('ps_calc_')])|set(non_imp)))\n",
    "    train.drop(unwanted, axis=1, inplace=True)\n",
    "            \n",
    "    \n",
    "#     minority_class = train.target.sum()\n",
    "#     majority_class = train.target.shape[0] - minority_class\n",
    "\n",
    "#     df_majority = train[train['target']==0]\n",
    "#     df_minority = train[train['target']==1]\n",
    "\n",
    "#     df_majority_downsampled = resample(df_majority, \n",
    "#                                      replace=False,     # sample with replacement\n",
    "#                                      n_samples=minority_class,    # to match majority class\n",
    "#                                      random_state=np.random.randint(1999)) # reproducible results\n",
    "\n",
    "#     train = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    \n",
    "    test  = (pd.read_csv('../data/test.csv', na_values=-1)\n",
    "              .fillna(value=-1)\n",
    "              .drop(unwanted, axis=1)) \n",
    "    \n",
    "    y = train.target.values        \n",
    "    train = train.drop(['id', 'target'], axis=1)\n",
    "    \n",
    "    test_id = test.id.values\n",
    "    test = test.drop('id', axis=1)\n",
    "    \n",
    "    fl = train.columns.tolist()\n",
    "    \n",
    "    return train.values, y, test.values, test_id, fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, X_test, test_id, _ = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, shuffle=True,  random_state=np.random.randint(1000), stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth=2, warm_start=True, subsample=0.25)\n",
    "val_error = np.zeros((500))\n",
    "for i, n_estimators in enumerate(range(1, 500)):\n",
    "    gbc.n_estimators = n_estimators\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred = gbc.predict(X_val)\n",
    "    val_error[i] = gini_normalized(y_val, y_pred)\n",
    "max(val_error), np.argmax(val_error)\n",
    "plt.plot(range(1,500), val_error[:-1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# A list of dictionaries to specify the parameters we want to tune.\n",
    "param_dist = {\"n_estimators\":[200, 250,300],\n",
    "              \"max_depth\": [1,2,3,9],\n",
    "              \"max_features\": np.random.uniform(0.1,0.5,5),\n",
    "              \"min_samples_split\": np.random.uniform(0.125,0.5,5),\n",
    "              \"min_samples_leaf\": np.random.uniform(0.125,0.5,5),\n",
    "              \"subsample\":  np.random.uniform(0.8,.9,3)}\n",
    "\n",
    "\n",
    "# Initialize GridSearchSV object to train and tune clf\n",
    "n_iter_search = 10\n",
    "gini_scorer = make_scorer(normalized_gini, greater_is_better = True)\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring = gini_scorer,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1,\n",
    "                                   iid = false,\n",
    "                                   cv= StratifiedKFold(n_splits=3, shuffle=True),\n",
    "                                   verbose=2)\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distribution=\"bernoulli\",\n",
    "                                      ntrees=100,\n",
    "                                      max_depth=27,\n",
    "                                      min_rows=2048,\n",
    "                                      learn_rate=0.2,\n",
    "                                      sample_rate=0.37,\n",
    "                                      col_sample_rate=0.63,\n",
    "                                      col_sample_rate_per_tree=0.85,\n",
    "                                      col_sample_rate_change_per_level=1.0,\n",
    "                                      nbins=128,\n",
    "                                      nbins_cats=4096,\n",
    "                                      min_split_improvement=0.0,\n",
    "                                      histogram_type='RoundRobin',\n",
    "                                      nfolds=nfolds,\n",
    "                                      fold_assignment=\"Modulo\",\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {1 : (len(y_train) - sum(y_train))/y_train.shape[0], 0: sum(y_train)/y_train.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gini_scorer = make_scorer(normalized_gini, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF = GradientBoostingClassifier(n_estimators = 81,\n",
    "                                max_features = 0.5,\n",
    "                                max_depth = 27,\n",
    "                                min_samples_leaf = 50,\n",
    "                                min_samples_split = 500,\n",
    "                                subsample = 0.8,\n",
    "                                learning_rate = 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.01637837  0.01610228  0.00327906  0.00118265 -0.00038704]\n",
      "\n",
      "CV accuracy: 0.007 +/- 0.007\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=RF, X=X, y=y, cv=5, n_jobs=-1, scoring=gini_scorer)\n",
    "print('CV accuracy scores: %s' % scores); print()\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01637837,  0.01610228,  0.00327906,  0.00118265, -0.00038704])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
