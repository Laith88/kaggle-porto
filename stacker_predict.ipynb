{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h2o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.estimators import H2ONaiveBayesEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_131\"; OpenJDK Runtime Environment (build 1.8.0_131-8u131-b11-2ubuntu1.16.04.3-b11); OpenJDK 64-Bit Server VM (build 25.131-b11, mixed mode)\n",
      "  Starting server from /home/laith/anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpu0851snw\n",
      "  JVM stdout: /tmp/tmpu0851snw/h2o_laith_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpu0851snw/h2o_laith_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.14.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>17 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_laith_g68owb</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>22.22 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster version:        3.14.0.7\n",
       "H2O cluster version age:    17 days\n",
       "H2O cluster name:           H2O_from_python_laith_g68owb\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    22.22 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(nthreads = -1, max_mem_size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = h2o.import_file(os.path.realpath(\"../data/train2.csv\"))\n",
    "test  = h2o.import_file(os.path.realpath(\"../data/test2.csv\"))\n",
    "\n",
    "x = train.columns\n",
    "y = \"target\"\n",
    "x.remove(y)\n",
    "\n",
    "test_id = test['id'].as_data_frame(True).id.values\n",
    "\n",
    "features_bin = [i for i in x if set(i)&set('bin')==set('bin')]\n",
    "features_cat = [i for i in x if (set(i)&set('cat')==set('cat'))&(set(i)&set('avg')==set(''))]\n",
    "features_con = list(set(x) - (set(features_bin)|set(features_cat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_05_cat',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_ind_02_cat',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_reg_01_plus_ps_car_02_cat',\n",
       " 'ps_reg_01_plus_ps_car_04_cat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in x if (set(i)&set('cat')==set('cat'))&(set(i)&set('avg')!=set('avg'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(with_validation = True):\n",
    "    train = h2o.import_file(os.path.realpath(\"../data/train2.csv\"))\n",
    "    test  = h2o.import_file(os.path.realpath(\"../data/test2.csv\"))\n",
    "    \n",
    "    x = train.columns\n",
    "    y = \"target\"\n",
    "    x.remove(y)\n",
    "    \n",
    "    test_id = test['id'].as_data_frame(True).id.values\n",
    "    \n",
    "    features_bin = [i for i in x if set(i)&set('bin')==set('bin')]\n",
    "    features_cat = [i for i in x if (set(i)&set('cat')==set('cat'))&(set(i)&set('avg')!=set('avg'))]\n",
    "    features_con = list(set(x) - (set(features_bin)|set(features_cat)))\n",
    "    \n",
    "    train[features_cat] = train[features_cat].asfactor()\n",
    "    train[features_bin] = train[features_bin].asfactor()\n",
    "    train[features_con] = train[features_con].asnumeric()\n",
    "    \n",
    "    test[features_cat] = test[features_cat].asfactor()\n",
    "    test[features_bin] = test[features_bin].asfactor()\n",
    "    test[features_con] = test[features_con].asnumeric()\n",
    "    \n",
    "    train['target'] = train['target'].asfactor()\n",
    "    \n",
    "    return train, test, x, y, test_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train, test, x, y, test_id = prepare_data(with_validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "my_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\",\n",
    "                                      ntrees=100,\n",
    "                                      max_depth=27,\n",
    "                                      min_rows=2048,\n",
    "                                      learn_rate=0.2,\n",
    "                                      sample_rate=0.37,\n",
    "                                      col_sample_rate=0.63,\n",
    "                                      col_sample_rate_per_tree=0.85,\n",
    "                                      col_sample_rate_change_per_level=1.0,\n",
    "                                      nbins=128,\n",
    "                                      nbins_cats=4096,\n",
    "                                      min_split_improvement=0.0,\n",
    "                                      histogram_type='RoundRobin',\n",
    "                                      nfolds=nfolds,\n",
    "                                      fold_assignment=\"Modulo\",\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1)\n",
    "my_gbm.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1510019598591_170\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.033984094636136976\n",
      "RMSE: 0.1843477546273265\n",
      "LogLoss: 0.14417417673490698\n",
      "Mean Per-Class Error: 0.3346685712802413\n",
      "AUC: 0.7281206830858074\n",
      "Gini: 0.4562413661716147\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.079346896191179: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>538792.0</td>\n",
       "<td>34726.0</td>\n",
       "<td>0.0605</td>\n",
       "<td> (34726.0/573518.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>16354.0</td>\n",
       "<td>5340.0</td>\n",
       "<td>0.7538</td>\n",
       "<td> (16354.0/21694.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>555146.0</td>\n",
       "<td>40066.0</td>\n",
       "<td>0.0858</td>\n",
       "<td> (51080.0/595212.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      538792  34726  0.0605   (34726.0/573518.0)\n",
       "1      16354   5340   0.7538   (16354.0/21694.0)\n",
       "Total  555146  40066  0.0858   (51080.0/595212.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0793469</td>\n",
       "<td>0.1729275</td>\n",
       "<td>163.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0520048</td>\n",
       "<td>0.2590653</td>\n",
       "<td>225.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.1066241</td>\n",
       "<td>0.1656448</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3201513</td>\n",
       "<td>0.9635810</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.3851384</td>\n",
       "<td>0.76</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0043954</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5515620</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0633855</td>\n",
       "<td>0.1435390</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0381870</td>\n",
       "<td>0.6642851</td>\n",
       "<td>268.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0391067</td>\n",
       "<td>0.6653314</td>\n",
       "<td>265.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0793469    0.172927  163\n",
       "max f2                       0.0520048    0.259065  225\n",
       "max f0point5                 0.106624     0.165645  122\n",
       "max accuracy                 0.320151     0.963581  16\n",
       "max precision                0.385138     0.76      8\n",
       "max recall                   0.00439543   1         397\n",
       "max specificity              0.551562     0.999998  0\n",
       "max absolute_mcc             0.0633855    0.143539  195\n",
       "max min_per_class_accuracy   0.038187     0.664285  268\n",
       "max mean_per_class_accuracy  0.0391067    0.665331  265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100015</td>\n",
       "<td>0.1363046</td>\n",
       "<td>6.4616611</td>\n",
       "<td>6.4616611</td>\n",
       "<td>0.2355115</td>\n",
       "<td>0.2355115</td>\n",
       "<td>0.0646262</td>\n",
       "<td>0.0646262</td>\n",
       "<td>546.1661058</td>\n",
       "<td>546.1661058</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200013</td>\n",
       "<td>0.1145869</td>\n",
       "<td>4.0426739</td>\n",
       "<td>5.2522691</td>\n",
       "<td>0.1473454</td>\n",
       "<td>0.1914322</td>\n",
       "<td>0.0404259</td>\n",
       "<td>0.1050521</td>\n",
       "<td>304.2673926</td>\n",
       "<td>425.2269087</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300011</td>\n",
       "<td>0.1025694</td>\n",
       "<td>3.5540497</td>\n",
       "<td>4.6862277</td>\n",
       "<td>0.1295363</td>\n",
       "<td>0.1708014</td>\n",
       "<td>0.0355398</td>\n",
       "<td>0.1405919</td>\n",
       "<td>255.4049711</td>\n",
       "<td>368.6227662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400009</td>\n",
       "<td>0.0942272</td>\n",
       "<td>3.1391801</td>\n",
       "<td>4.2994820</td>\n",
       "<td>0.1144153</td>\n",
       "<td>0.1567054</td>\n",
       "<td>0.0313912</td>\n",
       "<td>0.1719830</td>\n",
       "<td>213.9180095</td>\n",
       "<td>329.9482015</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.0879624</td>\n",
       "<td>2.8672100</td>\n",
       "<td>4.0130372</td>\n",
       "<td>0.1045027</td>\n",
       "<td>0.1462652</td>\n",
       "<td>0.0286715</td>\n",
       "<td>0.2006546</td>\n",
       "<td>186.7210013</td>\n",
       "<td>301.3037240</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000013</td>\n",
       "<td>0.0692150</td>\n",
       "<td>2.3563802</td>\n",
       "<td>3.1847087</td>\n",
       "<td>0.0858842</td>\n",
       "<td>0.1160747</td>\n",
       "<td>0.1178206</td>\n",
       "<td>0.3184752</td>\n",
       "<td>135.6380240</td>\n",
       "<td>218.4708740</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500003</td>\n",
       "<td>0.0586817</td>\n",
       "<td>1.8641475</td>\n",
       "<td>2.7445315</td>\n",
       "<td>0.0679435</td>\n",
       "<td>0.1000314</td>\n",
       "<td>0.0932055</td>\n",
       "<td>0.4116806</td>\n",
       "<td>86.4147475</td>\n",
       "<td>174.4531512</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000010</td>\n",
       "<td>0.0515554</td>\n",
       "<td>1.5902801</td>\n",
       "<td>2.4559662</td>\n",
       "<td>0.0579618</td>\n",
       "<td>0.0895139</td>\n",
       "<td>0.0795151</td>\n",
       "<td>0.4911957</td>\n",
       "<td>59.0280092</td>\n",
       "<td>145.5966233</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000007</td>\n",
       "<td>0.0417493</td>\n",
       "<td>1.2275325</td>\n",
       "<td>2.0464906</td>\n",
       "<td>0.0447405</td>\n",
       "<td>0.0745895</td>\n",
       "<td>0.1227528</td>\n",
       "<td>0.6139486</td>\n",
       "<td>22.7532474</td>\n",
       "<td>104.6490606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000003</td>\n",
       "<td>0.0349280</td>\n",
       "<td>1.0136477</td>\n",
       "<td>1.7882810</td>\n",
       "<td>0.0369449</td>\n",
       "<td>0.0651784</td>\n",
       "<td>0.1013644</td>\n",
       "<td>0.7153130</td>\n",
       "<td>1.3647732</td>\n",
       "<td>78.8280972</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0295629</td>\n",
       "<td>0.8034507</td>\n",
       "<td>1.5913156</td>\n",
       "<td>0.0292838</td>\n",
       "<td>0.0579995</td>\n",
       "<td>0.0803448</td>\n",
       "<td>0.7956578</td>\n",
       "<td>-19.6549342</td>\n",
       "<td>59.1315571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999997</td>\n",
       "<td>0.0250892</td>\n",
       "<td>0.6748432</td>\n",
       "<td>1.4385706</td>\n",
       "<td>0.0245964</td>\n",
       "<td>0.0524323</td>\n",
       "<td>0.0674841</td>\n",
       "<td>0.8631419</td>\n",
       "<td>-32.5156763</td>\n",
       "<td>43.8570610</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999993</td>\n",
       "<td>0.0210262</td>\n",
       "<td>0.4936865</td>\n",
       "<td>1.3035875</td>\n",
       "<td>0.0179936</td>\n",
       "<td>0.0475125</td>\n",
       "<td>0.0493685</td>\n",
       "<td>0.9125104</td>\n",
       "<td>-50.6313451</td>\n",
       "<td>30.3587497</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999990</td>\n",
       "<td>0.0171347</td>\n",
       "<td>0.4185503</td>\n",
       "<td>1.1929581</td>\n",
       "<td>0.0152551</td>\n",
       "<td>0.0434804</td>\n",
       "<td>0.0418549</td>\n",
       "<td>0.9543653</td>\n",
       "<td>-58.1449686</td>\n",
       "<td>19.2958081</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999987</td>\n",
       "<td>0.0128960</td>\n",
       "<td>0.2936306</td>\n",
       "<td>1.0930330</td>\n",
       "<td>0.0107021</td>\n",
       "<td>0.0398383</td>\n",
       "<td>0.0293630</td>\n",
       "<td>0.9837282</td>\n",
       "<td>-70.6369438</td>\n",
       "<td>9.3032988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0011514</td>\n",
       "<td>0.1627156</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0059306</td>\n",
       "<td>0.0364475</td>\n",
       "<td>0.0162718</td>\n",
       "<td>1.0</td>\n",
       "<td>-83.7284385</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100015                   0.136305           6.46166   6.46166            0.235512         0.235512                    0.0646262       0.0646262                  546.166   546.166\n",
       "    2        0.0200013                   0.114587           4.04267   5.25227            0.147345         0.191432                    0.0404259       0.105052                   304.267   425.227\n",
       "    3        0.0300011                   0.102569           3.55405   4.68623            0.129536         0.170801                    0.0355398       0.140592                   255.405   368.623\n",
       "    4        0.0400009                   0.0942272          3.13918   4.29948            0.114415         0.156705                    0.0313912       0.171983                   213.918   329.948\n",
       "    5        0.0500007                   0.0879624          2.86721   4.01304            0.104503         0.146265                    0.0286715       0.200655                   186.721   301.304\n",
       "    6        0.100001                    0.069215           2.35638   3.18471            0.0858842        0.116075                    0.117821        0.318475                   135.638   218.471\n",
       "    7        0.15                        0.0586817          1.86415   2.74453            0.0679435        0.100031                    0.0932055       0.411681                   86.4147   174.453\n",
       "    8        0.200001                    0.0515554          1.59028   2.45597            0.0579618        0.0895139                   0.0795151       0.491196                   59.028    145.597\n",
       "    9        0.300001                    0.0417493          1.22753   2.04649            0.0447405        0.0745895                   0.122753        0.613949                   22.7532   104.649\n",
       "    10       0.4                         0.034928           1.01365   1.78828            0.0369449        0.0651784                   0.101364        0.715313                   1.36477   78.8281\n",
       "    11       0.5                         0.0295629          0.803451  1.59132            0.0292838        0.0579995                   0.0803448       0.795658                   -19.6549  59.1316\n",
       "    12       0.6                         0.0250892          0.674843  1.43857            0.0245964        0.0524323                   0.0674841       0.863142                   -32.5157  43.8571\n",
       "    13       0.699999                    0.0210262          0.493687  1.30359            0.0179936        0.0475125                   0.0493685       0.91251                    -50.6313  30.3587\n",
       "    14       0.799999                    0.0171347          0.41855   1.19296            0.0152551        0.0434804                   0.0418549       0.954365                   -58.145   19.2958\n",
       "    15       0.899999                    0.012896           0.293631  1.09303            0.0107021        0.0398383                   0.029363        0.983728                   -70.6369  9.3033\n",
       "    16       1                           0.00115138         0.162716  1                  0.00593058       0.0364475                   0.0162718       1                          -83.7284  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.03496371397441792\n",
      "RMSE: 0.1869858657075928\n",
      "LogLoss: 0.15441540009850316\n",
      "Mean Per-Class Error: 0.4148099889665947\n",
      "AUC: 0.6175420015199719\n",
      "Gini: 0.2350840030399437\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.058805335844667496: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>491707.0</td>\n",
       "<td>81811.0</td>\n",
       "<td>0.1426</td>\n",
       "<td> (81811.0/573518.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>15918.0</td>\n",
       "<td>5776.0</td>\n",
       "<td>0.7338</td>\n",
       "<td> (15918.0/21694.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>507625.0</td>\n",
       "<td>87587.0</td>\n",
       "<td>0.1642</td>\n",
       "<td> (97729.0/595212.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      491707  81811  0.1426   (81811.0/573518.0)\n",
       "1      15918   5776   0.7338   (15918.0/21694.0)\n",
       "Total  507625  87587  0.1642   (97729.0/595212.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0588053</td>\n",
       "<td>0.1057091</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0347355</td>\n",
       "<td>0.1883046</td>\n",
       "<td>277.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0850699</td>\n",
       "<td>0.0872286</td>\n",
       "<td>145.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6925635</td>\n",
       "<td>0.9635508</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4131544</td>\n",
       "<td>0.3333333</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0022372</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.6925635</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0473635</td>\n",
       "<td>0.0673714</td>\n",
       "<td>234.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0338025</td>\n",
       "<td>0.5833871</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0338025</td>\n",
       "<td>0.5851900</td>\n",
       "<td>281.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value      idx\n",
       "---------------------------  -----------  ---------  -----\n",
       "max f1                       0.0588053    0.105709   201\n",
       "max f2                       0.0347355    0.188305   277\n",
       "max f0point5                 0.0850699    0.0872286  145\n",
       "max accuracy                 0.692564     0.963551   0\n",
       "max precision                0.413154     0.333333   8\n",
       "max recall                   0.0022372    1          399\n",
       "max specificity              0.692564     0.999998   0\n",
       "max absolute_mcc             0.0473635    0.0673714  234\n",
       "max min_per_class_accuracy   0.0338025    0.583387   281\n",
       "max mean_per_class_accuracy  0.0338025    0.58519    281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100015</td>\n",
       "<td>0.1318583</td>\n",
       "<td>3.1248261</td>\n",
       "<td>3.1248261</td>\n",
       "<td>0.1138922</td>\n",
       "<td>0.1138922</td>\n",
       "<td>0.0312529</td>\n",
       "<td>0.0312529</td>\n",
       "<td>212.4826104</td>\n",
       "<td>212.4826104</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200013</td>\n",
       "<td>0.1113522</td>\n",
       "<td>2.3878051</td>\n",
       "<td>2.7563466</td>\n",
       "<td>0.0870296</td>\n",
       "<td>0.1004620</td>\n",
       "<td>0.0238776</td>\n",
       "<td>0.0551305</td>\n",
       "<td>138.7805124</td>\n",
       "<td>175.6346568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300011</td>\n",
       "<td>0.1000469</td>\n",
       "<td>1.8715229</td>\n",
       "<td>2.4614219</td>\n",
       "<td>0.0682124</td>\n",
       "<td>0.0897127</td>\n",
       "<td>0.0187149</td>\n",
       "<td>0.0738453</td>\n",
       "<td>87.1522935</td>\n",
       "<td>146.1421874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400009</td>\n",
       "<td>0.0922206</td>\n",
       "<td>1.8761326</td>\n",
       "<td>2.3151057</td>\n",
       "<td>0.0683804</td>\n",
       "<td>0.0843799</td>\n",
       "<td>0.0187609</td>\n",
       "<td>0.0926063</td>\n",
       "<td>87.6132597</td>\n",
       "<td>131.5105700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.0863152</td>\n",
       "<td>2.0328611</td>\n",
       "<td>2.2586587</td>\n",
       "<td>0.0740927</td>\n",
       "<td>0.0823225</td>\n",
       "<td>0.0203282</td>\n",
       "<td>0.1129345</td>\n",
       "<td>103.2861119</td>\n",
       "<td>125.8658681</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000013</td>\n",
       "<td>0.0683263</td>\n",
       "<td>1.6372971</td>\n",
       "<td>1.9479779</td>\n",
       "<td>0.0596754</td>\n",
       "<td>0.0709990</td>\n",
       "<td>0.0818660</td>\n",
       "<td>0.1948004</td>\n",
       "<td>63.7297068</td>\n",
       "<td>94.7977874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500003</td>\n",
       "<td>0.0581391</td>\n",
       "<td>1.5110473</td>\n",
       "<td>1.8023376</td>\n",
       "<td>0.0550739</td>\n",
       "<td>0.0656907</td>\n",
       "<td>0.0755508</td>\n",
       "<td>0.2703512</td>\n",
       "<td>51.1047335</td>\n",
       "<td>80.2337624</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000010</td>\n",
       "<td>0.0511858</td>\n",
       "<td>1.3395229</td>\n",
       "<td>1.6866330</td>\n",
       "<td>0.0488223</td>\n",
       "<td>0.0614736</td>\n",
       "<td>0.0669770</td>\n",
       "<td>0.3373283</td>\n",
       "<td>33.9522883</td>\n",
       "<td>68.6632967</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000007</td>\n",
       "<td>0.0415793</td>\n",
       "<td>1.1957263</td>\n",
       "<td>1.5229983</td>\n",
       "<td>0.0435813</td>\n",
       "<td>0.0555095</td>\n",
       "<td>0.1195722</td>\n",
       "<td>0.4569005</td>\n",
       "<td>19.5726337</td>\n",
       "<td>52.2998340</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000003</td>\n",
       "<td>0.0347885</td>\n",
       "<td>1.0611265</td>\n",
       "<td>1.4075309</td>\n",
       "<td>0.0386754</td>\n",
       "<td>0.0513010</td>\n",
       "<td>0.1061123</td>\n",
       "<td>0.5630128</td>\n",
       "<td>6.1126457</td>\n",
       "<td>40.7530854</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0294941</td>\n",
       "<td>0.9463478</td>\n",
       "<td>1.3152946</td>\n",
       "<td>0.0344920</td>\n",
       "<td>0.0479392</td>\n",
       "<td>0.0946345</td>\n",
       "<td>0.6576473</td>\n",
       "<td>-5.3652209</td>\n",
       "<td>31.5294551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999997</td>\n",
       "<td>0.0249854</td>\n",
       "<td>0.8822746</td>\n",
       "<td>1.2431248</td>\n",
       "<td>0.0321567</td>\n",
       "<td>0.0453088</td>\n",
       "<td>0.0882272</td>\n",
       "<td>0.7458744</td>\n",
       "<td>-11.7725440</td>\n",
       "<td>24.3124755</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999993</td>\n",
       "<td>0.0209551</td>\n",
       "<td>0.7421432</td>\n",
       "<td>1.1715561</td>\n",
       "<td>0.0270493</td>\n",
       "<td>0.0427003</td>\n",
       "<td>0.0742141</td>\n",
       "<td>0.8200885</td>\n",
       "<td>-25.7856822</td>\n",
       "<td>17.1556130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999990</td>\n",
       "<td>0.0170305</td>\n",
       "<td>0.6826795</td>\n",
       "<td>1.1104467</td>\n",
       "<td>0.0248820</td>\n",
       "<td>0.0404730</td>\n",
       "<td>0.0682677</td>\n",
       "<td>0.8883562</td>\n",
       "<td>-31.7320468</td>\n",
       "<td>11.0446684</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999987</td>\n",
       "<td>0.0128146</td>\n",
       "<td>0.6107700</td>\n",
       "<td>1.0549272</td>\n",
       "<td>0.0222611</td>\n",
       "<td>0.0384495</td>\n",
       "<td>0.0610768</td>\n",
       "<td>0.9494330</td>\n",
       "<td>-38.9229993</td>\n",
       "<td>5.4927156</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0009310</td>\n",
       "<td>0.5056630</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0184302</td>\n",
       "<td>0.0364475</td>\n",
       "<td>0.0505670</td>\n",
       "<td>1.0</td>\n",
       "<td>-49.4337026</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100015                   0.131858           3.12483   3.12483            0.113892         0.113892                    0.0312529       0.0312529                  212.483   212.483\n",
       "    2        0.0200013                   0.111352           2.38781   2.75635            0.0870296        0.100462                    0.0238776       0.0551305                  138.781   175.635\n",
       "    3        0.0300011                   0.100047           1.87152   2.46142            0.0682124        0.0897127                   0.0187149       0.0738453                  87.1523   146.142\n",
       "    4        0.0400009                   0.0922206          1.87613   2.31511            0.0683804        0.0843799                   0.0187609       0.0926063                  87.6133   131.511\n",
       "    5        0.0500007                   0.0863152          2.03286   2.25866            0.0740927        0.0823225                   0.0203282       0.112934                   103.286   125.866\n",
       "    6        0.100001                    0.0683263          1.6373    1.94798            0.0596754        0.070999                    0.081866        0.1948                     63.7297   94.7978\n",
       "    7        0.15                        0.0581391          1.51105   1.80234            0.0550739        0.0656907                   0.0755508       0.270351                   51.1047   80.2338\n",
       "    8        0.200001                    0.0511858          1.33952   1.68663            0.0488223        0.0614736                   0.066977        0.337328                   33.9523   68.6633\n",
       "    9        0.300001                    0.0415793          1.19573   1.523              0.0435813        0.0555095                   0.119572        0.456901                   19.5726   52.2998\n",
       "    10       0.4                         0.0347885          1.06113   1.40753            0.0386754        0.051301                    0.106112        0.563013                   6.11265   40.7531\n",
       "    11       0.5                         0.0294941          0.946348  1.31529            0.034492         0.0479392                   0.0946345       0.657647                   -5.36522  31.5295\n",
       "    12       0.6                         0.0249854          0.882275  1.24312            0.0321567        0.0453088                   0.0882272       0.745874                   -11.7725  24.3125\n",
       "    13       0.699999                    0.0209551          0.742143  1.17156            0.0270493        0.0427003                   0.0742141       0.820089                   -25.7857  17.1556\n",
       "    14       0.799999                    0.0170305          0.68268   1.11045            0.024882         0.040473                    0.0682677       0.888356                   -31.732   11.0447\n",
       "    15       0.899999                    0.0128146          0.61077   1.05493            0.0222611        0.0384495                   0.0610768       0.949433                   -38.923   5.49272\n",
       "    16       1                           0.000931047        0.505663  1                  0.0184302        0.0364475                   0.050567        1                          -49.4337  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.8265877</td>\n",
       "<td>0.0220306</td>\n",
       "<td>0.8682073</td>\n",
       "<td>0.8345724</td>\n",
       "<td>0.8427194</td>\n",
       "<td>0.8115623</td>\n",
       "<td>0.7758774</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.6175691</td>\n",
       "<td>0.0024692</td>\n",
       "<td>0.6171947</td>\n",
       "<td>0.6239794</td>\n",
       "<td>0.6158515</td>\n",
       "<td>0.6173416</td>\n",
       "<td>0.6134782</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1734122</td>\n",
       "<td>0.0220306</td>\n",
       "<td>0.1317927</td>\n",
       "<td>0.1654276</td>\n",
       "<td>0.1572806</td>\n",
       "<td>0.1884377</td>\n",
       "<td>0.2241226</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>20643.4</td>\n",
       "<td>2622.5352</td>\n",
       "<td>15689.0</td>\n",
       "<td>19693.0</td>\n",
       "<td>18723.0</td>\n",
       "<td>22432.0</td>\n",
       "<td>26680.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.0781223</td>\n",
       "<td>0.0020707</td>\n",
       "<td>0.0811909</td>\n",
       "<td>0.0800795</td>\n",
       "<td>0.0785766</td>\n",
       "<td>0.0780661</td>\n",
       "<td>0.0726983</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.1067468</td>\n",
       "<td>0.0014467</td>\n",
       "<td>0.1060908</td>\n",
       "<td>0.1092768</td>\n",
       "<td>0.1061727</td>\n",
       "<td>0.1086386</td>\n",
       "<td>0.1035549</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.1694280</td>\n",
       "<td>0.0070919</td>\n",
       "<td>0.1530193</td>\n",
       "<td>0.1719818</td>\n",
       "<td>0.1636449</td>\n",
       "<td>0.1785714</td>\n",
       "<td>0.1799225</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.1388187</td>\n",
       "<td>0.1469255</td>\n",
       "<td>3.4482324</td>\n",
       "<td>3.2725856</td>\n",
       "<td>3.129951</td>\n",
       "<td>2.8590188</td>\n",
       "<td>2.984306</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.1544154</td>\n",
       "<td>0.0006155</td>\n",
       "<td>0.1531077</td>\n",
       "<td>0.1537213</td>\n",
       "<td>0.1546678</td>\n",
       "<td>0.1553251</td>\n",
       "<td>0.1552551</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.7163328</td>\n",
       "<td>0.0331931</td>\n",
       "<td>0.7829837</td>\n",
       "<td>0.7214664</td>\n",
       "<td>0.7439558</td>\n",
       "<td>0.6871854</td>\n",
       "<td>0.6460726</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.0677430</td>\n",
       "<td>0.0018015</td>\n",
       "<td>0.0649084</td>\n",
       "<td>0.0705183</td>\n",
       "<td>0.0654701</td>\n",
       "<td>0.0710103</td>\n",
       "<td>0.0668081</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5653883</td>\n",
       "<td>0.0048539</td>\n",
       "<td>0.5547841</td>\n",
       "<td>0.5670648</td>\n",
       "<td>0.5604888</td>\n",
       "<td>0.5716918</td>\n",
       "<td>0.5729119</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4346117</td>\n",
       "<td>0.0048539</td>\n",
       "<td>0.4452159</td>\n",
       "<td>0.4329352</td>\n",
       "<td>0.4395112</td>\n",
       "<td>0.4283082</td>\n",
       "<td>0.4270881</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0349637</td>\n",
       "<td>0.0001504</td>\n",
       "<td>0.0345943</td>\n",
       "<td>0.0348903</td>\n",
       "<td>0.0350133</td>\n",
       "<td>0.0352074</td>\n",
       "<td>0.0351132</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.0663067</td>\n",
       "<td>0.0022526</td>\n",
       "<td>0.0702059</td>\n",
       "<td>0.0679721</td>\n",
       "<td>0.0669718</td>\n",
       "<td>0.0657338</td>\n",
       "<td>0.0606502</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.0044233</td>\n",
       "<td>0.0006293</td>\n",
       "<td>0.0041567</td>\n",
       "<td>0.0061132</td>\n",
       "<td>0.0039433</td>\n",
       "<td>0.0043746</td>\n",
       "<td>0.0035287</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.2836672</td>\n",
       "<td>0.0331931</td>\n",
       "<td>0.2170163</td>\n",
       "<td>0.2785336</td>\n",
       "<td>0.2560442</td>\n",
       "<td>0.3128147</td>\n",
       "<td>0.3539274</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.186985</td>\n",
       "<td>0.0004025</td>\n",
       "<td>0.1859954</td>\n",
       "<td>0.1867895</td>\n",
       "<td>0.1871184</td>\n",
       "<td>0.1876364</td>\n",
       "<td>0.1873853</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8471093</td>\n",
       "<td>0.0240350</td>\n",
       "<td>0.8925518</td>\n",
       "<td>0.8555961</td>\n",
       "<td>0.8649334</td>\n",
       "<td>0.8305689</td>\n",
       "<td>0.7918963</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.826588    0.0220306    0.868207      0.834572      0.842719      0.811562      0.775877\n",
       "auc                      0.617569    0.00246921   0.617195      0.623979      0.615851      0.617342      0.613478\n",
       "err                      0.173412    0.0220306    0.131793      0.165428      0.157281      0.188438      0.224123\n",
       "err_count                20643.4     2622.54      15689         19693         18723         22432         26680\n",
       "f0point5                 0.0781223   0.00207067   0.0811909     0.0800795     0.0785766     0.0780661     0.0726983\n",
       "f1                       0.106747    0.00144665   0.106091      0.109277      0.106173      0.108639      0.103555\n",
       "f2                       0.169428    0.00709188   0.153019      0.171982      0.163645      0.178571      0.179922\n",
       "lift_top_group           3.13882     0.146926     3.44823       3.27259       3.12995       2.85902       2.98431\n",
       "logloss                  0.154415    0.000615476  0.153108      0.153721      0.154668      0.155325      0.155255\n",
       "max_per_class_error      0.716333    0.0331931    0.782984      0.721466      0.743956      0.687185      0.646073\n",
       "mcc                      0.067743    0.00180146   0.0649084     0.0705183     0.0654701     0.0710103     0.0668081\n",
       "mean_per_class_accuracy  0.565388    0.00485389   0.554784      0.567065      0.560489      0.571692      0.572912\n",
       "mean_per_class_error     0.434612    0.00485389   0.445216      0.432935      0.439511      0.428308      0.427088\n",
       "mse                      0.0349637   0.000150354  0.0345943     0.0348903     0.0350133     0.0352074     0.0351132\n",
       "precision                0.0663067   0.00225264   0.0702059     0.0679721     0.0669718     0.0657338     0.0606502\n",
       "r2                       0.00442331  0.000629273  0.00415671    0.00611321    0.00394334    0.00437457    0.00352873\n",
       "recall                   0.283667    0.0331931    0.217016      0.278534      0.256044      0.312815      0.353927\n",
       "rmse                     0.186985    0.00040247   0.185995      0.186789      0.187118      0.187636      0.187385\n",
       "specificity              0.847109    0.024035     0.892552      0.855596      0.864933      0.830569      0.791896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:11</td>\n",
       "<td> 4 min 48.942 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1874009</td>\n",
       "<td>0.1564850</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9635525</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:12</td>\n",
       "<td> 4 min 50.120 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1871565</td>\n",
       "<td>0.1552321</td>\n",
       "<td>0.6141815</td>\n",
       "<td>1.9872232</td>\n",
       "<td>0.1517375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:12</td>\n",
       "<td> 4 min 50.530 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1869539</td>\n",
       "<td>0.1542612</td>\n",
       "<td>0.6279385</td>\n",
       "<td>2.6797822</td>\n",
       "<td>0.1680779</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:13</td>\n",
       "<td> 4 min 51.346 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1868145</td>\n",
       "<td>0.1536090</td>\n",
       "<td>0.6348566</td>\n",
       "<td>2.9827315</td>\n",
       "<td>0.1512503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:14</td>\n",
       "<td> 4 min 52.247 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1866908</td>\n",
       "<td>0.1530483</td>\n",
       "<td>0.6400460</td>\n",
       "<td>3.1114270</td>\n",
       "<td>0.1415613</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:15</td>\n",
       "<td> 4 min 53.176 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1865776</td>\n",
       "<td>0.1525560</td>\n",
       "<td>0.6434592</td>\n",
       "<td>3.3454907</td>\n",
       "<td>0.1373847</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:22</td>\n",
       "<td> 4 min 59.705 sec</td>\n",
       "<td>22.0</td>\n",
       "<td>0.1858738</td>\n",
       "<td>0.1496622</td>\n",
       "<td>0.6724275</td>\n",
       "<td>4.3507903</td>\n",
       "<td>0.1042234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:34</td>\n",
       "<td> 5 min 12.186 sec</td>\n",
       "<td>53.0</td>\n",
       "<td>0.1852187</td>\n",
       "<td>0.1472278</td>\n",
       "<td>0.6982537</td>\n",
       "<td>5.1849991</td>\n",
       "<td>0.1066578</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-07 03:33:53</td>\n",
       "<td> 5 min 31.446 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.1843478</td>\n",
       "<td>0.1441742</td>\n",
       "<td>0.7281207</td>\n",
       "<td>6.4616611</td>\n",
       "<td>0.0858182</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2017-11-07 03:33:11  4 min 48.942 sec  0                  0.187401         0.156485            0.5             1                0.963552\n",
       "    2017-11-07 03:33:12  4 min 50.120 sec  1                  0.187157         0.155232            0.614181        1.98722          0.151738\n",
       "    2017-11-07 03:33:12  4 min 50.530 sec  2                  0.186954         0.154261            0.627939        2.67978          0.168078\n",
       "    2017-11-07 03:33:13  4 min 51.346 sec  3                  0.186814         0.153609            0.634857        2.98273          0.15125\n",
       "    2017-11-07 03:33:14  4 min 52.247 sec  4                  0.186691         0.153048            0.640046        3.11143          0.141561\n",
       "    2017-11-07 03:33:15  4 min 53.176 sec  5                  0.186578         0.152556            0.643459        3.34549          0.137385\n",
       "    2017-11-07 03:33:22  4 min 59.705 sec  22                 0.185874         0.149662            0.672427        4.35079          0.104223\n",
       "    2017-11-07 03:33:34  5 min 12.186 sec  53                 0.185219         0.147228            0.698254        5.185            0.106658\n",
       "    2017-11-07 03:33:53  5 min 31.446 sec  100                0.184348         0.144174            0.728121        6.46166          0.0858182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ps_reg_01_plus_ps_car_04_cat</td>\n",
       "<td>406.4349365</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2161171</td></tr>\n",
       "<tr><td>ps_car_06_cat</td>\n",
       "<td>200.7972260</td>\n",
       "<td>0.4940452</td>\n",
       "<td>0.1067716</td></tr>\n",
       "<tr><td>ps_car_13</td>\n",
       "<td>191.3916168</td>\n",
       "<td>0.4709035</td>\n",
       "<td>0.1017703</td></tr>\n",
       "<tr><td>ps_reg_01_plus_ps_car_02_cat</td>\n",
       "<td>142.1145172</td>\n",
       "<td>0.3496612</td>\n",
       "<td>0.0755678</td></tr>\n",
       "<tr><td>ps_car_01_cat</td>\n",
       "<td>103.2764740</td>\n",
       "<td>0.2541033</td>\n",
       "<td>0.0549161</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>ps_car_04_cat_avg</td>\n",
       "<td>1.1248965</td>\n",
       "<td>0.0027677</td>\n",
       "<td>0.0005982</td></tr>\n",
       "<tr><td>ps_car_02_cat_avg</td>\n",
       "<td>1.1166131</td>\n",
       "<td>0.0027473</td>\n",
       "<td>0.0005937</td></tr>\n",
       "<tr><td>ps_car_02_cat</td>\n",
       "<td>0.9194434</td>\n",
       "<td>0.0022622</td>\n",
       "<td>0.0004889</td></tr>\n",
       "<tr><td>ps_ind_12_bin</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>ps_ind_14</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                      relative_importance    scaled_importance      percentage\n",
       "----------------------------  ---------------------  ---------------------  ---------------------\n",
       "ps_reg_01_plus_ps_car_04_cat  406.4349365234375      1.0                    0.21611714447104136\n",
       "ps_car_06_cat                 200.79722595214844     0.4940451912665959     0.10677163597618616\n",
       "ps_car_13                     191.39161682128906     0.4709034574104637     0.10177031053709004\n",
       "ps_reg_01_plus_ps_car_02_cat  142.11451721191406     0.34966117437524685    0.0755677745383692\n",
       "ps_car_01_cat                 103.27647399902344     0.2541033378735341     0.05491608778178841\n",
       "---                           ---                    ---                    ---\n",
       "ps_car_04_cat_avg             1.12489652633667       0.0027677161219426855  0.0005981509049807176\n",
       "ps_car_02_cat_avg             1.1166131496429443     0.002747335549434377   0.0005937463138475371\n",
       "ps_car_02_cat                 0.9194434285163879     0.0022622155378204485  0.0004889035622117763\n",
       "ps_ind_12_bin                 0.0                    0.0                    0.0\n",
       "ps_ind_14                     0.0                    0.0                    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5082102957884913"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gbm.gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541051478942457"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gbm.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAJTCAYAAAB0N5WdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naEZ9EXyrzjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2e4123160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_gbm.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# create hyperameter and search criteria lists (ranges are inclusive..exclusive))\n",
    "hyper_params_tune = {'max_depth' : list(range(22,27,1)),\n",
    "                    'sample_rate': [x/100. for x in range(20,101)],\n",
    "                    'col_sample_rate_per_tree': [x/100. for x in range(60,101)],\n",
    "                    'col_sample_rate_change_per_level': [x/100. for x in range(90,111)],\n",
    "                    'min_rows': [2**x for x in range(0,int(math.log(train.nrow,2)-1)+1)],\n",
    "                    'nbins': [2**x for x in range(4,10)],\n",
    "                    'nbins_cats': [2**x for x in range(8,13)],\n",
    "                    'min_split_improvement': [0,1e-8,1e-6,1e-4],\n",
    "                    'histogram_type': [\"QuantilesGlobal\",\"RoundRobin\",'UniformAdaptive','Random']}\n",
    "\n",
    "search_criteria_tune = {'strategy': \"RandomDiscrete\",\n",
    "                       'max_runtime_secs': 60*60*8,  ## limit the runtime to 60 minutes\n",
    "                       'max_models': 200,  ## build no more than 100 models\n",
    "                       'seed' : 1234,\n",
    "                       'stopping_rounds' : 5,\n",
    "                       'stopping_metric' : \"AUC\",\n",
    "                       'stopping_tolerance': 1e-3\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_rdf= H2ORandomForestEstimator(binomial_double_trees=True,\n",
    "                                 nfolds=nfolds,\n",
    "                                 fold_assignment=\"Stratified\",\n",
    "                                 keep_cross_validation_predictions=True,\n",
    "                                 stopping_rounds = 5,\n",
    "                                 stopping_metric = \"AUC\",\n",
    "                                 stopping_tolerance = 1e-4,\n",
    "                                 seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "Errors/Warnings building gridsearch model\n",
      "\n",
      "Hyper-parameter: col_sample_rate_change_per_level, 0.91\n",
      "Hyper-parameter: col_sample_rate_per_tree, 1.0\n",
      "Hyper-parameter: histogram_type, Random\n",
      "Hyper-parameter: max_depth, 23\n",
      "Hyper-parameter: min_rows, 262144.0\n",
      "Hyper-parameter: min_split_improvement, 1e-06\n",
      "Hyper-parameter: nbins, 16\n",
      "Hyper-parameter: nbins_cats, 2048\n",
      "Hyper-parameter: sample_rate, 0.61\n",
      "failure_details: Illegal argument(s) for DRF model: final_grid_model_12.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "failure_stack_traces: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: final_grid_model_12.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:20)\n",
      "\tat hex.ModelBuilder.cv_makeFramesAndBuilders(ModelBuilder.java:420)\n",
      "\tat hex.ModelBuilder.computeCrossValidation(ModelBuilder.java:279)\n",
      "\tat hex.ModelBuilder.trainModelNested(ModelBuilder.java:230)\n",
      "\tat hex.grid.GridSearch.startBuildModel(GridSearch.java:332)\n",
      "\tat hex.grid.GridSearch.buildModel(GridSearch.java:314)\n",
      "\tat hex.grid.GridSearch.gridSearch(GridSearch.java:213)\n",
      "\tat hex.grid.GridSearch.access$000(GridSearch.java:68)\n",
      "\tat hex.grid.GridSearch$1.compute2(GridSearch.java:135)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "\n",
      "\n",
      "Hyper-parameter: col_sample_rate_change_per_level, 0.91\n",
      "Hyper-parameter: col_sample_rate_per_tree, 0.99\n",
      "Hyper-parameter: histogram_type, UniformAdaptive\n",
      "Hyper-parameter: max_depth, 22\n",
      "Hyper-parameter: min_rows, 262144.0\n",
      "Hyper-parameter: min_split_improvement, 1e-08\n",
      "Hyper-parameter: nbins, 512\n",
      "Hyper-parameter: nbins_cats, 256\n",
      "Hyper-parameter: sample_rate, 0.78\n",
      "failure_details: Illegal argument(s) for DRF model: final_grid_model_39.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "failure_stack_traces: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: final_grid_model_39.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:20)\n",
      "\tat hex.ModelBuilder.cv_makeFramesAndBuilders(ModelBuilder.java:420)\n",
      "\tat hex.ModelBuilder.computeCrossValidation(ModelBuilder.java:279)\n",
      "\tat hex.ModelBuilder.trainModelNested(ModelBuilder.java:230)\n",
      "\tat hex.grid.GridSearch.startBuildModel(GridSearch.java:332)\n",
      "\tat hex.grid.GridSearch.buildModel(GridSearch.java:314)\n",
      "\tat hex.grid.GridSearch.gridSearch(GridSearch.java:213)\n",
      "\tat hex.grid.GridSearch.access$000(GridSearch.java:68)\n",
      "\tat hex.grid.GridSearch$1.compute2(GridSearch.java:135)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "\n",
      "\n",
      "Hyper-parameter: col_sample_rate_change_per_level, 1.08\n",
      "Hyper-parameter: col_sample_rate_per_tree, 0.99\n",
      "Hyper-parameter: histogram_type, UniformAdaptive\n",
      "Hyper-parameter: max_depth, 22\n",
      "Hyper-parameter: min_rows, 262144.0\n",
      "Hyper-parameter: min_split_improvement, 1e-08\n",
      "Hyper-parameter: nbins, 256\n",
      "Hyper-parameter: nbins_cats, 1024\n",
      "Hyper-parameter: sample_rate, 0.82\n",
      "failure_details: Illegal argument(s) for DRF model: final_grid_model_52.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "failure_stack_traces: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: final_grid_model_52.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476591.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476339.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476265.0.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 475152.99999999994.\n",
      "ERRR on field: _min_rows: The dataset size is too small to split for min_rows=262144.0: must have at least 524288.0 (weighted) rows, but have only 476500.0.\n",
      "\n",
      "\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:20)\n",
      "\tat hex.ModelBuilder.cv_makeFramesAndBuilders(ModelBuilder.java:420)\n",
      "\tat hex.ModelBuilder.computeCrossValidation(ModelBuilder.java:279)\n",
      "\tat hex.ModelBuilder.trainModelNested(ModelBuilder.java:230)\n",
      "\tat hex.grid.GridSearch.startBuildModel(GridSearch.java:332)\n",
      "\tat hex.grid.GridSearch.buildModel(GridSearch.java:314)\n",
      "\tat hex.grid.GridSearch.gridSearch(GridSearch.java:213)\n",
      "\tat hex.grid.GridSearch.access$000(GridSearch.java:68)\n",
      "\tat hex.grid.GridSearch$1.compute2(GridSearch.java:135)\n",
      "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n",
      "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
      "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
      "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
      "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
      "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_grid = H2OGridSearch(my_rdf, hyper_params = hyper_params_tune,\n",
    "                                    grid_id = 'final_grid',\n",
    "                                    search_criteria = search_criteria_tune)\n",
    "final_grid.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_final_grid = final_grid.get_grid(sort_by='auc',decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      col_sample_rate_change_per_level col_sample_rate_per_tree  \\\n",
      "0                                 0.92                      0.9   \n",
      "1                                 1.02                     0.85   \n",
      "2                                 1.04                     0.95   \n",
      "3                                 1.01                     0.99   \n",
      "4                                 1.02                     0.79   \n",
      "5                                 0.99                      1.0   \n",
      "6                                 0.94                     0.65   \n",
      "7                                 1.05                     0.88   \n",
      "8                                 1.02                     0.89   \n",
      "9                                 1.08                     0.63   \n",
      "10                                1.05                     0.97   \n",
      "11                                1.05                     0.88   \n",
      "12                                0.94                     0.63   \n",
      "13                                 0.9                     0.93   \n",
      "14                                1.09                     0.68   \n",
      "15                                0.93                     0.71   \n",
      "16                                1.03                     0.71   \n",
      "17                                0.99                     0.86   \n",
      "18                                0.95                     0.62   \n",
      "19                                0.94                     0.72   \n",
      "20                                1.03                     0.85   \n",
      "21                                1.07                      1.0   \n",
      "22                                 0.9                     0.79   \n",
      "23                                 0.9                     0.82   \n",
      "24                                0.95                     0.86   \n",
      "25                                 0.9                     0.99   \n",
      "26                                1.08                     0.74   \n",
      "27                                 1.0                     0.77   \n",
      "28                                 1.1                     0.95   \n",
      "29                                0.94                     0.99   \n",
      ".. ..                              ...                      ...   \n",
      "40                                0.98                     0.69   \n",
      "41                                 1.0                     0.96   \n",
      "42                                1.07                     0.85   \n",
      "43                                0.91                      0.7   \n",
      "44                                0.96                     0.74   \n",
      "45                                0.92                      0.7   \n",
      "46                                1.07                     0.86   \n",
      "47                                1.07                     0.63   \n",
      "48                                0.97                     0.63   \n",
      "49                                 1.0                     0.93   \n",
      "50                                0.92                     0.94   \n",
      "51                                 1.0                     0.93   \n",
      "52                                1.04                     0.62   \n",
      "53                                1.09                     0.83   \n",
      "54                                 1.0                     0.63   \n",
      "55                                0.99                     0.86   \n",
      "56                                1.07                      0.6   \n",
      "57                                0.99                     0.86   \n",
      "58                                1.09                     0.73   \n",
      "59                                1.08                     0.83   \n",
      "60                                0.93                     0.63   \n",
      "61                                1.04                     0.74   \n",
      "62                                1.05                     0.87   \n",
      "63                                0.93                     0.71   \n",
      "64                                0.96                     0.74   \n",
      "65                                0.96                     0.99   \n",
      "66                                1.04                     0.88   \n",
      "67                                 1.1                      0.7   \n",
      "68                                1.02                     0.81   \n",
      "69                                0.99                     0.71   \n",
      "\n",
      "     histogram_type max_depth  min_rows min_split_improvement nbins  \\\n",
      "0        RoundRobin        23     256.0                   0.0    32   \n",
      "1   QuantilesGlobal        25     256.0                1.0E-6   512   \n",
      "2        RoundRobin        22    1024.0                1.0E-6   128   \n",
      "3        RoundRobin        26    2048.0                1.0E-6   256   \n",
      "4   QuantilesGlobal        25    1024.0                1.0E-4    32   \n",
      "5        RoundRobin        22     128.0                1.0E-6    32   \n",
      "6   UniformAdaptive        26     512.0                1.0E-6   256   \n",
      "7   QuantilesGlobal        22    2048.0                1.0E-8   128   \n",
      "8   UniformAdaptive        24    2048.0                1.0E-8    64   \n",
      "9            Random        25     128.0                1.0E-8    16   \n",
      "10  QuantilesGlobal        22     256.0                1.0E-4    64   \n",
      "11  UniformAdaptive        25    4096.0                1.0E-6   256   \n",
      "12           Random        22     256.0                1.0E-6    64   \n",
      "13       RoundRobin        24      16.0                1.0E-8    32   \n",
      "14  QuantilesGlobal        26    4096.0                1.0E-4   512   \n",
      "15       RoundRobin        25      64.0                1.0E-8    32   \n",
      "16       RoundRobin        22    1024.0                1.0E-6   512   \n",
      "17           Random        26     128.0                1.0E-8   128   \n",
      "18  QuantilesGlobal        24     512.0                1.0E-8    16   \n",
      "19  UniformAdaptive        25    1024.0                1.0E-4    16   \n",
      "20  UniformAdaptive        25    4096.0                   0.0    16   \n",
      "21           Random        22      64.0                   0.0    16   \n",
      "22           Random        24      64.0                1.0E-8   256   \n",
      "23       RoundRobin        23    4096.0                1.0E-4   256   \n",
      "24  UniformAdaptive        22      32.0                1.0E-6   512   \n",
      "25  QuantilesGlobal        22       4.0                1.0E-4   128   \n",
      "26  QuantilesGlobal        25    2048.0                1.0E-8   256   \n",
      "27  UniformAdaptive        26    2048.0                   0.0   128   \n",
      "28       RoundRobin        26      64.0                1.0E-6   128   \n",
      "29  QuantilesGlobal        22    8192.0                   0.0    64   \n",
      "..              ...       ...       ...                   ...   ...   \n",
      "40  QuantilesGlobal        26    8192.0                1.0E-8   512   \n",
      "41       RoundRobin        22      16.0                1.0E-6    32   \n",
      "42  QuantilesGlobal        25   32768.0                1.0E-8   256   \n",
      "43  UniformAdaptive        24   16384.0                1.0E-4    64   \n",
      "44       RoundRobin        26   32768.0                1.0E-6   256   \n",
      "45  QuantilesGlobal        24       8.0                1.0E-6    64   \n",
      "46       RoundRobin        23      16.0                1.0E-6    16   \n",
      "47       RoundRobin        25      16.0                1.0E-6    64   \n",
      "48       RoundRobin        23       8.0                1.0E-6    16   \n",
      "49       RoundRobin        25   16384.0                1.0E-4    16   \n",
      "50  UniformAdaptive        23   32768.0                1.0E-6   512   \n",
      "51           Random        23       8.0                1.0E-8   256   \n",
      "52       RoundRobin        25   65536.0                   0.0   128   \n",
      "53       RoundRobin        24  131072.0                   0.0    32   \n",
      "54       RoundRobin        22  131072.0                1.0E-8   512   \n",
      "55  QuantilesGlobal        26       4.0                   0.0    64   \n",
      "56  UniformAdaptive        23  131072.0                   0.0   128   \n",
      "57           Random        23  131072.0                   0.0    16   \n",
      "58           Random        23       2.0                1.0E-4    16   \n",
      "59  QuantilesGlobal        23       4.0                1.0E-4    32   \n",
      "60  QuantilesGlobal        23       2.0                1.0E-8   128   \n",
      "61           Random        25  131072.0                1.0E-6    16   \n",
      "62       RoundRobin        22       4.0                1.0E-4    16   \n",
      "63       RoundRobin        23       1.0                1.0E-8   128   \n",
      "64  UniformAdaptive        24       2.0                1.0E-6   128   \n",
      "65           Random        22       1.0                1.0E-8    32   \n",
      "66  QuantilesGlobal        25       2.0                1.0E-8    16   \n",
      "67  QuantilesGlobal        25       2.0                1.0E-6    16   \n",
      "68  QuantilesGlobal        24       1.0                1.0E-4    32   \n",
      "69  QuantilesGlobal        24       1.0                   0.0    32   \n",
      "\n",
      "   nbins_cats sample_rate            model_ids                 auc  \n",
      "0        1024        0.99  final_grid_model_53  0.6312959503531086  \n",
      "1        1024        0.75  final_grid_model_70  0.6311954603113105  \n",
      "2        2048        0.94   final_grid_model_1  0.6310417194374809  \n",
      "3        2048        0.92  final_grid_model_55  0.6304937099069117  \n",
      "4         512        0.76  final_grid_model_54  0.6303646361669227  \n",
      "5         256        0.77  final_grid_model_21  0.6302576585305211  \n",
      "6        2048        0.62  final_grid_model_16  0.6297596825579629  \n",
      "7         256        0.85  final_grid_model_18   0.629533626319379  \n",
      "8        1024        0.69  final_grid_model_71  0.6293845866569712  \n",
      "9        4096        0.85  final_grid_model_36  0.6293457084695762  \n",
      "10       1024        0.35  final_grid_model_51  0.6289671007655814  \n",
      "11        256        0.97  final_grid_model_30  0.6285967193778389  \n",
      "12       4096        0.73  final_grid_model_68  0.6285529968336767  \n",
      "13        256        0.97  final_grid_model_41  0.6279797355318485  \n",
      "14        256         1.0  final_grid_model_22   0.627960862529366  \n",
      "15        512         0.5   final_grid_model_0  0.6275202807674312  \n",
      "16       2048        0.34  final_grid_model_23  0.6274977054363751  \n",
      "17        256        0.47  final_grid_model_24  0.6271646980042973  \n",
      "18       1024        0.24  final_grid_model_46  0.6267625812693713  \n",
      "19        512        0.36  final_grid_model_35  0.6265681602726775  \n",
      "20       2048         0.6  final_grid_model_40  0.6263995762070893  \n",
      "21       2048        0.85  final_grid_model_48  0.6262931705090806  \n",
      "22       4096         0.7  final_grid_model_44  0.6259289787710817  \n",
      "23        512        0.79  final_grid_model_59  0.6248654218754076  \n",
      "24       2048        0.66  final_grid_model_34  0.6247253373970593  \n",
      "25        512        0.91  final_grid_model_37  0.6239513069520944  \n",
      "26        512        0.27  final_grid_model_26  0.6236661453895629  \n",
      "27       4096        0.25  final_grid_model_13  0.6236099737816464  \n",
      "28       1024        0.29  final_grid_model_14  0.6222806577065058  \n",
      "29        512        0.65   final_grid_model_7  0.6221481975462979  \n",
      "..        ...         ...                  ...                 ...  \n",
      "40        512        0.31  final_grid_model_27  0.6155945358604412  \n",
      "41       2048        0.86  final_grid_model_17  0.6155888361278526  \n",
      "42       4096        0.71  final_grid_model_25  0.6145222270856775  \n",
      "43       4096        0.56   final_grid_model_5  0.6140892829437109  \n",
      "44        512        0.96  final_grid_model_38  0.6133781647574813  \n",
      "45       4096        0.37  final_grid_model_50  0.6131560259673572  \n",
      "46       2048        0.64  final_grid_model_57  0.6115698709343022  \n",
      "47        256        0.55  final_grid_model_19  0.6099542351937205  \n",
      "48       4096        0.78  final_grid_model_15  0.6091366284845087  \n",
      "49        512        0.34  final_grid_model_11  0.6090804700578591  \n",
      "50        512        0.53  final_grid_model_20  0.6074372253898609  \n",
      "51        256         0.4   final_grid_model_8  0.6066889795528015  \n",
      "52        256        0.91  final_grid_model_56  0.6019177649936284  \n",
      "53       2048        0.31  final_grid_model_61  0.5980234284792436  \n",
      "54       2048        0.67  final_grid_model_69  0.5963172155723117  \n",
      "55       2048        0.45  final_grid_model_58  0.5949150702639352  \n",
      "56        512        0.52  final_grid_model_31  0.5937094497307003  \n",
      "57       1024        0.92  final_grid_model_42   0.593241174890211  \n",
      "58       1024        0.98  final_grid_model_62  0.5932316888788447  \n",
      "59       1024        0.77  final_grid_model_43  0.5926784184152449  \n",
      "60        256        0.35  final_grid_model_67  0.5917950363394561  \n",
      "61       1024        0.31  final_grid_model_28  0.5905428797849028  \n",
      "62        256        0.64  final_grid_model_72  0.5873622971475455  \n",
      "63       2048        0.42   final_grid_model_2  0.5869964011681633  \n",
      "64       1024        0.26   final_grid_model_4  0.5846729811374367  \n",
      "65       2048         0.5  final_grid_model_10  0.5846566242700524  \n",
      "66       2048        0.99  final_grid_model_65  0.5846397731855267  \n",
      "67        256        0.37  final_grid_model_49  0.5818555916365379  \n",
      "68       2048         0.7  final_grid_model_63    0.57868618723608  \n",
      "69       1024        0.73  final_grid_model_45  0.5784425349704473  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 rows x 12 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_final_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = h2o.get_model(sorted_final_grid.sorted_metric_table()['model_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "my_rdf= H2ORandomForestEstimator(binomial_double_trees=True,\n",
    "                                 max_depth=23,\n",
    "                                 min_rows=256,\n",
    "                                 min_split_improvement=0,\n",
    "                                 nbins=32,\n",
    "                                 nbins_cats=1024,\n",
    "                                 sample_rate=0.99,\n",
    "                                 col_sample_rate_change_per_level=0.92,\n",
    "                                 col_sample_rate_per_tree=0.9,\n",
    "                                 histogram_type='RoundRobin',\n",
    "                                 nfolds=nfolds,\n",
    "                                 fold_assignment=\"Modulo\",\n",
    "                                 keep_cross_validation_predictions=True,\n",
    "                                 stopping_rounds = 5,\n",
    "                                 stopping_metric = \"AUC\",\n",
    "                                 stopping_tolerance = 1e-4,\n",
    "                                 seed=1)\n",
    "my_rdf.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1509234555216_13641\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.03530859637047687\n",
      "RMSE: 0.1879058178196643\n",
      "LogLoss: 0.16085840877783458\n",
      "Mean Per-Class Error: 0.43661764093759303\n",
      "AUC: 0.5869001214614877\n",
      "Gini: 0.17380024292297547\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.05673730037073246: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>194607.0</td>\n",
       "<td>31239.0</td>\n",
       "<td>0.1383</td>\n",
       "<td> (31239.0/225846.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>6576.0</td>\n",
       "<td>2034.0</td>\n",
       "<td>0.7638</td>\n",
       "<td> (6576.0/8610.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>201183.0</td>\n",
       "<td>33273.0</td>\n",
       "<td>0.1613</td>\n",
       "<td> (37815.0/234456.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      194607  31239  0.1383   (31239.0/225846.0)\n",
       "1      6576    2034   0.7638   (6576.0/8610.0)\n",
       "Total  201183  33273  0.1613   (37815.0/234456.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0567373</td>\n",
       "<td>0.0971277</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0340894</td>\n",
       "<td>0.1761752</td>\n",
       "<td>259.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0736991</td>\n",
       "<td>0.0748483</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2296377</td>\n",
       "<td>0.9632724</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.1935382</td>\n",
       "<td>0.4</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.2296377</td>\n",
       "<td>0.9999911</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0567373</td>\n",
       "<td>0.0527745</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0350227</td>\n",
       "<td>0.5599037</td>\n",
       "<td>255.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0340894</td>\n",
       "<td>0.5633824</td>\n",
       "<td>259.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value      idx\n",
       "---------------------------  -----------  ---------  -----\n",
       "max f1                       0.0567373    0.0971277  165\n",
       "max f2                       0.0340894    0.176175   259\n",
       "max f0point5                 0.0736991    0.0748483  114\n",
       "max accuracy                 0.229638     0.963272   0\n",
       "max precision                0.193538     0.4        2\n",
       "max recall                   0            1          399\n",
       "max specificity              0.229638     0.999991   0\n",
       "max absolute_mcc             0.0567373    0.0527745  165\n",
       "max min_per_class_accuracy   0.0350227    0.559904   255\n",
       "max mean_per_class_accuracy  0.0340894    0.563382   259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100015</td>\n",
       "<td>0.0788738</td>\n",
       "<td>5.8071990</td>\n",
       "<td>5.8071990</td>\n",
       "<td>0.2116580</td>\n",
       "<td>0.2116580</td>\n",
       "<td>0.0580806</td>\n",
       "<td>0.0580806</td>\n",
       "<td>480.7198953</td>\n",
       "<td>480.7198953</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200013</td>\n",
       "<td>0.0716358</td>\n",
       "<td>4.0933802</td>\n",
       "<td>4.9503616</td>\n",
       "<td>0.1491935</td>\n",
       "<td>0.1804284</td>\n",
       "<td>0.0409330</td>\n",
       "<td>0.0990136</td>\n",
       "<td>309.3380212</td>\n",
       "<td>395.0361562</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300011</td>\n",
       "<td>0.0674308</td>\n",
       "<td>3.7799232</td>\n",
       "<td>4.5602373</td>\n",
       "<td>0.1377688</td>\n",
       "<td>0.1662093</td>\n",
       "<td>0.0377985</td>\n",
       "<td>0.1368120</td>\n",
       "<td>277.9923169</td>\n",
       "<td>356.0237279</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400009</td>\n",
       "<td>0.0643628</td>\n",
       "<td>3.2590313</td>\n",
       "<td>4.2349495</td>\n",
       "<td>0.1187836</td>\n",
       "<td>0.1543534</td>\n",
       "<td>0.0325897</td>\n",
       "<td>0.1694017</td>\n",
       "<td>225.9031318</td>\n",
       "<td>323.4949452</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.0619731</td>\n",
       "<td>3.0884738</td>\n",
       "<td>4.0056620</td>\n",
       "<td>0.1125672</td>\n",
       "<td>0.1459964</td>\n",
       "<td>0.0308841</td>\n",
       "<td>0.2002858</td>\n",
       "<td>208.8473809</td>\n",
       "<td>300.5662028</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000013</td>\n",
       "<td>0.0541462</td>\n",
       "<td>2.4808369</td>\n",
       "<td>3.2432495</td>\n",
       "<td>0.0904203</td>\n",
       "<td>0.1182084</td>\n",
       "<td>0.1240435</td>\n",
       "<td>0.3243293</td>\n",
       "<td>148.0836943</td>\n",
       "<td>224.3249485</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500003</td>\n",
       "<td>0.0493419</td>\n",
       "<td>2.1416492</td>\n",
       "<td>2.8760576</td>\n",
       "<td>0.0780578</td>\n",
       "<td>0.1048252</td>\n",
       "<td>0.1070803</td>\n",
       "<td>0.4314096</td>\n",
       "<td>114.1649152</td>\n",
       "<td>187.6057600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000010</td>\n",
       "<td>0.0458793</td>\n",
       "<td>1.7138149</td>\n",
       "<td>2.5854945</td>\n",
       "<td>0.0624643</td>\n",
       "<td>0.0942349</td>\n",
       "<td>0.0856919</td>\n",
       "<td>0.5171015</td>\n",
       "<td>71.3814893</td>\n",
       "<td>158.5494482</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000007</td>\n",
       "<td>0.0408555</td>\n",
       "<td>1.3515303</td>\n",
       "<td>2.1741754</td>\n",
       "<td>0.0492599</td>\n",
       "<td>0.0792433</td>\n",
       "<td>0.1351526</td>\n",
       "<td>0.6522541</td>\n",
       "<td>35.1530309</td>\n",
       "<td>117.4175395</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000003</td>\n",
       "<td>0.0371265</td>\n",
       "<td>0.9956704</td>\n",
       "<td>1.8795504</td>\n",
       "<td>0.0362897</td>\n",
       "<td>0.0685049</td>\n",
       "<td>0.0995667</td>\n",
       "<td>0.7518208</td>\n",
       "<td>-0.4329650</td>\n",
       "<td>87.9550371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0340143</td>\n",
       "<td>0.7684178</td>\n",
       "<td>1.6573246</td>\n",
       "<td>0.0280069</td>\n",
       "<td>0.0604054</td>\n",
       "<td>0.0768415</td>\n",
       "<td>0.8286623</td>\n",
       "<td>-23.1582188</td>\n",
       "<td>65.7324606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999997</td>\n",
       "<td>0.0311604</td>\n",
       "<td>0.5960193</td>\n",
       "<td>1.4804409</td>\n",
       "<td>0.0217234</td>\n",
       "<td>0.0539584</td>\n",
       "<td>0.0596017</td>\n",
       "<td>0.8882640</td>\n",
       "<td>-40.3980665</td>\n",
       "<td>48.0440889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999993</td>\n",
       "<td>0.0283239</td>\n",
       "<td>0.4637242</td>\n",
       "<td>1.3351960</td>\n",
       "<td>0.0169016</td>\n",
       "<td>0.0486646</td>\n",
       "<td>0.0463723</td>\n",
       "<td>0.9346363</td>\n",
       "<td>-53.6275754</td>\n",
       "<td>33.5196003</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999990</td>\n",
       "<td>0.0253536</td>\n",
       "<td>0.3512504</td>\n",
       "<td>1.2122031</td>\n",
       "<td>0.0128022</td>\n",
       "<td>0.0441818</td>\n",
       "<td>0.0351249</td>\n",
       "<td>0.9697612</td>\n",
       "<td>-64.8749626</td>\n",
       "<td>21.2203058</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999987</td>\n",
       "<td>0.0219148</td>\n",
       "<td>0.2290964</td>\n",
       "<td>1.1029692</td>\n",
       "<td>0.0083500</td>\n",
       "<td>0.0402005</td>\n",
       "<td>0.0229096</td>\n",
       "<td>0.9926708</td>\n",
       "<td>-77.0903628</td>\n",
       "<td>10.2969186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0104286</td>\n",
       "<td>0.0732912</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0026713</td>\n",
       "<td>0.0364475</td>\n",
       "<td>0.0073292</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.6708831</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain       cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  ---------  -----------------\n",
       "    1        0.0100015                   0.0788738          5.8072     5.8072             0.211658         0.211658                    0.0580806       0.0580806                  480.72     480.72\n",
       "    2        0.0200013                   0.0716358          4.09338    4.95036            0.149194         0.180428                    0.040933        0.0990136                  309.338    395.036\n",
       "    3        0.0300011                   0.0674308          3.77992    4.56024            0.137769         0.166209                    0.0377985       0.136812                   277.992    356.024\n",
       "    4        0.0400009                   0.0643628          3.25903    4.23495            0.118784         0.154353                    0.0325897       0.169402                   225.903    323.495\n",
       "    5        0.0500007                   0.0619731          3.08847    4.00566            0.112567         0.145996                    0.0308841       0.200286                   208.847    300.566\n",
       "    6        0.100001                    0.0541462          2.48084    3.24325            0.0904203        0.118208                    0.124044        0.324329                   148.084    224.325\n",
       "    7        0.15                        0.0493419          2.14165    2.87606            0.0780578        0.104825                    0.10708         0.43141                    114.165    187.606\n",
       "    8        0.200001                    0.0458793          1.71381    2.58549            0.0624643        0.0942349                   0.0856919       0.517102                   71.3815    158.549\n",
       "    9        0.300001                    0.0408555          1.35153    2.17418            0.0492599        0.0792433                   0.135153        0.652254                   35.153     117.418\n",
       "    10       0.4                         0.0371265          0.99567    1.87955            0.0362897        0.0685049                   0.0995667       0.751821                   -0.432965  87.955\n",
       "    11       0.5                         0.0340143          0.768418   1.65732            0.0280069        0.0604054                   0.0768415       0.828662                   -23.1582   65.7325\n",
       "    12       0.6                         0.0311604          0.596019   1.48044            0.0217234        0.0539584                   0.0596017       0.888264                   -40.3981   48.0441\n",
       "    13       0.699999                    0.0283239          0.463724   1.3352             0.0169016        0.0486646                   0.0463723       0.934636                   -53.6276   33.5196\n",
       "    14       0.799999                    0.0253536          0.35125    1.2122             0.0128022        0.0441818                   0.0351249       0.969761                   -64.875    21.2203\n",
       "    15       0.899999                    0.0219148          0.229096   1.10297            0.00834999       0.0402005                   0.0229096       0.992671                   -77.0904   10.2969\n",
       "    16       1                           0.0104286          0.0732912  1                  0.00267128       0.0364475                   0.00732922      1                          -92.6709   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.03482308997743171\n",
      "RMSE: 0.18660945843507426\n",
      "LogLoss: 0.1526803942909237\n",
      "Mean Per-Class Error: 0.40563381742836535\n",
      "AUC: 0.6320304779070305\n",
      "Gini: 0.26406095581406097\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.05267112225883115: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>511316.0</td>\n",
       "<td>62202.0</td>\n",
       "<td>0.1085</td>\n",
       "<td> (62202.0/573518.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>16680.0</td>\n",
       "<td>5014.0</td>\n",
       "<td>0.7689</td>\n",
       "<td> (16680.0/21694.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>527996.0</td>\n",
       "<td>67216.0</td>\n",
       "<td>0.1325</td>\n",
       "<td> (78882.0/595212.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      511316  62202  0.1085   (62202.0/573518.0)\n",
       "1      16680   5014   0.7689   (16680.0/21694.0)\n",
       "Total  527996  67216  0.1325   (78882.0/595212.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0526711</td>\n",
       "<td>0.1127882</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0402720</td>\n",
       "<td>0.1956690</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0661198</td>\n",
       "<td>0.0937531</td>\n",
       "<td>86.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1321680</td>\n",
       "<td>0.9635508</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.1022925</td>\n",
       "<td>0.1831395</td>\n",
       "<td>13.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0122662</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.1321680</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0432083</td>\n",
       "<td>0.0761785</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0368850</td>\n",
       "<td>0.5929289</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0368850</td>\n",
       "<td>0.5943662</td>\n",
       "<td>241.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value      idx\n",
       "---------------------------  -----------  ---------  -----\n",
       "max f1                       0.0526711    0.112788   142\n",
       "max f2                       0.040272     0.195669   216\n",
       "max f0point5                 0.0661198    0.0937531  86\n",
       "max accuracy                 0.132168     0.963551   0\n",
       "max precision                0.102293     0.18314    13\n",
       "max recall                   0.0122662    1          398\n",
       "max specificity              0.132168     0.999998   0\n",
       "max absolute_mcc             0.0432083    0.0761785  196\n",
       "max min_per_class_accuracy   0.036885     0.592929   241\n",
       "max mean_per_class_accuracy  0.036885     0.594366   241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100015</td>\n",
       "<td>0.0778017</td>\n",
       "<td>3.2308305</td>\n",
       "<td>3.2308305</td>\n",
       "<td>0.1177558</td>\n",
       "<td>0.1177558</td>\n",
       "<td>0.0323131</td>\n",
       "<td>0.0323131</td>\n",
       "<td>223.0830529</td>\n",
       "<td>223.0830529</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200013</td>\n",
       "<td>0.0709673</td>\n",
       "<td>2.4385114</td>\n",
       "<td>2.8347042</td>\n",
       "<td>0.0888777</td>\n",
       "<td>0.1033179</td>\n",
       "<td>0.0243846</td>\n",
       "<td>0.0566977</td>\n",
       "<td>143.8511410</td>\n",
       "<td>183.4704246</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300011</td>\n",
       "<td>0.0669932</td>\n",
       "<td>2.3048312</td>\n",
       "<td>2.6580898</td>\n",
       "<td>0.0840054</td>\n",
       "<td>0.0968808</td>\n",
       "<td>0.0230478</td>\n",
       "<td>0.0797456</td>\n",
       "<td>130.4831201</td>\n",
       "<td>165.8089789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400009</td>\n",
       "<td>0.0640017</td>\n",
       "<td>2.0789577</td>\n",
       "<td>2.5133129</td>\n",
       "<td>0.0757728</td>\n",
       "<td>0.0916040</td>\n",
       "<td>0.0207892</td>\n",
       "<td>0.1005347</td>\n",
       "<td>107.8957743</td>\n",
       "<td>151.3312858</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.0616470</td>\n",
       "<td>1.9775452</td>\n",
       "<td>2.4061629</td>\n",
       "<td>0.0720766</td>\n",
       "<td>0.0876987</td>\n",
       "<td>0.0197751</td>\n",
       "<td>0.1203098</td>\n",
       "<td>97.7545170</td>\n",
       "<td>140.6162921</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000013</td>\n",
       "<td>0.0539497</td>\n",
       "<td>1.7921765</td>\n",
       "<td>2.0991697</td>\n",
       "<td>0.0653204</td>\n",
       "<td>0.0765095</td>\n",
       "<td>0.0896100</td>\n",
       "<td>0.2099198</td>\n",
       "<td>79.2176521</td>\n",
       "<td>109.9169721</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500003</td>\n",
       "<td>0.0492846</td>\n",
       "<td>1.5184228</td>\n",
       "<td>1.9055917</td>\n",
       "<td>0.0553427</td>\n",
       "<td>0.0694541</td>\n",
       "<td>0.0759196</td>\n",
       "<td>0.2858394</td>\n",
       "<td>51.8422795</td>\n",
       "<td>90.5591749</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000010</td>\n",
       "<td>0.0458691</td>\n",
       "<td>1.3607266</td>\n",
       "<td>1.7693743</td>\n",
       "<td>0.0495951</td>\n",
       "<td>0.0644893</td>\n",
       "<td>0.0680372</td>\n",
       "<td>0.3538766</td>\n",
       "<td>36.0726617</td>\n",
       "<td>76.9374322</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000007</td>\n",
       "<td>0.0409223</td>\n",
       "<td>1.2381345</td>\n",
       "<td>1.5922954</td>\n",
       "<td>0.0451269</td>\n",
       "<td>0.0580352</td>\n",
       "<td>0.1238130</td>\n",
       "<td>0.4776897</td>\n",
       "<td>23.8134519</td>\n",
       "<td>59.2295379</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000003</td>\n",
       "<td>0.0371982</td>\n",
       "<td>1.0311642</td>\n",
       "<td>1.4520132</td>\n",
       "<td>0.0375834</td>\n",
       "<td>0.0529223</td>\n",
       "<td>0.1031161</td>\n",
       "<td>0.5808058</td>\n",
       "<td>3.1164154</td>\n",
       "<td>45.2013162</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0340670</td>\n",
       "<td>0.9343629</td>\n",
       "<td>1.3484835</td>\n",
       "<td>0.0340552</td>\n",
       "<td>0.0491489</td>\n",
       "<td>0.0934360</td>\n",
       "<td>0.6742417</td>\n",
       "<td>-6.5637130</td>\n",
       "<td>34.8483452</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999997</td>\n",
       "<td>0.0311661</td>\n",
       "<td>0.8394054</td>\n",
       "<td>1.2636374</td>\n",
       "<td>0.0305942</td>\n",
       "<td>0.0460564</td>\n",
       "<td>0.0839403</td>\n",
       "<td>0.7581820</td>\n",
       "<td>-16.0594580</td>\n",
       "<td>26.3637351</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999993</td>\n",
       "<td>0.0283308</td>\n",
       "<td>0.7624254</td>\n",
       "<td>1.1920358</td>\n",
       "<td>0.0277885</td>\n",
       "<td>0.0434467</td>\n",
       "<td>0.0762423</td>\n",
       "<td>0.8344243</td>\n",
       "<td>-23.7574648</td>\n",
       "<td>19.2035808</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999990</td>\n",
       "<td>0.0253696</td>\n",
       "<td>0.6743823</td>\n",
       "<td>1.1273293</td>\n",
       "<td>0.0245796</td>\n",
       "<td>0.0410884</td>\n",
       "<td>0.0674380</td>\n",
       "<td>0.9018623</td>\n",
       "<td>-32.5617721</td>\n",
       "<td>12.7329253</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999987</td>\n",
       "<td>0.0219068</td>\n",
       "<td>0.5711276</td>\n",
       "<td>1.0655292</td>\n",
       "<td>0.0208162</td>\n",
       "<td>0.0388359</td>\n",
       "<td>0.0571126</td>\n",
       "<td>0.9589748</td>\n",
       "<td>-42.8872424</td>\n",
       "<td>6.5529182</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0100407</td>\n",
       "<td>0.4102462</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0149525</td>\n",
       "<td>0.0364475</td>\n",
       "<td>0.0410252</td>\n",
       "<td>1.0</td>\n",
       "<td>-58.9753831</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100015                   0.0778017          3.23083   3.23083            0.117756         0.117756                    0.0323131       0.0323131                  223.083   223.083\n",
       "    2        0.0200013                   0.0709673          2.43851   2.8347             0.0888777        0.103318                    0.0243846       0.0566977                  143.851   183.47\n",
       "    3        0.0300011                   0.0669932          2.30483   2.65809            0.0840054        0.0968808                   0.0230478       0.0797456                  130.483   165.809\n",
       "    4        0.0400009                   0.0640017          2.07896   2.51331            0.0757728        0.091604                    0.0207892       0.100535                   107.896   151.331\n",
       "    5        0.0500007                   0.061647           1.97755   2.40616            0.0720766        0.0876987                   0.0197751       0.12031                    97.7545   140.616\n",
       "    6        0.100001                    0.0539497          1.79218   2.09917            0.0653204        0.0765095                   0.08961         0.20992                    79.2177   109.917\n",
       "    7        0.15                        0.0492846          1.51842   1.90559            0.0553427        0.0694541                   0.0759196       0.285839                   51.8423   90.5592\n",
       "    8        0.200001                    0.0458691          1.36073   1.76937            0.0495951        0.0644893                   0.0680372       0.353877                   36.0727   76.9374\n",
       "    9        0.300001                    0.0409223          1.23813   1.5923             0.0451269        0.0580352                   0.123813        0.47769                    23.8135   59.2295\n",
       "    10       0.4                         0.0371982          1.03116   1.45201            0.0375834        0.0529223                   0.103116        0.580806                   3.11642   45.2013\n",
       "    11       0.5                         0.034067           0.934363  1.34848            0.0340552        0.0491489                   0.093436        0.674242                   -6.56371  34.8483\n",
       "    12       0.6                         0.0311661          0.839405  1.26364            0.0305942        0.0460564                   0.0839403       0.758182                   -16.0595  26.3637\n",
       "    13       0.699999                    0.0283308          0.762425  1.19204            0.0277885        0.0434467                   0.0762423       0.834424                   -23.7575  19.2036\n",
       "    14       0.799999                    0.0253696          0.674382  1.12733            0.0245796        0.0410884                   0.067438        0.901862                   -32.5618  12.7329\n",
       "    15       0.899999                    0.0219068          0.571128  1.06553            0.0208162        0.0388359                   0.0571126       0.958975                   -42.8872  6.55292\n",
       "    16       1                           0.0100407          0.410246  1                  0.0149525        0.0364475                   0.0410252       1                          -58.9754  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.8697456</td>\n",
       "<td>0.0072583</td>\n",
       "<td>0.8582613</td>\n",
       "<td>0.8678545</td>\n",
       "<td>0.8848305</td>\n",
       "<td>0.8779002</td>\n",
       "<td>0.8598814</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.6320995</td>\n",
       "<td>0.0026186</td>\n",
       "<td>0.6350407</td>\n",
       "<td>0.6368893</td>\n",
       "<td>0.632322</td>\n",
       "<td>0.6297507</td>\n",
       "<td>0.6264948</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1302544</td>\n",
       "<td>0.0072583</td>\n",
       "<td>0.1417387</td>\n",
       "<td>0.1321455</td>\n",
       "<td>0.1151694</td>\n",
       "<td>0.1220998</td>\n",
       "<td>0.1401186</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>15505.8</td>\n",
       "<td>864.06287</td>\n",
       "<td>16873.0</td>\n",
       "<td>15731.0</td>\n",
       "<td>13710.0</td>\n",
       "<td>14535.0</td>\n",
       "<td>16680.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.0874616</td>\n",
       "<td>0.0021835</td>\n",
       "<td>0.0859047</td>\n",
       "<td>0.0892964</td>\n",
       "<td>0.0906823</td>\n",
       "<td>0.0892755</td>\n",
       "<td>0.0821490</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.1136790</td>\n",
       "<td>0.0019486</td>\n",
       "<td>0.1142317</td>\n",
       "<td>0.1167818</td>\n",
       "<td>0.1145699</td>\n",
       "<td>0.1143136</td>\n",
       "<td>0.1084981</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.1626574</td>\n",
       "<td>0.0041303</td>\n",
       "<td>0.1704314</td>\n",
       "<td>0.1687107</td>\n",
       "<td>0.1555431</td>\n",
       "<td>0.1588700</td>\n",
       "<td>0.1597318</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.2544043</td>\n",
       "<td>0.2349898</td>\n",
       "<td>3.6113245</td>\n",
       "<td>3.664374</td>\n",
       "<td>3.198994</td>\n",
       "<td>2.881891</td>\n",
       "<td>2.9154377</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.1526804</td>\n",
       "<td>0.0005969</td>\n",
       "<td>0.1512419</td>\n",
       "<td>0.1523858</td>\n",
       "<td>0.1527617</td>\n",
       "<td>0.1536399</td>\n",
       "<td>0.1533727</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.7709178</td>\n",
       "<td>0.0124843</td>\n",
       "<td>0.7463869</td>\n",
       "<td>0.7602029</td>\n",
       "<td>0.7957633</td>\n",
       "<td>0.7853547</td>\n",
       "<td>0.7668810</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.0736978</td>\n",
       "<td>0.0024973</td>\n",
       "<td>0.0760550</td>\n",
       "<td>0.0777071</td>\n",
       "<td>0.0739237</td>\n",
       "<td>0.0734798</td>\n",
       "<td>0.0673233</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5615331</td>\n",
       "<td>0.0028906</td>\n",
       "<td>0.5672395</td>\n",
       "<td>0.5656991</td>\n",
       "<td>0.5574188</td>\n",
       "<td>0.5589107</td>\n",
       "<td>0.5583974</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4384669</td>\n",
       "<td>0.0028906</td>\n",
       "<td>0.4327605</td>\n",
       "<td>0.4343009</td>\n",
       "<td>0.4425813</td>\n",
       "<td>0.4410893</td>\n",
       "<td>0.4416026</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0348231</td>\n",
       "<td>0.0001534</td>\n",
       "<td>0.0344354</td>\n",
       "<td>0.0347887</td>\n",
       "<td>0.0348510</td>\n",
       "<td>0.0350723</td>\n",
       "<td>0.0349681</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.0758244</td>\n",
       "<td>0.0022630</td>\n",
       "<td>0.0737177</td>\n",
       "<td>0.0771857</td>\n",
       "<td>0.0796158</td>\n",
       "<td>0.0779005</td>\n",
       "<td>0.0707021</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.0084287</td>\n",
       "<td>0.0003325</td>\n",
       "<td>0.0087305</td>\n",
       "<td>0.0090071</td>\n",
       "<td>0.0085611</td>\n",
       "<td>0.0081965</td>\n",
       "<td>0.0076484</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.2290822</td>\n",
       "<td>0.0124843</td>\n",
       "<td>0.2536131</td>\n",
       "<td>0.2397971</td>\n",
       "<td>0.2042367</td>\n",
       "<td>0.2146453</td>\n",
       "<td>0.2331190</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1866086</td>\n",
       "<td>0.0004116</td>\n",
       "<td>0.1855678</td>\n",
       "<td>0.1865173</td>\n",
       "<td>0.1866842</td>\n",
       "<td>0.1872759</td>\n",
       "<td>0.1869975</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8939839</td>\n",
       "<td>0.0080289</td>\n",
       "<td>0.8808659</td>\n",
       "<td>0.8916011</td>\n",
       "<td>0.9106008</td>\n",
       "<td>0.903176</td>\n",
       "<td>0.8836757</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.869746    0.00725825   0.858261      0.867854      0.884831      0.8779        0.859881\n",
       "auc                      0.6321      0.00261862   0.635041      0.636889      0.632322      0.629751      0.626495\n",
       "err                      0.130254    0.00725825   0.141739      0.132146      0.115169      0.1221        0.140119\n",
       "err_count                15505.8     864.063      16873         15731         13710         14535         16680\n",
       "f0point5                 0.0874616   0.00218353   0.0859047     0.0892964     0.0906823     0.0892755     0.082149\n",
       "f1                       0.113679    0.0019486    0.114232      0.116782      0.11457       0.114314      0.108498\n",
       "f2                       0.162657    0.00413031   0.170431      0.168711      0.155543      0.15887       0.159732\n",
       "lift_top_group           3.2544      0.23499      3.61132       3.66437       3.19899       2.88189       2.91544\n",
       "logloss                  0.15268     0.000596869  0.151242      0.152386      0.152762      0.15364       0.153373\n",
       "max_per_class_error      0.770918    0.0124843    0.746387      0.760203      0.795763      0.785355      0.766881\n",
       "mcc                      0.0736978   0.00249728   0.076055      0.0777071     0.0739237     0.0734798     0.0673233\n",
       "mean_per_class_accuracy  0.561533    0.00289061   0.567239      0.565699      0.557419      0.558911      0.558397\n",
       "mean_per_class_error     0.438467    0.00289061   0.432761      0.434301      0.442581      0.441089      0.441603\n",
       "mse                      0.0348231   0.000153415  0.0344354     0.0347887     0.034851      0.0350723     0.0349681\n",
       "precision                0.0758244   0.00226305   0.0737177     0.0771857     0.0796158     0.0779005     0.0707021\n",
       "r2                       0.00842873  0.000332548  0.00873052    0.0090071     0.00856106    0.0081965     0.00764845\n",
       "recall                   0.229082    0.0124843    0.253613      0.239797      0.204237      0.214645      0.233119\n",
       "rmse                     0.186609    0.000411564  0.185568      0.186517      0.186684      0.187276      0.186997\n",
       "specificity              0.893984    0.00802892   0.880866      0.891601      0.910601      0.903176      0.883676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:00</td>\n",
       "<td> 6 min  5.992 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:02</td>\n",
       "<td> 6 min  7.439 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1886341</td>\n",
       "<td>0.1629365</td>\n",
       "<td>0.5975824</td>\n",
       "<td>3.3829238</td>\n",
       "<td>0.0709051</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:03</td>\n",
       "<td> 6 min  8.573 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1938897</td>\n",
       "<td>0.1703525</td>\n",
       "<td>0.5887558</td>\n",
       "<td>4.0742570</td>\n",
       "<td>0.0739167</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:04</td>\n",
       "<td> 6 min  9.827 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1910683</td>\n",
       "<td>0.1655660</td>\n",
       "<td>0.5800537</td>\n",
       "<td>4.6134969</td>\n",
       "<td>0.1077606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:11</td>\n",
       "<td> 6 min 16.997 sec</td>\n",
       "<td>11.0</td>\n",
       "<td>0.1866343</td>\n",
       "<td>0.1625386</td>\n",
       "<td>0.5847768</td>\n",
       "<td>5.4292701</td>\n",
       "<td>0.1373613</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:31</td>\n",
       "<td> 6 min 36.757 sec</td>\n",
       "<td>32.0</td>\n",
       "<td>0.1879265</td>\n",
       "<td>0.1620380</td>\n",
       "<td>0.5862762</td>\n",
       "<td>5.6366701</td>\n",
       "<td>0.1543821</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-29 12:02:49</td>\n",
       "<td> 6 min 54.896 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1879058</td>\n",
       "<td>0.1608584</td>\n",
       "<td>0.5869001</td>\n",
       "<td>5.8071990</td>\n",
       "<td>0.1612883</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2017-10-29 12:02:00  6 min  5.992 sec  0                  nan              nan                 nan             nan              nan\n",
       "    2017-10-29 12:02:02  6 min  7.439 sec  1                  0.188634         0.162937            0.597582        3.38292          0.0709051\n",
       "    2017-10-29 12:02:03  6 min  8.573 sec  2                  0.19389          0.170353            0.588756        4.07426          0.0739167\n",
       "    2017-10-29 12:02:04  6 min  9.827 sec  3                  0.191068         0.165566            0.580054        4.6135           0.107761\n",
       "    2017-10-29 12:02:11  6 min 16.997 sec  11                 0.186634         0.162539            0.584777        5.42927          0.137361\n",
       "    2017-10-29 12:02:31  6 min 36.757 sec  32                 0.187926         0.162038            0.586276        5.63667          0.154382\n",
       "    2017-10-29 12:02:49  6 min 54.896 sec  50                 0.187906         0.160858            0.5869          5.8072           0.161288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ps_car_11_cat</td>\n",
       "<td>5423.3886719</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1851469</td></tr>\n",
       "<tr><td>ps_ind_05_cat</td>\n",
       "<td>2037.6219482</td>\n",
       "<td>0.3757101</td>\n",
       "<td>0.0695616</td></tr>\n",
       "<tr><td>ps_car_13</td>\n",
       "<td>1942.5847168</td>\n",
       "<td>0.3581865</td>\n",
       "<td>0.0663171</td></tr>\n",
       "<tr><td>ps_ind_17_bin</td>\n",
       "<td>1401.5368652</td>\n",
       "<td>0.2584246</td>\n",
       "<td>0.0478465</td></tr>\n",
       "<tr><td>ps_reg_03</td>\n",
       "<td>1335.0637207</td>\n",
       "<td>0.2461678</td>\n",
       "<td>0.0455772</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>ps_ind_12_bin</td>\n",
       "<td>7.6879830</td>\n",
       "<td>0.0014176</td>\n",
       "<td>0.0002625</td></tr>\n",
       "<tr><td>ps_car_10_cat</td>\n",
       "<td>1.0008702</td>\n",
       "<td>0.0001845</td>\n",
       "<td>0.0000342</td></tr>\n",
       "<tr><td>ps_ind_11_bin</td>\n",
       "<td>0.1216903</td>\n",
       "<td>0.0000224</td>\n",
       "<td>0.0000042</td></tr>\n",
       "<tr><td>ps_ind_10_bin</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>ps_ind_13_bin</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable       relative_importance    scaled_importance       percentage\n",
       "-------------  ---------------------  ----------------------  ----------------------\n",
       "ps_car_11_cat  5423.388671875         1.0                     0.1851468795978182\n",
       "ps_ind_05_cat  2037.6219482421875     0.3757101088492946      0.06956155428680351\n",
       "ps_car_13      1942.584716796875      0.3581865203338405      0.06631711655381102\n",
       "ps_ind_17_bin  1401.536865234375      0.2584245662684229      0.047846502056018085\n",
       "ps_reg_03      1335.063720703125      0.24616781157998038     0.04557720217145702\n",
       "---            ---                    ---                     ---\n",
       "ps_ind_12_bin  7.68798303604126       0.0014175607726420489   0.00026245695369494755\n",
       "ps_car_10_cat  1.0008702278137207     0.00018454702186551845  3.4168305237471064e-05\n",
       "ps_ind_11_bin  0.1216903105378151     2.2438058177332093e-05  4.154336455767345e-06\n",
       "ps_ind_10_bin  0.0                    0.0                     0.0\n",
       "ps_ind_13_bin  0.0                    0.0                     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naivebayes Model Build progress: |████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "my_nbe = H2ONaiveBayesEstimator(laplace=3,\n",
    "                                compute_metrics=True,\n",
    "                                nfolds=nfolds,\n",
    "                                fold_assignment=\"Modulo\",\n",
    "                                keep_cross_validation_predictions=True,\n",
    "                                seed=1)\n",
    "my_nbe.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2352899015847476"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nbe.gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_binomial_third\",\n",
    "                                       base_models=[my_gbm.model_id, my_rdf.model_id,my_nbe.model_id])\n",
    "ensemble.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  my_ensemble_binomial_third\n",
      "No model summary for this model\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.03399206503785317\n",
      "RMSE: 0.18436937120317237\n",
      "LogLoss: 0.1445988564503525\n",
      "Null degrees of freedom: 595211\n",
      "Residual degrees of freedom: 595209\n",
      "Null deviance: 186283.45504691734\n",
      "Residual deviance: 172133.94909105444\n",
      "AIC: 172139.94909105444\n",
      "AUC: 0.7593889296063765\n",
      "Gini: 0.518777859212753\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.05933166636628491: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>528485.0</td>\n",
       "<td>45033.0</td>\n",
       "<td>0.0785</td>\n",
       "<td> (45033.0/573518.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>14883.0</td>\n",
       "<td>6811.0</td>\n",
       "<td>0.686</td>\n",
       "<td> (14883.0/21694.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>543368.0</td>\n",
       "<td>51844.0</td>\n",
       "<td>0.1007</td>\n",
       "<td> (59916.0/595212.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      528485  45033  0.0785   (45033.0/573518.0)\n",
       "1      14883   6811   0.686    (14883.0/21694.0)\n",
       "Total  543368  51844  0.1007   (59916.0/595212.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0593317</td>\n",
       "<td>0.1852376</td>\n",
       "<td>209.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0455005</td>\n",
       "<td>0.2823402</td>\n",
       "<td>253.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0883387</td>\n",
       "<td>0.1709569</td>\n",
       "<td>148.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2983533</td>\n",
       "<td>0.9635978</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4621968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0185927</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.4621968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0455005</td>\n",
       "<td>0.1639315</td>\n",
       "<td>253.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0371411</td>\n",
       "<td>0.6914535</td>\n",
       "<td>288.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0367337</td>\n",
       "<td>0.6927922</td>\n",
       "<td>290.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0593317    0.185238  209\n",
       "max f2                       0.0455005    0.28234   253\n",
       "max f0point5                 0.0883387    0.170957  148\n",
       "max accuracy                 0.298353     0.963598  20\n",
       "max precision                0.462197     1         0\n",
       "max recall                   0.0185927    1         394\n",
       "max specificity              0.462197     1         0\n",
       "max absolute_mcc             0.0455005    0.163931  253\n",
       "max min_per_class_accuracy   0.0371411    0.691453  288\n",
       "max mean_per_class_accuracy  0.0367337    0.692792  290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100015</td>\n",
       "<td>0.1164635</td>\n",
       "<td>6.4570522</td>\n",
       "<td>6.4570522</td>\n",
       "<td>0.2353435</td>\n",
       "<td>0.2353435</td>\n",
       "<td>0.0645801</td>\n",
       "<td>0.0645801</td>\n",
       "<td>545.7052170</td>\n",
       "<td>545.7052170</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200013</td>\n",
       "<td>0.0943665</td>\n",
       "<td>4.3284730</td>\n",
       "<td>5.3928520</td>\n",
       "<td>0.1577621</td>\n",
       "<td>0.1965561</td>\n",
       "<td>0.0432839</td>\n",
       "<td>0.1078639</td>\n",
       "<td>332.8472995</td>\n",
       "<td>439.2851981</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300011</td>\n",
       "<td>0.0834298</td>\n",
       "<td>3.7799232</td>\n",
       "<td>4.8552392</td>\n",
       "<td>0.1377688</td>\n",
       "<td>0.1769614</td>\n",
       "<td>0.0377985</td>\n",
       "<td>0.1456624</td>\n",
       "<td>277.9923169</td>\n",
       "<td>385.5239152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400009</td>\n",
       "<td>0.0762947</td>\n",
       "<td>3.5817077</td>\n",
       "<td>4.5368697</td>\n",
       "<td>0.1305444</td>\n",
       "<td>0.1653576</td>\n",
       "<td>0.0358164</td>\n",
       "<td>0.1814787</td>\n",
       "<td>258.1707686</td>\n",
       "<td>353.6869658</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.0710908</td>\n",
       "<td>3.0700352</td>\n",
       "<td>4.2435126</td>\n",
       "<td>0.1118952</td>\n",
       "<td>0.1546655</td>\n",
       "<td>0.0306997</td>\n",
       "<td>0.2121785</td>\n",
       "<td>207.0035159</td>\n",
       "<td>324.3512615</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000013</td>\n",
       "<td>0.0564507</td>\n",
       "<td>2.6440135</td>\n",
       "<td>3.4437631</td>\n",
       "<td>0.0963677</td>\n",
       "<td>0.1255166</td>\n",
       "<td>0.1322025</td>\n",
       "<td>0.3443809</td>\n",
       "<td>164.4013509</td>\n",
       "<td>244.3763062</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500003</td>\n",
       "<td>0.0490321</td>\n",
       "<td>2.0946306</td>\n",
       "<td>2.9940623</td>\n",
       "<td>0.0763441</td>\n",
       "<td>0.1091261</td>\n",
       "<td>0.1047294</td>\n",
       "<td>0.4491104</td>\n",
       "<td>109.4630595</td>\n",
       "<td>199.4062314</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000010</td>\n",
       "<td>0.0442535</td>\n",
       "<td>1.7027521</td>\n",
       "<td>2.6712320</td>\n",
       "<td>0.0620611</td>\n",
       "<td>0.0973598</td>\n",
       "<td>0.0851387</td>\n",
       "<td>0.5342491</td>\n",
       "<td>70.2752075</td>\n",
       "<td>167.1232042</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000007</td>\n",
       "<td>0.0381076</td>\n",
       "<td>1.3340139</td>\n",
       "<td>2.2254952</td>\n",
       "<td>0.0486215</td>\n",
       "<td>0.0811138</td>\n",
       "<td>0.1334009</td>\n",
       "<td>0.6676500</td>\n",
       "<td>33.4013886</td>\n",
       "<td>122.5495153</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000003</td>\n",
       "<td>0.0340972</td>\n",
       "<td>0.9574108</td>\n",
       "<td>1.9084754</td>\n",
       "<td>0.0348952</td>\n",
       "<td>0.0695592</td>\n",
       "<td>0.0957408</td>\n",
       "<td>0.7633908</td>\n",
       "<td>-4.2589205</td>\n",
       "<td>90.8475395</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0310896</td>\n",
       "<td>0.7527452</td>\n",
       "<td>1.6773301</td>\n",
       "<td>0.0274357</td>\n",
       "<td>0.0611345</td>\n",
       "<td>0.0752743</td>\n",
       "<td>0.8386651</td>\n",
       "<td>-24.7254777</td>\n",
       "<td>67.7330137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999997</td>\n",
       "<td>0.0285701</td>\n",
       "<td>0.5679009</td>\n",
       "<td>1.4924258</td>\n",
       "<td>0.0206986</td>\n",
       "<td>0.0543952</td>\n",
       "<td>0.0567899</td>\n",
       "<td>0.8954550</td>\n",
       "<td>-43.2099134</td>\n",
       "<td>49.2425777</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999993</td>\n",
       "<td>0.0262925</td>\n",
       "<td>0.4462078</td>\n",
       "<td>1.3429664</td>\n",
       "<td>0.0162632</td>\n",
       "<td>0.0489478</td>\n",
       "<td>0.0446206</td>\n",
       "<td>0.9400756</td>\n",
       "<td>-55.3792176</td>\n",
       "<td>34.2966428</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999990</td>\n",
       "<td>0.0240941</td>\n",
       "<td>0.3240538</td>\n",
       "<td>1.2156026</td>\n",
       "<td>0.0118110</td>\n",
       "<td>0.0443057</td>\n",
       "<td>0.0324053</td>\n",
       "<td>0.9724809</td>\n",
       "<td>-67.5946178</td>\n",
       "<td>21.5602620</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999987</td>\n",
       "<td>0.0217583</td>\n",
       "<td>0.2042046</td>\n",
       "<td>1.1032253</td>\n",
       "<td>0.0074428</td>\n",
       "<td>0.0402098</td>\n",
       "<td>0.0204204</td>\n",
       "<td>0.9929013</td>\n",
       "<td>-79.5795386</td>\n",
       "<td>10.3225273</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0156088</td>\n",
       "<td>0.0709864</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025873</td>\n",
       "<td>0.0364475</td>\n",
       "<td>0.0070987</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.9013584</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100015                   0.116464           6.45705    6.45705            0.235344         0.235344                    0.0645801       0.0645801                  545.705   545.705\n",
       "    2        0.0200013                   0.0943665          4.32847    5.39285            0.157762         0.196556                    0.0432839       0.107864                   332.847   439.285\n",
       "    3        0.0300011                   0.0834298          3.77992    4.85524            0.137769         0.176961                    0.0377985       0.145662                   277.992   385.524\n",
       "    4        0.0400009                   0.0762947          3.58171    4.53687            0.130544         0.165358                    0.0358164       0.181479                   258.171   353.687\n",
       "    5        0.0500007                   0.0710908          3.07004    4.24351            0.111895         0.154666                    0.0306997       0.212178                   207.004   324.351\n",
       "    6        0.100001                    0.0564507          2.64401    3.44376            0.0963677        0.125517                    0.132202        0.344381                   164.401   244.376\n",
       "    7        0.15                        0.0490321          2.09463    2.99406            0.0763441        0.109126                    0.104729        0.44911                    109.463   199.406\n",
       "    8        0.200001                    0.0442535          1.70275    2.67123            0.0620611        0.0973598                   0.0851387       0.534249                   70.2752   167.123\n",
       "    9        0.300001                    0.0381076          1.33401    2.2255             0.0486215        0.0811138                   0.133401        0.66765                    33.4014   122.55\n",
       "    10       0.4                         0.0340972          0.957411   1.90848            0.0348952        0.0695592                   0.0957408       0.763391                   -4.25892  90.8475\n",
       "    11       0.5                         0.0310896          0.752745   1.67733            0.0274357        0.0611345                   0.0752743       0.838665                   -24.7255  67.733\n",
       "    12       0.6                         0.0285701          0.567901   1.49243            0.0206986        0.0543952                   0.0567899       0.895455                   -43.2099  49.2426\n",
       "    13       0.699999                    0.0262925          0.446208   1.34297            0.0162632        0.0489478                   0.0446206       0.940076                   -55.3792  34.2966\n",
       "    14       0.799999                    0.0240941          0.324054   1.2156             0.011811         0.0443057                   0.0324053       0.972481                   -67.5946  21.5603\n",
       "    15       0.899999                    0.0217583          0.204205   1.10323            0.00744275       0.0402098                   0.0204204       0.992901                   -79.5795  10.3225\n",
       "    16       1                           0.0156088          0.0709864  1                  0.00258728       0.0364475                   0.00709874      1                          -92.9014  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518777859212753"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)\n",
    "p = ensemble.predict(test_data=test)\n",
    "sub['target'] = p['p1'].as_data_frame(True).values\n",
    "filename = 'stack_model_'+str(dt.datetime.now()).replace(' ','_').replace(':','').replace('.','')\n",
    "sub.id = sub.id.astype('Int32')\n",
    "sub.to_csv('../output/'+filename+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
